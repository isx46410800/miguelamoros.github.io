{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Apuntes Miguel For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. mkdocs gh-deploy - Deploy to GitHub Pages. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Github pages Tutorial GithHub pages Creamos repositorio con extensi\u00f3n github.io->https://github.com/isx46410800/miguelamoros.github.io Clonamos, metemos la chicha de MKdocs. Hacemos un mkdocs build y un mkdocs gh-deploy y nos dar\u00e1 un link de nuestra web est\u00e1tica generada por mkdocs en Github. https://isx46410800.github.io/miguelamoros.github.io","title":"MkDocs"},{"location":"#apuntes-miguel","text":"For full documentation visit mkdocs.org .","title":"Apuntes Miguel"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. mkdocs gh-deploy - Deploy to GitHub Pages.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"#github-pages","text":"Tutorial GithHub pages Creamos repositorio con extensi\u00f3n github.io->https://github.com/isx46410800/miguelamoros.github.io Clonamos, metemos la chicha de MKdocs. Hacemos un mkdocs build y un mkdocs gh-deploy y nos dar\u00e1 un link de nuestra web est\u00e1tica generada por mkdocs en Github. https://isx46410800.github.io/miguelamoros.github.io","title":"Github pages"},{"location":"ansible/","text":"Comandos para GIT ANSIBLE Es un software de gesti\u00f3n de la configuraci\u00f3n autom\u00e1tica y remota. Nos permite centralizar la configuraci\u00f3n de numerosas servidores, dispositivos de red y Cloud Providers de una forma sencilla y automatizada. Podremos aprovisionar servidores en AWS, Azure o VMWARE y automatizar la configuraci\u00f3n de dichos servidores. Ventajas: No requiere agentes Multiplataforma, eficiente y seguro Aprovisiona infraestructuras Configura dispositivos de red Se necesita un Ansible Controller ejecutando en un SO Linux. Se puede administrar equipos Windows/Max pero el Ansible Controller debe ser LINUX. Instalaci\u00f3n yum install ansible RedHat dnf install ansible Fedora apt-get install ansible Ubuntu pip install ansible Python-Pip brew install ansible MAC ansible --version comprobamos la versi\u00f3n instalada. Inventarios Ansible trabaja ejecutando tareas contra diferentes equipos remotos, dispositivos de red o APIs. Nos permiten definir dichos equipos, agruparlos y especificar valores grupales o individuales de los mismos. Formato Ansible INI, YAML o JSON. /etc/ansible/hosts fichero por defecto donde se define o ruta concreta -i file . ansbible.cfg fichero de configuraci\u00f3n. EJEMPLO: [masters] # nombre general master ansible_host=IP/FQDN/service_docker ansible_user=remote_user ansible_private_key_file=xxx.pem # nombre - maqquina a conectar - usuario a conectar - private_key Comprobamos la conexi\u00f3n: ansible -i inventory -m ping all ansible -m ping -i hosts master -m de modulo -i fichero y maquina master | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } Comando b\u00e1sico ansible -i <inventory_path> -m {modulo} -a \"{modulo opciones}\" <nodos: all/master> Ejemplo: ansible -i hosts -m shell -a \"echo 'hola'\" all Ejemplo: ansible -i hosts -m shell -a \"echo 'hola'\" all Ejemplo: ansible -i hosts -m shell -a \"ls -l /etc\" all/masters Ejemplo: ansible -i hosts -b -m user -a \"name=andy state=present shell=/bin/bash\" all atacamos a todos los users(all) y le creamos un usuario andy. -b de superuser, con una shell concreta Ayuda Ansible ansible-doc -l Ejemplo de ayuda de un m\u00f3dulo concreto: ansible-doc (-s) user Playbook Los Playbooks describen configuraciones, despliegue, y orquestaci\u00f3n en Ansible. \u200b El formato del Playbook es YAML. \u200b Cada Playbook asocia un grupo de hosts a un conjunto de roles. Cada rol est\u00e1 representado por llamadas a lo que Ansible define como Tareas. Ejemplo: - name: Demo Install Ansible hosts: all become: yes tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: ansible state: present Ejemplo: cat play.yml - hosts: test1 tasks: - shell: echo \"Hola Mundo desde Ansible y Jenkins\" > /tmp/hola-ansible.txt Ejemplo: - hosts: test1 tasks: - debug: var: MSG Ejemplo: - hosts: test1 tasks: - debug: var: MSG - debug: msg: \"Yo no me voy a ejecutar :(\" tags: no-exec - debug: msg: \"Yo s\u00ed me voy a ejecutar :)\" tags: si-exec Ejemplo completo de crear un user: - hosts: master become: yes # ser superuser tasks: - name: create user andy user: name: andy state: present shell: /bin/bash - name: create user miguel user: name=andy state= present ORDEN: ansible-playbook -i hosts playbook.yml --syntax ansible-playbook -i hosts playbook.yml --check (solo simula) M\u00f3dulos Conocidos tambi\u00e9n task plugins o library plugins, son unidades discretas de c\u00f3digo que se pueden utilizar desde linea de comandos o playbook. Se suelen utilizar en el nodo de destino remoto y recopila los valores de retorno. Se pueden utilizar en ad-hoc commands, playbooks y roles. Ejemplo m\u00f3dulo apt: - name: Demo Install Ansible hosts: all become: yes tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: ansible state: present Ejemplo m\u00f3dulo authorized_keys: - hosts: master become: yes # ser superuser tasks: - name: create user andy user: name: andy state: present shell: /bin/bash - name: create ssh keys authorized_keys: user: andy key: \"{{ item }}\" state: present with_file: - ~/.ssh/id_rsa.pub no_log: yes Variables Ejemplo de variables para Ansible: - name: Demo Install Ansible hosts: all become: yes ## definimos las variables vars: package: ansible state: present tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: \"{{ package }}\" state: \"{{ state }}\" Condicionales Realizar tareas segun ciertas cosas o par\u00e1metros: Ejemplo condicional: - name: Demo Install Ansible hosts: all become: yes ## definimos las variables vars: package: ansible state: present tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: \"{{ package }}\" state: \"{{ state }}\" ## indicando la condicion de solo en master when: \"'master' in inventory_hostname\" Bucles Ejemplo de bucle: - name: Demo Install Ansible hosts: all become: yes tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: \"{{ item }}\" state: present ## indicando bucle de paquetes a instalar loop: - ansible - apache2 - name: Demo Install Ansible hosts: all become: yes tasks: - name: create users user: name: \"{{ item }}\" state: present/absent ## indicando bucle de crear users with_items: - andy - miguel - mario Roles Los roles son formas de cargar autom\u00e1ticamente una estructura de archivos/directorios, archivos de variables, tareas y controladores basados en una estructura de archivos conocida. Agrupar contenido por roles permite compartir los roles con otros usuarios y poder reutilizar c\u00f3digo. Los roles esperan que los archivos esten en ciertos directorios, deben incluir al menos uno de estos. Ejemplo de role: - name: Play to demo roles hosts: all become: yes ## roles block roles: ## the role we want to install - apache ## dentro de este directorio hay muchos files, playbooks, tasks... Ansible Galaxy Es un sitio gratuito para buscar, descargar, calificar y revisar toto tipo de roles de Ansible desarrollados por la comunidad y puede ser una excelente manera de impulsar nuestros proyectos de automatizaci\u00f3n. El cliente ansible-galaxy est\u00e1 incluido en Ansible. Ejemplo: ## ansible-galaxy ## install a role in 'roles' folder ansible-galaxy install \"ansible.docker\" -p roles/ ## create a role folders/files structure ansible-galaxy init \"my-role\" ## search for a role ansible-galaxy search 'docker'","title":"Ansible"},{"location":"ansible/#comandos-para-git","text":"","title":"Comandos para GIT"},{"location":"ansible/#ansible","text":"Es un software de gesti\u00f3n de la configuraci\u00f3n autom\u00e1tica y remota. Nos permite centralizar la configuraci\u00f3n de numerosas servidores, dispositivos de red y Cloud Providers de una forma sencilla y automatizada. Podremos aprovisionar servidores en AWS, Azure o VMWARE y automatizar la configuraci\u00f3n de dichos servidores. Ventajas: No requiere agentes Multiplataforma, eficiente y seguro Aprovisiona infraestructuras Configura dispositivos de red Se necesita un Ansible Controller ejecutando en un SO Linux. Se puede administrar equipos Windows/Max pero el Ansible Controller debe ser LINUX.","title":"ANSIBLE"},{"location":"ansible/#instalacion","text":"yum install ansible RedHat dnf install ansible Fedora apt-get install ansible Ubuntu pip install ansible Python-Pip brew install ansible MAC ansible --version comprobamos la versi\u00f3n instalada.","title":"Instalaci\u00f3n"},{"location":"ansible/#inventarios","text":"Ansible trabaja ejecutando tareas contra diferentes equipos remotos, dispositivos de red o APIs. Nos permiten definir dichos equipos, agruparlos y especificar valores grupales o individuales de los mismos. Formato Ansible INI, YAML o JSON. /etc/ansible/hosts fichero por defecto donde se define o ruta concreta -i file . ansbible.cfg fichero de configuraci\u00f3n. EJEMPLO: [masters] # nombre general master ansible_host=IP/FQDN/service_docker ansible_user=remote_user ansible_private_key_file=xxx.pem # nombre - maqquina a conectar - usuario a conectar - private_key Comprobamos la conexi\u00f3n: ansible -i inventory -m ping all ansible -m ping -i hosts master -m de modulo -i fichero y maquina master | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" }","title":"Inventarios"},{"location":"ansible/#comando-basico","text":"ansible -i <inventory_path> -m {modulo} -a \"{modulo opciones}\" <nodos: all/master> Ejemplo: ansible -i hosts -m shell -a \"echo 'hola'\" all Ejemplo: ansible -i hosts -m shell -a \"echo 'hola'\" all Ejemplo: ansible -i hosts -m shell -a \"ls -l /etc\" all/masters Ejemplo: ansible -i hosts -b -m user -a \"name=andy state=present shell=/bin/bash\" all atacamos a todos los users(all) y le creamos un usuario andy. -b de superuser, con una shell concreta","title":"Comando b\u00e1sico"},{"location":"ansible/#ayuda-ansible","text":"ansible-doc -l Ejemplo de ayuda de un m\u00f3dulo concreto: ansible-doc (-s) user","title":"Ayuda Ansible"},{"location":"ansible/#playbook","text":"Los Playbooks describen configuraciones, despliegue, y orquestaci\u00f3n en Ansible. \u200b El formato del Playbook es YAML. \u200b Cada Playbook asocia un grupo de hosts a un conjunto de roles. Cada rol est\u00e1 representado por llamadas a lo que Ansible define como Tareas. Ejemplo: - name: Demo Install Ansible hosts: all become: yes tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: ansible state: present Ejemplo: cat play.yml - hosts: test1 tasks: - shell: echo \"Hola Mundo desde Ansible y Jenkins\" > /tmp/hola-ansible.txt Ejemplo: - hosts: test1 tasks: - debug: var: MSG Ejemplo: - hosts: test1 tasks: - debug: var: MSG - debug: msg: \"Yo no me voy a ejecutar :(\" tags: no-exec - debug: msg: \"Yo s\u00ed me voy a ejecutar :)\" tags: si-exec Ejemplo completo de crear un user: - hosts: master become: yes # ser superuser tasks: - name: create user andy user: name: andy state: present shell: /bin/bash - name: create user miguel user: name=andy state= present ORDEN: ansible-playbook -i hosts playbook.yml --syntax ansible-playbook -i hosts playbook.yml --check (solo simula)","title":"Playbook"},{"location":"ansible/#modulos","text":"Conocidos tambi\u00e9n task plugins o library plugins, son unidades discretas de c\u00f3digo que se pueden utilizar desde linea de comandos o playbook. Se suelen utilizar en el nodo de destino remoto y recopila los valores de retorno. Se pueden utilizar en ad-hoc commands, playbooks y roles. Ejemplo m\u00f3dulo apt: - name: Demo Install Ansible hosts: all become: yes tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: ansible state: present Ejemplo m\u00f3dulo authorized_keys: - hosts: master become: yes # ser superuser tasks: - name: create user andy user: name: andy state: present shell: /bin/bash - name: create ssh keys authorized_keys: user: andy key: \"{{ item }}\" state: present with_file: - ~/.ssh/id_rsa.pub no_log: yes","title":"M\u00f3dulos"},{"location":"ansible/#variables","text":"Ejemplo de variables para Ansible: - name: Demo Install Ansible hosts: all become: yes ## definimos las variables vars: package: ansible state: present tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: \"{{ package }}\" state: \"{{ state }}\"","title":"Variables"},{"location":"ansible/#condicionales","text":"Realizar tareas segun ciertas cosas o par\u00e1metros: Ejemplo condicional: - name: Demo Install Ansible hosts: all become: yes ## definimos las variables vars: package: ansible state: present tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: \"{{ package }}\" state: \"{{ state }}\" ## indicando la condicion de solo en master when: \"'master' in inventory_hostname\"","title":"Condicionales"},{"location":"ansible/#bucles","text":"Ejemplo de bucle: - name: Demo Install Ansible hosts: all become: yes tasks: ## instalando ansible usando apt-get - name: install ansible using apt apt: name: \"{{ item }}\" state: present ## indicando bucle de paquetes a instalar loop: - ansible - apache2 - name: Demo Install Ansible hosts: all become: yes tasks: - name: create users user: name: \"{{ item }}\" state: present/absent ## indicando bucle de crear users with_items: - andy - miguel - mario","title":"Bucles"},{"location":"ansible/#roles","text":"Los roles son formas de cargar autom\u00e1ticamente una estructura de archivos/directorios, archivos de variables, tareas y controladores basados en una estructura de archivos conocida. Agrupar contenido por roles permite compartir los roles con otros usuarios y poder reutilizar c\u00f3digo. Los roles esperan que los archivos esten en ciertos directorios, deben incluir al menos uno de estos. Ejemplo de role: - name: Play to demo roles hosts: all become: yes ## roles block roles: ## the role we want to install - apache ## dentro de este directorio hay muchos files, playbooks, tasks...","title":"Roles"},{"location":"ansible/#ansible-galaxy","text":"Es un sitio gratuito para buscar, descargar, calificar y revisar toto tipo de roles de Ansible desarrollados por la comunidad y puede ser una excelente manera de impulsar nuestros proyectos de automatizaci\u00f3n. El cliente ansible-galaxy est\u00e1 incluido en Ansible. Ejemplo: ## ansible-galaxy ## install a role in 'roles' folder ansible-galaxy install \"ansible.docker\" -p roles/ ## create a role folders/files structure ansible-galaxy init \"my-role\" ## search for a role ansible-galaxy search 'docker'","title":"Ansible Galaxy"},{"location":"bash_scripting/","text":"Comandos para Bash Scripting #! /bin/bash validar argumentos # indica el numero de argumentos pasados echo $# # si no tiene 2 args, plegar if [ $# -ne 2 ] then echo \"Num de args incorrecte\" echo \"USAGE: prog.sh arg1 arg2\" exit 1 fi # mostrar los args echo \"Los argumentos son $1 y $2\" exit 0 validar help #help if [ $1 == \"--help\" -o $1 == \"-h\" ] then echo \"mostramos ayuda\" exit 0 fi comparadores -lt / -gt / -eq / -ne / -ge / -le m\u00e1s grande, menor que... -d / -f / -h directorio, file, link -n mientras sea nulo $? estatus level de error /dev/stderr / >>/dev/null if [ $# -eq 3 ] then if ! [ \"$1\" == \"-b\" -a \"$2\" == \"-a\" ] then echo \"ERROR: format args incorrecte\" echo \"USAGE: prog arg -h / prog -a arg / prog -b -a arg\" exit $ERR_NARGS fi fi conficional if edad=$1 echo $edad if [ $edad -lt 18 ] then echo \"Es menor de edat\" elif [ $edad -eq 18 ] then echo \"18 recien cumplidos\" else echo \"Ya es mayor de edad\" fi bucle for count=0 for arg in $* do count=$((count+1)) echo \"$count: $arg\" done exit 0 bucle while cont=0 MAX=$1 while [ $cont -le $MAX ] do echo $cont cont=$((cont+1)) done exit 0 bucle esac for mes in $* do case $mes in '2') echo \"$mes tiene 28 dias\";; '1'|'3'|'5'|'7'|'8'|'10'|'12') echo \"$mes tiene 31 dias\";; '2'|'4'|'6'|'9'|'11') echo \"$mes tiene 30 dias\";; *) echo \"$mes no es un mes correcto\" esac done exit 0 leer por entrada standard count=0 while read -r line do count=$((count+1)) echo \"$count: $line\" done exit 0 MAX=$1 cont=1 while read -r line && [ $cont -le $MAX ] do echo \"$cont: $line\" cont=$((cont+1)) done exit 0 separar opciones con shift opciones='' argumentos='' numeros='' files='' while [ -n \"$1\" ] do case $1 in '-a') files=$2 shift;; '-c'|'-b'|'-e') opciones=\"$opciones $1\";; '-d') numeros=$2 shift;; *) argumentos=\"$argumentos $1\";; esac shift done echo \"opciones: $opciones\" echo \"argumentos: $argumentos\" echo \"numeros: $numeros\" echo \"files: $files\" exit 0 mirar si es directorio, regular file... #files y dir a copiar llistafiles=$(echo $* | cut -d' ' -f1-$(($#-1))) dirdesti=$(echo $* | cut -d' ' -f$#) #comprobar que sea un directorio if ! [ -d $dirdesti ] then echo \"error, no es un dir desti correcto\" exit 2 fi # para cada file validada lo copiamos al dir for file in $llistafiles do if ! [ -f $file ] then echo \"error, no es un file\" >> /dev/stderr exit 3 fi cp $file $dirdesti/. done exit 0 for dir in $* do # miramos si es un help if [ $dir == \"--help\" -o $dir == \"-h\" ] then echo \"mostramos ayuda\" exit 0 fi # verificar que es un dir if ! [ -d $dir ] then echo \"error arg no es un dir\" echo \"USAGE: prog.sh arg[dir]\" exit 2 fi llistadir=$(ls $dir) count=1 for file in $llistadir do #de cada cosa que imprime decir si es un regular file, dir, link o altre cosa if [ -d $dir/$file ] then echo \"es un directorio\" echo \"$count: $file\" elif [ -f $dir/$file ] then echo \"es un file\" echo \"$count: $file\" elif [ -d $dir/$file ] then echo \"es una altra cosa\" echo \"$count: $file\" fi count=$((count+1)) done done exit 0 Mayusculas , copiar , buscar , ordenar tr echo \"hola\" | tr -s '[a-z]' '[A-Z]' echo \"hola\" | tr -s '[:blank:]' ' ' #'\\t' tabulador cut + cut -d' ' -f1-5 corta por campos y delimitador + cut -c1-50 corta por caracteres llistafiles=$(echo $ | cut -d' ' -f1-$(($#-1))) dirdesti=$(echo $ | cut -d' ' -f$#) uid=$(echo $loginLine | cut -d: -f3) grep/egrep + egrep \"^[^ ]{10,}\" busca de lo que se pase o line algo que tenga mas de 10 chars + echo $arg | egrep \".{4,}\" busca de lo que se pase que tenga mas de 4 chars + egrep \"^$user:\" /etc/passwd buscar el campo user del /etc/passwd + egrep \"^[^:] :[^:] :[^:]*:$gid:\" /etc/passwd + sort -u 2> /dev/null) ordenar unico y quita los repetidos + listshells=$(cut -d: -f7 /etc/passwd | sort -u 2> /dev/null) Funciones function nombreFuncion(){ return xxxxx } function showUser(){ ERR_NARGS=1 ERR_NOLOGIN=2 OK=0 #validar args if [ $# -ne 1 ] then echo \"ERR: num args incorrecte\" echo \"USAGE: $0 login\" return $ERR_NARGS fi #validar si existe el login login=$1 userLine=$(egrep \"^$login:\" /etc/passwd 2> /dev/null) if [ $? -ne 0 ] then echo \"ERR: el login $login no existe\" return $ERR_NOLOGIN fi #mostrar uid=$(echo $userLine | cut -d: -f3) gid=$(echo $userLine | cut -d: -f4) gecos=$(echo $userLine | cut -d: -f5) home=$(echo $userLine | cut -d: -f6) shell=$(echo $userLine | cut -d: -f7) echo \"uid: $uid\" echo \"gid: $gid\" echo \"gecos: $gecos\" echo \"home: $home\" echo \"shell: $shell\" return $OK }","title":"BashScripting"},{"location":"bash_scripting/#comandos-para-bash-scripting","text":"#! /bin/bash","title":"Comandos para Bash Scripting"},{"location":"bash_scripting/#validar-argumentos","text":"# indica el numero de argumentos pasados echo $# # si no tiene 2 args, plegar if [ $# -ne 2 ] then echo \"Num de args incorrecte\" echo \"USAGE: prog.sh arg1 arg2\" exit 1 fi # mostrar los args echo \"Los argumentos son $1 y $2\" exit 0","title":"validar argumentos"},{"location":"bash_scripting/#validar-help","text":"#help if [ $1 == \"--help\" -o $1 == \"-h\" ] then echo \"mostramos ayuda\" exit 0 fi","title":"validar help"},{"location":"bash_scripting/#comparadores","text":"-lt / -gt / -eq / -ne / -ge / -le m\u00e1s grande, menor que... -d / -f / -h directorio, file, link -n mientras sea nulo $? estatus level de error /dev/stderr / >>/dev/null if [ $# -eq 3 ] then if ! [ \"$1\" == \"-b\" -a \"$2\" == \"-a\" ] then echo \"ERROR: format args incorrecte\" echo \"USAGE: prog arg -h / prog -a arg / prog -b -a arg\" exit $ERR_NARGS fi fi","title":"comparadores"},{"location":"bash_scripting/#conficional-if","text":"edad=$1 echo $edad if [ $edad -lt 18 ] then echo \"Es menor de edat\" elif [ $edad -eq 18 ] then echo \"18 recien cumplidos\" else echo \"Ya es mayor de edad\" fi","title":"conficional if"},{"location":"bash_scripting/#bucle-for","text":"count=0 for arg in $* do count=$((count+1)) echo \"$count: $arg\" done exit 0","title":"bucle for"},{"location":"bash_scripting/#bucle-while","text":"cont=0 MAX=$1 while [ $cont -le $MAX ] do echo $cont cont=$((cont+1)) done exit 0","title":"bucle while"},{"location":"bash_scripting/#bucle-esac","text":"for mes in $* do case $mes in '2') echo \"$mes tiene 28 dias\";; '1'|'3'|'5'|'7'|'8'|'10'|'12') echo \"$mes tiene 31 dias\";; '2'|'4'|'6'|'9'|'11') echo \"$mes tiene 30 dias\";; *) echo \"$mes no es un mes correcto\" esac done exit 0","title":"bucle esac"},{"location":"bash_scripting/#leer-por-entrada-standard","text":"count=0 while read -r line do count=$((count+1)) echo \"$count: $line\" done exit 0 MAX=$1 cont=1 while read -r line && [ $cont -le $MAX ] do echo \"$cont: $line\" cont=$((cont+1)) done exit 0","title":"leer por entrada standard"},{"location":"bash_scripting/#separar-opciones-con-shift","text":"opciones='' argumentos='' numeros='' files='' while [ -n \"$1\" ] do case $1 in '-a') files=$2 shift;; '-c'|'-b'|'-e') opciones=\"$opciones $1\";; '-d') numeros=$2 shift;; *) argumentos=\"$argumentos $1\";; esac shift done echo \"opciones: $opciones\" echo \"argumentos: $argumentos\" echo \"numeros: $numeros\" echo \"files: $files\" exit 0","title":"separar opciones con shift"},{"location":"bash_scripting/#mirar-si-es-directorio-regular-file","text":"#files y dir a copiar llistafiles=$(echo $* | cut -d' ' -f1-$(($#-1))) dirdesti=$(echo $* | cut -d' ' -f$#) #comprobar que sea un directorio if ! [ -d $dirdesti ] then echo \"error, no es un dir desti correcto\" exit 2 fi # para cada file validada lo copiamos al dir for file in $llistafiles do if ! [ -f $file ] then echo \"error, no es un file\" >> /dev/stderr exit 3 fi cp $file $dirdesti/. done exit 0 for dir in $* do # miramos si es un help if [ $dir == \"--help\" -o $dir == \"-h\" ] then echo \"mostramos ayuda\" exit 0 fi # verificar que es un dir if ! [ -d $dir ] then echo \"error arg no es un dir\" echo \"USAGE: prog.sh arg[dir]\" exit 2 fi llistadir=$(ls $dir) count=1 for file in $llistadir do #de cada cosa que imprime decir si es un regular file, dir, link o altre cosa if [ -d $dir/$file ] then echo \"es un directorio\" echo \"$count: $file\" elif [ -f $dir/$file ] then echo \"es un file\" echo \"$count: $file\" elif [ -d $dir/$file ] then echo \"es una altra cosa\" echo \"$count: $file\" fi count=$((count+1)) done done exit 0","title":"mirar si es directorio, regular file..."},{"location":"bash_scripting/#mayusculas-copiar-buscar-ordenar","text":"tr echo \"hola\" | tr -s '[a-z]' '[A-Z]' echo \"hola\" | tr -s '[:blank:]' ' ' #'\\t' tabulador cut + cut -d' ' -f1-5 corta por campos y delimitador + cut -c1-50 corta por caracteres llistafiles=$(echo $ | cut -d' ' -f1-$(($#-1))) dirdesti=$(echo $ | cut -d' ' -f$#) uid=$(echo $loginLine | cut -d: -f3) grep/egrep + egrep \"^[^ ]{10,}\" busca de lo que se pase o line algo que tenga mas de 10 chars + echo $arg | egrep \".{4,}\" busca de lo que se pase que tenga mas de 4 chars + egrep \"^$user:\" /etc/passwd buscar el campo user del /etc/passwd + egrep \"^[^:] :[^:] :[^:]*:$gid:\" /etc/passwd + sort -u 2> /dev/null) ordenar unico y quita los repetidos + listshells=$(cut -d: -f7 /etc/passwd | sort -u 2> /dev/null)","title":"Mayusculas , copiar , buscar , ordenar"},{"location":"bash_scripting/#funciones","text":"function nombreFuncion(){ return xxxxx } function showUser(){ ERR_NARGS=1 ERR_NOLOGIN=2 OK=0 #validar args if [ $# -ne 1 ] then echo \"ERR: num args incorrecte\" echo \"USAGE: $0 login\" return $ERR_NARGS fi #validar si existe el login login=$1 userLine=$(egrep \"^$login:\" /etc/passwd 2> /dev/null) if [ $? -ne 0 ] then echo \"ERR: el login $login no existe\" return $ERR_NOLOGIN fi #mostrar uid=$(echo $userLine | cut -d: -f3) gid=$(echo $userLine | cut -d: -f4) gecos=$(echo $userLine | cut -d: -f5) home=$(echo $userLine | cut -d: -f6) shell=$(echo $userLine | cut -d: -f7) echo \"uid: $uid\" echo \"gid: $gid\" echo \"gecos: $gecos\" echo \"home: $home\" echo \"shell: $shell\" return $OK }","title":"Funciones"},{"location":"bbdd/","text":"BASES DE DATOS POSTGRESQL Crear database y conectarnos: create database diccionari; \\c diccionari; Crear tablas: create table exemplar_soci ( id_exemplar_soci serial primary key, id_exemplar int not null, id_soci int not null, foreign key (id_exemplar) references exemplars(id_exemplar), foreign key (id_soci) references socis(id_soci) ); create table exemplars ( id_exemplar serial primary key, id_volum int not null, num_exemplars int not null, foreign key (id_volum) references grup_volums(id_volum) ); create table obres ( id_obra serial primary key, nom_obra varchar(200) not null, data_publicacio date not null, descripcio varchar(500) not null, id_autor int not null, foreign key (id_autor) references autors(id_autor) ); create table socis ( id_soci serial primary key, nom_soci varchar(100) not null, cognom_soci varchar(200) not null, naixement date not null, localitat varchar(100) not null, unique(nom_soci, cognom_soci) ); Consulta simple: select * from paraules where paraula='casa' Consultas con comparaciones: training=# select objetivo, ventas, ciudad, region from oficinas where region='Este' order by ciudad; training=# select nombre, contrato from repventas where ventas>300000; training=# select nombre from repventas where director=104; training=# select nombre, contrato from repventas where contrato < '1988-1- 1'; training=# select id_fab, id_producto, descripcion from productos where id_fab like '%i'; training=# select id_fab, descripcion, (existencias*precio) as valor_inventario from productos; training=# select num_pedido, importe from pedidos where importe between 20000 and 29999; training=# select num_pedido, importe from pedidos where importe>=20000 and importe<=29999; training=# select id_fab, descripcion from productos where (id_fab='imm' and existencias>=200) or (id_fab='bic' and existencias>=50); training=# select empresa from clientes where (empresa not like '%Corp.%' or empresa not like '%Inc.%') and limite_credito>30000; practica1=# select nomalumne from alumnes where nomalumne like 'Ann_'; JOIN: training=# select ciudad, nombre, titulo from oficinas join repventas on dir=num_empl; training=# select ciudad, nombre, titulo from oficinas, repventas where dir=num_empl; training=# select num_pedido, descripcion from pedidos, productos where fab=id_fab and producto=id_producto; training=# select num_pedido, nombre, empresa from pedidos, clientes, repventas where clie=num_clie and rep=num_empl and importe>25000; training=# select treballador.nombre, treballador.cuota, dir.nombre, dir.cuota from repventas treballador, repventas dir where treballador.director=dir.num_empl and treballador.cuota>dir.cuota; LEFT/RIGHT JOIN + GROUP BY: > EJERCICIO ENTENDER JOIN Y JOIN LEFT/RIGHT **CODI_VENDEDOR, NOM_VENDEDOR, CODI_CAP, NOM_CAP, OFICINA, CIUTAT, CODI_CAPOFICINA, NOM_CAPOFICINA** > CON JOIN LEFT MANDA LA COLUMNA QUE QUEREMOS Y SALEN TODOS LOS CAMPOS AUNQUE HAYA NULL se ha de coger la tabla principal, ver las relaciones manualmente como si tuvieramos una al lado de otra. coger el campo central y ver como se relaciona con la otra tabla. si es la misma tabla se ha de ir haciendo copias de tablas con cada tabla con un nombre predefinido. SOLO CON JOIN TE SALDR\u00cdA SIN LOS NULL training=# select id_fab, sum(existencias) from productos where precio>54 group by id_fab having sum(existencias)>300; training=# select id_fab, id_producto, descripcion, sum(importe) from productos join pedidos on id_fab=fab and id_producto=producto where fecha_pedido>='01-01-89' and fecha_pedido<='12-31-89' group by id_fab, id_producto order by 4; training=# select id_fab, id_producto, descripcion, existencias, count(distinct clie) from productos join pedidos on id_fab=fab and id_producto=producto group by id_fab, id_producto order by 5 desc, 4 desc, 3 limit 5; training=# select oficina, ciudad, count(*) from oficinas right join repventas venedors on oficina=venedors.oficina_rep join pedidos on venedors.num_empl=rep group by oficina order by oficina; UNION: training=# select 'producto individual', id_fab, id_producto, descripcion, importe from productos join pedidos on id_fab=fab and id_producto=producto where descripcion ilike 'Bisagra%' or descripcion ilike 'Articulo%' union select 'total', id_fab, id_producto, descripcion, sum(importe) from productos join pedidos on id_fab=fab and id_producto=producto where descripcion ilike 'Bisagra%' or descripcion ilike 'Articulo%' group by id_fab, id_producto, descripcion order by 2,3,1; SUBQUERIES: training=# select id_fab, id_producto, descripcion, (select count(num_pedido) as num_comandes from pedidos where fab=id_fab and producto=id_producto), (select count(distinct clie) as clientes from pedidos where fab=id_fab and producto=id_producto), (select sum(importe) from pedidos where fab=id_fab and producto=id_producto) from productos where id_fab in (select fab from pedidos group by fab) or id_producto in (select producto from pedidos group by producto) or id_fab not in (select fab from pedidos group by fab) or id_producto not in (select producto from pedidos group by producto) order by 1,2; INSERT/UPDATE/DELETE: INSERT training=# insert into copia_repventas values (1012, 'Enric Jimenez', 99, 18, 'Dir Ventas', '2012-01-02', 101, 0, 0); training=# insert into copia_clientes (num_clie, empresa, rep_clie) values (3001, 'C2', 1013); training=# insert into copia_repventas values (1013, 'Pere Mendoza', null, null, null, '2011-08-15', null, null, 0); DELETE training=# delete from copia_pedidos where rep=102; training=# delete from copia_repventas where nombre='Enric Jimenez'; training=# delete from copia_pedidos where fecha_pedido<'1989-11-15'; training=# delete from copia_clientes where rep_clie=105 or rep_clie=109 or rep_clie=101; (rep_clie in (select num_empl from repventas where nombre like '%adams'); training=# delete from copia_repventas where contrato<'1988-07-01' and cuota is null; UPDATE training=# update copia_clientes set limite_credito=60000, rep_clie=109 where num_clie=2103; training=# update copia_clientes set limite_credito=60000, rep_clie=(select num_empl from repventas where nombre='Mary Jones') where empresa='Acme Mfg.'; training=# update copia_repventas set oficina_rep=11, cuota=cuota-cuota*0.10 where oficina_rep=12; training=# update copia_clientes set rep_clie=102 where rep_clie in (105,106,107); training=# update copia_repventas set cuota= cuota + cuota*0.05; training=# update copia_oficinas set objetivo=2*(select sum(ventas) from copia_repventas where oficina_rep=oficina) where objetivo<ventas; ALTER TABLE: alter table oficinas add constraint director_de_la_oficina foreign key (dir) references repventas(num_empl) on delete set null --si un rep desapareix, la oficina quedara temporalmente vacia on update cascade -- si un rep canvia de codi, canviara tambe el codi a la oficina ALTER TABLE copia_clientes ADD tel numeric(9,0) unique not null check (tel >=100000000 and tel<=999999999); ALTER TABLE copia_repventas ADD CHECK(edad>=18 and edad<=65); ALTER TABLE copia_repventas DROP titulo; alter table oficinas add constraint director_de_la_oficina foreign key (dir) references repventas(num_empl); alter table pedidos add constraint cliente_que_ha_hecho_pedido foreign (clie) references clientes(num_clie) add constraint rep_que_atendido_pedido foreign key (rep) references repventas(num_empl) add constraint producto_del_pedido foreign key (fab,producto) references productos(id_fab,id_producto); Crear funciones: CREATE FUNCTION suma (INTEGER,INTEGER) RETURNS INTEGER AS $$ BEGIN RETURN $1+$2; END; $$ LANGUAGE 'plpgsql'; -------------------------------------------------------------------------------- CREATE OR REPLACE FUNCTION hola (TEXT) RETURNS TEXT AS $$ BEGIN RETURN 'HOLA '|| $1; END; $$ LANGUAGE 'plpgsql'; -------------------------------------------------------------------------------- CREATE FUNCTION INS_ALUM() RETURNS VOID AS $$ INSERT INTO prova(a,b) VALUES (100,200); $$ LANGUAGE sql; -------------------------------------------------------------------------------- CREATE FUNCTION llista_Alum() RETURNS RECORD -- RECORD DEVUELVE UNA LISTA CON CAMPOS AS $$ -- SI QUEREMOS QUE DEVUELVA M\u00c1S \"RETURNS SETOF RECORD\" SELECT * FROM prova; $$ LANGUAGE sql; -------------------------------------------------------------------------------- CREATE OR REPLACE FUNCTION counter () RETURNS SETOF INTEGER AS $$ BEGIN FOR counter IN 1..10 LOOP RAISE NOTICE 'Counter: %', counter; END LOOP; END; $$ LANGUAGE 'plpgsql'; Crear triggers: CREATE OR REPLACE FUNCTION afegeix_audit() RETURNS TRIGGER AS $$ BEGIN IF (TG_OP = 'DELETE') THEN INSERT INTO auditoria VALUES (DEFAULT, CURRENT_TIMESTAMP, TG_TABLE_NAME, 'D', CURRENT_USER); RETURN OLD; ELSIF (TG_OP = 'UPDATE') THEN INSERT INTO auditoria VALUES (DEFAULT, CURRENT_TIMESTAMP, TG_TABLE_NAME, 'U', CURRENT_USER); RETURN NEW; ELSIF (TG_OP = 'INSERT') THEN INSERT INTO auditoria VALUES (DEFAULT, CURRENT_TIMESTAMP, TG_TABLE_NAME, 'I', CURRENT_USER); RETURN NEW; END IF; --Aqu\u00ed no hauria d'arribar-hi mai: RETURN NULL; END $$ LANGUAGE plpgsql; CREATE TRIGGER tauditresultats AFTER INSERT OR UPDATE OR DELETE ON resultats FOR EACH ROW EXECUTE PROCEDURE afegeix_audit(); CREATE TRIGGER tauditanalitiques AFTER INSERT OR UPDATE OR DELETE ON analitiques FOR EACH ROW EXECUTE PROCEDURE afegeix_audit(); Crear Squema y roles: --crear roles CREATE ROLE lc_consultar NOLOGIN; CREATE ROLE lc_inserir NOLOGIN; CREATE ROLE lc_admin NOLOGIN; --- --CREACION DE UN SCHEMA CREATE SCHEMA lcschema AUTHORIZATION postgres; --TODOS LOS SCHEMAS SE CREAN EN PUBLIC (PUBLIC-POSTGRES OWNER) REVOKE ALL PRIVILEGES ON SCHEMA lschema FROM public; -- todos los privilegios para los users: GRANT ALL PRIVILEGES ON SCHEMA lschema TO postgres, lc_admin; --privilegios para usar este schema para: GRANT USAGE ON SCHEMA lschema TO ROLE lc_consultar, lc_inserir, lc_admin; --s'hauria de crear un SCHEMA de lab_clinic i tamb\u00e9 fer aixo; GRANT USAGE ON SCHEMA lschema to lc_consultar, lc_inserir, lc_admin; GRANT CREATE ON SCHEMA lschema to lc_admin; --DAR LOS PRIVILEGIOS A CIERTOS USUARIOS ---para poder conectarse a la bbdd GRANT CONNECT ON DATABASE lab_clinic to lschema to lc_consultar, lc_inserir, lc_admin; ---para ver las tablas, y podra crear tablas y filas a su nombre GRANT SELECT ON ALL TABLES IN SCHEMA public TO lc_consultar; ---para poder ver y insertar (no borrar) GRANT SELECT, INSERT ON ALL TABLES IN SCHEMA public to lc_inserir; ---para poder insertar, tambien necesita permisos de inserir secuencias GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public to lc_inserir; ---para tener todos los privilegios en la bbdd GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public to lc_admin; --creamos usuarios, para poder tener roles se necesita LOGIN con create role postgres=# create user miguel password 'miguel'; CREATE ROLE --create role miguel login password 'miguel'; postgres=# create user walid password 'walid'; CREATE ROLE --asignar los roles a los usuarios GRANT lc_consultar to walid; GRANT lc_inserir to miguel; GRANT lc_admin to miguel with admin option; --permiso de superusuario postgres=# alter role miguel with superuser; ALTER ROLE --todos los privilegios en esta base de datos postgres=# grant all privileges on database lab_clinic to walid; GRANT --entrar a la bbdd como miguel [isx46410800@i05 ipc2019]$ su postgres Password: bash-4.4$ psql lab_clinic miguel; Password for user miguel: psql (9.6.10) Ver tiempos de ejecucion: explain analyse select * from paraulesraw where paraula = 'comparar/00'; Crear indices: create index index_paraula on paraulesraw using btree(paraula); `` PHPPGADMIN phpPgAdmin \u00e9s una aplicaci\u00f3 web que ens permet gestionar una BD Postgres SQL amb un entorn gr\u00e0fic. Existeix un an\u00e0leg per a MariaDB (o MySQL) anomenat phpMySql. El primer pas \u00e9s instal\u00b7lar l\u2019aplicaci\u00f3 al mateix ordinador que fa de servidor postgres. sudo dnf install phpPgAdmin Editant l'arxiu /var/lib/pgsql/data/pg_hba.conf i activant els m\u00e8todes d'autenticaci\u00f3 md5 ). Editar l\u2019arxiu /etc/phpPgAdmin/config.inc.php i posar a false la l\u00ednia: $conf['extra_login_security'] = true; // use 'localhost' for TCP/IP connection on this computer\\\\ $conf['servers'][0]['host'] = 'localhost'; Entrar: http://localhost/phpPgAdmin MARIADB Instalar: sudo dnf install mariadb mariadeb-server sudo systemctl start mariadb Crear database: create database instagram; Entrar a una bbdd: USE Nom_BD; Crear Usuario: create user 'miguel'@'localhost' identified by \"miguel14031993\"; Bloquear tablas: FLUSH TABLES WITH READ LOCK; UNLOCK TABLES; Agafem les dades del servidor mestre per replicar des d'aquest punt: show master status; Copiem la BD amb mydqldump: mysqldump -u root -p --routines --opt nomdb > db-dump.sql MONGODB Entrar: systemctl start mongod mongo Entrar bbdd: use database Ver bases: show databases Importar tablas: mongoimport --db foursquare --collection restaurants --file '/run/media/isx46410800/TOSHIBA EXT/HISX2/M10/UF2/json_dades_exemple/json/foursquare/restaurants.json' Entrar a una bbdd,tabla y ver algo: Database: imdb > use imdb switched to db imdb > db imdb > db.createCollection(\u201cmovies\u201d) {\u201cok\u201d: 1} > db.createCollection(\u201coscars\u201d) {\u201cok\u201d: 1} > db.createCollection(\u201cpeople\u201d) {\u201cok\u201d: 1} > show collections movies oscars people Consultas ejemplos: { \"_id\" : \"0000002\", \"name\" : \"Lauren Bacall\", \"dob\" : \"1924-9-16\", \"pob\" : \"New York, New York, USA\", \"hasActed\" : true } { \"_id\" : \"0000004\", \"name\" : \"John Belushi\", \"dob\" : \"1949-1-24\", \"pob\" : \"Chicago, Illinois, USA\", \"hasActed\" : true } db.people.find({hasActed: true, hasDirected: { $exists: false}}).pretty().count()->1909 { \"_id\" : 6, \"name\" : { \"first\" : \"Guido\", \"last\" : \"van Rossum\" }, \"birthYear\" : 1931, \"contribs\" : [ \"Python\" ], \"awards\" : [ { \"award\" : \"Award for the Advancement of Free Software\", \"year\" : 2001, \"by\" : \"Free Software Foundation\" }, { \"award\" : \"NLUUG Award\", \"year\" : 2003, \"by\" : \"NLUUG\" } ] } > db.bios.find({\"awards.year\" : 2001}).count() 3 Buscar las personas que haya obtenido un premio del tipo 'National Medal of' { \"_id\" : 7, \"name\" : { \"first\" : \"Dennis\", \"last\" : \"Ritchie\" }, \"birthYear\" : 1956, \"deathYear\" : 2011, \"contribs\" : [ \"UNIX\", \"C\" ], \"awards\" : [ { \"award\" : \"Turing Award\", \"year\" : 1983, \"by\" : \"ACM\" }, { \"award\" : \"National Medal of Technology\", \"year\" : 1998, \"by\" : \"United States\" }, { \"award\" : \"Japan Prize\", \"year\" : 2011, \"by\" : \"The Japan Prize Foundation\" } ] } > db.bios.find({ \"awards.award\" : /^National Medal of/}).pretty().count() 4 //6.- Buscar las personas de la colecci\u00f3n bios que destaquen en el terreno de Java, Ruby o Python (3) { \"_id\" : 9, \"name\" : { \"first\" : \"James\", \"last\" : \"Gosling\" }, \"birthYear\" : 1965, \"contribs\" : [ \"Java\" ], \"awards\" : [ { \"award\" : \"The Economist Innovation Award\", \"year\" : 2002, \"by\" : \"The Economist\" }, { \"award\" : \"Officer of the Order of Canada\", \"year\" : 2007, \"by\" : \"Canada\" } ] } > db.bios.find({ contribs : { $in: [ \"Java\", \"Ruby\", \"Python\" ] } }).pretty().count() 3 //9.- Buscar las personas de la colecci\u00f3n bios con 1 premio conseguido (1) { \"_id\" : 8, \"name\" : { \"first\" : \"Yukihiro\", \"aka\" : \"Matz\", \"last\" : \"Matsumoto\" }, \"birthYear\" : 1941, \"contribs\" : [ \"Ruby\" ], \"awards\" : [ { \"award\" : \"Award for the Advancement of Free Software\", \"year\" : \"2011\", \"by\" : \"Free Software Foundation\" } ] } #size sirve para que el tama\u00f1o del array de tal cosa sea la medida que indiquemos > db.bios.find({ awards : { $size: 1}}).pretty().count() 1 //10.- Buscar las personas de la colecci\u00f3n bios con 3 o m\u00e1s premios conseguidos (6) #que no tenga ni 2 ni 1 ni 0 ni no existe el campo > db.bios.find({ $nor: [ {awards: {$exists: false}}, {awards: {$size: 2}}, {awards: {$size: 1}}, {awards: {$size: 0}}]}).pretty().count() 6 #que tenga o 4 o 3 o 2 > db.bios.find({ $or: [ {awards: {$size: 4}}, {awards: {$size: 3}}, {awards: {$size: 2}}]}).pretty().count() 8 //1.- Buscar todos los libros con precio superior a 100 USD (7) #COMPRUEBO SI TODOS LOS PRECIOS SON EN USD > db.books.find().count() 333 > db.books.find({\"price.currency\": \"USD\"}).count() 333 > db.books.find({\"price.msrp\": {$gt: 100}}).pretty().count() 7 //3.- Buscar los libros que tengan el tag 'programming', 'agile' y \"java\" (5) #all para que salgan los 3 en los tags > db.books.find({tags: {$all : [\"programming\", \"agile\", \"java\"]}}).pretty().count() 5 //5.- Buscar los libros escritos por 3 autores (17) > db.books.find({author: {$size: 3}}).pretty().count() 17 Insertar varios: > db.stores.insertMany( [ { _id: 1, name: \"Java Hut\", description: \"Coffee and cakes\" }, { _id: 2, name: \"Burger Buns\", description: \"Gourmet hamburgers\" }, { _id: 3, name: \"Coffee Shop\", description: \"Just coffee\" }, { _id: 4, name: \"Clothes Clothes Clothes\", description: \"Discount clothing\" }, { _id: 5, name: \"Java Shopping\", description: \"Indonesian goods\" } ] ) Ver indices: > db.stores.getIndexes() Crear indices: db.stores.createIndex( { name: \"text\", description: \"text\" } ) Consulta una: > db.tweets.findOne() 2.1) Buscar quants twits tenim amb Obama President > db.tweets.find( { $text: { $search: \"Obama President\" } } ).count() 52 2.2) Buscar le textScore de cada twit amb Obama President > db.tweets.find({ $text: { $search: \"Obama President\" } }, { puntuacio: { $meta: \"textScore\" } }).sort( { puntuacio: { $meta: \"textScore\" } } ).pretty() - frase exacta :\"Yes we can\" > db.tweets.find( { $text: { $search: \"\\\"Yes we can\\\"\" } } ).count() 2 2.6) Busca les ciutats que estan a entre 20 i 50 km de Barcelona > db.cities.find({ \"loc\": { \"$near\": { \"$geometry\": { type: \"Point\" , coordinates: [2.15899, 41.38879]}, \"$maxDistance\": 50000, \"$minDistance\": 20000 } } }).count() 72 Update/delete/insert: Y los cambiamos por Miky > db.students.updateMany( { name: \"Mikel\" }, { $set: { name: \"Miky\" } }) Vemos cuantos usuarios tienen m\u00e1s de 50000 amigos: > db.tweets.find({ \"user.friends_count\" : { $gt: 50000}}).pretty().count() Incrementamos +1 a estos usuarios el contador de amigos: > db.tweets.updateMany({ \"user.friends_count\" : { $gt : 50000 }}, { $inc: { \"user.friends_count\" : +1}})","title":"Base de datos"},{"location":"bbdd/#bases-de-datos","text":"","title":"BASES DE DATOS"},{"location":"bbdd/#postgresql","text":"Crear database y conectarnos: create database diccionari; \\c diccionari; Crear tablas: create table exemplar_soci ( id_exemplar_soci serial primary key, id_exemplar int not null, id_soci int not null, foreign key (id_exemplar) references exemplars(id_exemplar), foreign key (id_soci) references socis(id_soci) ); create table exemplars ( id_exemplar serial primary key, id_volum int not null, num_exemplars int not null, foreign key (id_volum) references grup_volums(id_volum) ); create table obres ( id_obra serial primary key, nom_obra varchar(200) not null, data_publicacio date not null, descripcio varchar(500) not null, id_autor int not null, foreign key (id_autor) references autors(id_autor) ); create table socis ( id_soci serial primary key, nom_soci varchar(100) not null, cognom_soci varchar(200) not null, naixement date not null, localitat varchar(100) not null, unique(nom_soci, cognom_soci) ); Consulta simple: select * from paraules where paraula='casa' Consultas con comparaciones: training=# select objetivo, ventas, ciudad, region from oficinas where region='Este' order by ciudad; training=# select nombre, contrato from repventas where ventas>300000; training=# select nombre from repventas where director=104; training=# select nombre, contrato from repventas where contrato < '1988-1- 1'; training=# select id_fab, id_producto, descripcion from productos where id_fab like '%i'; training=# select id_fab, descripcion, (existencias*precio) as valor_inventario from productos; training=# select num_pedido, importe from pedidos where importe between 20000 and 29999; training=# select num_pedido, importe from pedidos where importe>=20000 and importe<=29999; training=# select id_fab, descripcion from productos where (id_fab='imm' and existencias>=200) or (id_fab='bic' and existencias>=50); training=# select empresa from clientes where (empresa not like '%Corp.%' or empresa not like '%Inc.%') and limite_credito>30000; practica1=# select nomalumne from alumnes where nomalumne like 'Ann_'; JOIN: training=# select ciudad, nombre, titulo from oficinas join repventas on dir=num_empl; training=# select ciudad, nombre, titulo from oficinas, repventas where dir=num_empl; training=# select num_pedido, descripcion from pedidos, productos where fab=id_fab and producto=id_producto; training=# select num_pedido, nombre, empresa from pedidos, clientes, repventas where clie=num_clie and rep=num_empl and importe>25000; training=# select treballador.nombre, treballador.cuota, dir.nombre, dir.cuota from repventas treballador, repventas dir where treballador.director=dir.num_empl and treballador.cuota>dir.cuota; LEFT/RIGHT JOIN + GROUP BY: > EJERCICIO ENTENDER JOIN Y JOIN LEFT/RIGHT **CODI_VENDEDOR, NOM_VENDEDOR, CODI_CAP, NOM_CAP, OFICINA, CIUTAT, CODI_CAPOFICINA, NOM_CAPOFICINA** > CON JOIN LEFT MANDA LA COLUMNA QUE QUEREMOS Y SALEN TODOS LOS CAMPOS AUNQUE HAYA NULL se ha de coger la tabla principal, ver las relaciones manualmente como si tuvieramos una al lado de otra. coger el campo central y ver como se relaciona con la otra tabla. si es la misma tabla se ha de ir haciendo copias de tablas con cada tabla con un nombre predefinido. SOLO CON JOIN TE SALDR\u00cdA SIN LOS NULL training=# select id_fab, sum(existencias) from productos where precio>54 group by id_fab having sum(existencias)>300; training=# select id_fab, id_producto, descripcion, sum(importe) from productos join pedidos on id_fab=fab and id_producto=producto where fecha_pedido>='01-01-89' and fecha_pedido<='12-31-89' group by id_fab, id_producto order by 4; training=# select id_fab, id_producto, descripcion, existencias, count(distinct clie) from productos join pedidos on id_fab=fab and id_producto=producto group by id_fab, id_producto order by 5 desc, 4 desc, 3 limit 5; training=# select oficina, ciudad, count(*) from oficinas right join repventas venedors on oficina=venedors.oficina_rep join pedidos on venedors.num_empl=rep group by oficina order by oficina; UNION: training=# select 'producto individual', id_fab, id_producto, descripcion, importe from productos join pedidos on id_fab=fab and id_producto=producto where descripcion ilike 'Bisagra%' or descripcion ilike 'Articulo%' union select 'total', id_fab, id_producto, descripcion, sum(importe) from productos join pedidos on id_fab=fab and id_producto=producto where descripcion ilike 'Bisagra%' or descripcion ilike 'Articulo%' group by id_fab, id_producto, descripcion order by 2,3,1; SUBQUERIES: training=# select id_fab, id_producto, descripcion, (select count(num_pedido) as num_comandes from pedidos where fab=id_fab and producto=id_producto), (select count(distinct clie) as clientes from pedidos where fab=id_fab and producto=id_producto), (select sum(importe) from pedidos where fab=id_fab and producto=id_producto) from productos where id_fab in (select fab from pedidos group by fab) or id_producto in (select producto from pedidos group by producto) or id_fab not in (select fab from pedidos group by fab) or id_producto not in (select producto from pedidos group by producto) order by 1,2; INSERT/UPDATE/DELETE: INSERT training=# insert into copia_repventas values (1012, 'Enric Jimenez', 99, 18, 'Dir Ventas', '2012-01-02', 101, 0, 0); training=# insert into copia_clientes (num_clie, empresa, rep_clie) values (3001, 'C2', 1013); training=# insert into copia_repventas values (1013, 'Pere Mendoza', null, null, null, '2011-08-15', null, null, 0); DELETE training=# delete from copia_pedidos where rep=102; training=# delete from copia_repventas where nombre='Enric Jimenez'; training=# delete from copia_pedidos where fecha_pedido<'1989-11-15'; training=# delete from copia_clientes where rep_clie=105 or rep_clie=109 or rep_clie=101; (rep_clie in (select num_empl from repventas where nombre like '%adams'); training=# delete from copia_repventas where contrato<'1988-07-01' and cuota is null; UPDATE training=# update copia_clientes set limite_credito=60000, rep_clie=109 where num_clie=2103; training=# update copia_clientes set limite_credito=60000, rep_clie=(select num_empl from repventas where nombre='Mary Jones') where empresa='Acme Mfg.'; training=# update copia_repventas set oficina_rep=11, cuota=cuota-cuota*0.10 where oficina_rep=12; training=# update copia_clientes set rep_clie=102 where rep_clie in (105,106,107); training=# update copia_repventas set cuota= cuota + cuota*0.05; training=# update copia_oficinas set objetivo=2*(select sum(ventas) from copia_repventas where oficina_rep=oficina) where objetivo<ventas; ALTER TABLE: alter table oficinas add constraint director_de_la_oficina foreign key (dir) references repventas(num_empl) on delete set null --si un rep desapareix, la oficina quedara temporalmente vacia on update cascade -- si un rep canvia de codi, canviara tambe el codi a la oficina ALTER TABLE copia_clientes ADD tel numeric(9,0) unique not null check (tel >=100000000 and tel<=999999999); ALTER TABLE copia_repventas ADD CHECK(edad>=18 and edad<=65); ALTER TABLE copia_repventas DROP titulo; alter table oficinas add constraint director_de_la_oficina foreign key (dir) references repventas(num_empl); alter table pedidos add constraint cliente_que_ha_hecho_pedido foreign (clie) references clientes(num_clie) add constraint rep_que_atendido_pedido foreign key (rep) references repventas(num_empl) add constraint producto_del_pedido foreign key (fab,producto) references productos(id_fab,id_producto); Crear funciones: CREATE FUNCTION suma (INTEGER,INTEGER) RETURNS INTEGER AS $$ BEGIN RETURN $1+$2; END; $$ LANGUAGE 'plpgsql'; -------------------------------------------------------------------------------- CREATE OR REPLACE FUNCTION hola (TEXT) RETURNS TEXT AS $$ BEGIN RETURN 'HOLA '|| $1; END; $$ LANGUAGE 'plpgsql'; -------------------------------------------------------------------------------- CREATE FUNCTION INS_ALUM() RETURNS VOID AS $$ INSERT INTO prova(a,b) VALUES (100,200); $$ LANGUAGE sql; -------------------------------------------------------------------------------- CREATE FUNCTION llista_Alum() RETURNS RECORD -- RECORD DEVUELVE UNA LISTA CON CAMPOS AS $$ -- SI QUEREMOS QUE DEVUELVA M\u00c1S \"RETURNS SETOF RECORD\" SELECT * FROM prova; $$ LANGUAGE sql; -------------------------------------------------------------------------------- CREATE OR REPLACE FUNCTION counter () RETURNS SETOF INTEGER AS $$ BEGIN FOR counter IN 1..10 LOOP RAISE NOTICE 'Counter: %', counter; END LOOP; END; $$ LANGUAGE 'plpgsql'; Crear triggers: CREATE OR REPLACE FUNCTION afegeix_audit() RETURNS TRIGGER AS $$ BEGIN IF (TG_OP = 'DELETE') THEN INSERT INTO auditoria VALUES (DEFAULT, CURRENT_TIMESTAMP, TG_TABLE_NAME, 'D', CURRENT_USER); RETURN OLD; ELSIF (TG_OP = 'UPDATE') THEN INSERT INTO auditoria VALUES (DEFAULT, CURRENT_TIMESTAMP, TG_TABLE_NAME, 'U', CURRENT_USER); RETURN NEW; ELSIF (TG_OP = 'INSERT') THEN INSERT INTO auditoria VALUES (DEFAULT, CURRENT_TIMESTAMP, TG_TABLE_NAME, 'I', CURRENT_USER); RETURN NEW; END IF; --Aqu\u00ed no hauria d'arribar-hi mai: RETURN NULL; END $$ LANGUAGE plpgsql; CREATE TRIGGER tauditresultats AFTER INSERT OR UPDATE OR DELETE ON resultats FOR EACH ROW EXECUTE PROCEDURE afegeix_audit(); CREATE TRIGGER tauditanalitiques AFTER INSERT OR UPDATE OR DELETE ON analitiques FOR EACH ROW EXECUTE PROCEDURE afegeix_audit(); Crear Squema y roles: --crear roles CREATE ROLE lc_consultar NOLOGIN; CREATE ROLE lc_inserir NOLOGIN; CREATE ROLE lc_admin NOLOGIN; --- --CREACION DE UN SCHEMA CREATE SCHEMA lcschema AUTHORIZATION postgres; --TODOS LOS SCHEMAS SE CREAN EN PUBLIC (PUBLIC-POSTGRES OWNER) REVOKE ALL PRIVILEGES ON SCHEMA lschema FROM public; -- todos los privilegios para los users: GRANT ALL PRIVILEGES ON SCHEMA lschema TO postgres, lc_admin; --privilegios para usar este schema para: GRANT USAGE ON SCHEMA lschema TO ROLE lc_consultar, lc_inserir, lc_admin; --s'hauria de crear un SCHEMA de lab_clinic i tamb\u00e9 fer aixo; GRANT USAGE ON SCHEMA lschema to lc_consultar, lc_inserir, lc_admin; GRANT CREATE ON SCHEMA lschema to lc_admin; --DAR LOS PRIVILEGIOS A CIERTOS USUARIOS ---para poder conectarse a la bbdd GRANT CONNECT ON DATABASE lab_clinic to lschema to lc_consultar, lc_inserir, lc_admin; ---para ver las tablas, y podra crear tablas y filas a su nombre GRANT SELECT ON ALL TABLES IN SCHEMA public TO lc_consultar; ---para poder ver y insertar (no borrar) GRANT SELECT, INSERT ON ALL TABLES IN SCHEMA public to lc_inserir; ---para poder insertar, tambien necesita permisos de inserir secuencias GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public to lc_inserir; ---para tener todos los privilegios en la bbdd GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public to lc_admin; --creamos usuarios, para poder tener roles se necesita LOGIN con create role postgres=# create user miguel password 'miguel'; CREATE ROLE --create role miguel login password 'miguel'; postgres=# create user walid password 'walid'; CREATE ROLE --asignar los roles a los usuarios GRANT lc_consultar to walid; GRANT lc_inserir to miguel; GRANT lc_admin to miguel with admin option; --permiso de superusuario postgres=# alter role miguel with superuser; ALTER ROLE --todos los privilegios en esta base de datos postgres=# grant all privileges on database lab_clinic to walid; GRANT --entrar a la bbdd como miguel [isx46410800@i05 ipc2019]$ su postgres Password: bash-4.4$ psql lab_clinic miguel; Password for user miguel: psql (9.6.10) Ver tiempos de ejecucion: explain analyse select * from paraulesraw where paraula = 'comparar/00'; Crear indices: create index index_paraula on paraulesraw using btree(paraula); ``","title":"POSTGRESQL"},{"location":"bbdd/#phppgadmin","text":"phpPgAdmin \u00e9s una aplicaci\u00f3 web que ens permet gestionar una BD Postgres SQL amb un entorn gr\u00e0fic. Existeix un an\u00e0leg per a MariaDB (o MySQL) anomenat phpMySql. El primer pas \u00e9s instal\u00b7lar l\u2019aplicaci\u00f3 al mateix ordinador que fa de servidor postgres. sudo dnf install phpPgAdmin Editant l'arxiu /var/lib/pgsql/data/pg_hba.conf i activant els m\u00e8todes d'autenticaci\u00f3 md5 ). Editar l\u2019arxiu /etc/phpPgAdmin/config.inc.php i posar a false la l\u00ednia: $conf['extra_login_security'] = true; // use 'localhost' for TCP/IP connection on this computer\\\\ $conf['servers'][0]['host'] = 'localhost'; Entrar: http://localhost/phpPgAdmin","title":"PHPPGADMIN"},{"location":"bbdd/#mariadb","text":"Instalar: sudo dnf install mariadb mariadeb-server sudo systemctl start mariadb Crear database: create database instagram; Entrar a una bbdd: USE Nom_BD; Crear Usuario: create user 'miguel'@'localhost' identified by \"miguel14031993\"; Bloquear tablas: FLUSH TABLES WITH READ LOCK; UNLOCK TABLES; Agafem les dades del servidor mestre per replicar des d'aquest punt: show master status; Copiem la BD amb mydqldump: mysqldump -u root -p --routines --opt nomdb > db-dump.sql","title":"MARIADB"},{"location":"bbdd/#mongodb","text":"Entrar: systemctl start mongod mongo Entrar bbdd: use database Ver bases: show databases Importar tablas: mongoimport --db foursquare --collection restaurants --file '/run/media/isx46410800/TOSHIBA EXT/HISX2/M10/UF2/json_dades_exemple/json/foursquare/restaurants.json' Entrar a una bbdd,tabla y ver algo: Database: imdb > use imdb switched to db imdb > db imdb > db.createCollection(\u201cmovies\u201d) {\u201cok\u201d: 1} > db.createCollection(\u201coscars\u201d) {\u201cok\u201d: 1} > db.createCollection(\u201cpeople\u201d) {\u201cok\u201d: 1} > show collections movies oscars people Consultas ejemplos: { \"_id\" : \"0000002\", \"name\" : \"Lauren Bacall\", \"dob\" : \"1924-9-16\", \"pob\" : \"New York, New York, USA\", \"hasActed\" : true } { \"_id\" : \"0000004\", \"name\" : \"John Belushi\", \"dob\" : \"1949-1-24\", \"pob\" : \"Chicago, Illinois, USA\", \"hasActed\" : true } db.people.find({hasActed: true, hasDirected: { $exists: false}}).pretty().count()->1909 { \"_id\" : 6, \"name\" : { \"first\" : \"Guido\", \"last\" : \"van Rossum\" }, \"birthYear\" : 1931, \"contribs\" : [ \"Python\" ], \"awards\" : [ { \"award\" : \"Award for the Advancement of Free Software\", \"year\" : 2001, \"by\" : \"Free Software Foundation\" }, { \"award\" : \"NLUUG Award\", \"year\" : 2003, \"by\" : \"NLUUG\" } ] } > db.bios.find({\"awards.year\" : 2001}).count() 3 Buscar las personas que haya obtenido un premio del tipo 'National Medal of' { \"_id\" : 7, \"name\" : { \"first\" : \"Dennis\", \"last\" : \"Ritchie\" }, \"birthYear\" : 1956, \"deathYear\" : 2011, \"contribs\" : [ \"UNIX\", \"C\" ], \"awards\" : [ { \"award\" : \"Turing Award\", \"year\" : 1983, \"by\" : \"ACM\" }, { \"award\" : \"National Medal of Technology\", \"year\" : 1998, \"by\" : \"United States\" }, { \"award\" : \"Japan Prize\", \"year\" : 2011, \"by\" : \"The Japan Prize Foundation\" } ] } > db.bios.find({ \"awards.award\" : /^National Medal of/}).pretty().count() 4 //6.- Buscar las personas de la colecci\u00f3n bios que destaquen en el terreno de Java, Ruby o Python (3) { \"_id\" : 9, \"name\" : { \"first\" : \"James\", \"last\" : \"Gosling\" }, \"birthYear\" : 1965, \"contribs\" : [ \"Java\" ], \"awards\" : [ { \"award\" : \"The Economist Innovation Award\", \"year\" : 2002, \"by\" : \"The Economist\" }, { \"award\" : \"Officer of the Order of Canada\", \"year\" : 2007, \"by\" : \"Canada\" } ] } > db.bios.find({ contribs : { $in: [ \"Java\", \"Ruby\", \"Python\" ] } }).pretty().count() 3 //9.- Buscar las personas de la colecci\u00f3n bios con 1 premio conseguido (1) { \"_id\" : 8, \"name\" : { \"first\" : \"Yukihiro\", \"aka\" : \"Matz\", \"last\" : \"Matsumoto\" }, \"birthYear\" : 1941, \"contribs\" : [ \"Ruby\" ], \"awards\" : [ { \"award\" : \"Award for the Advancement of Free Software\", \"year\" : \"2011\", \"by\" : \"Free Software Foundation\" } ] } #size sirve para que el tama\u00f1o del array de tal cosa sea la medida que indiquemos > db.bios.find({ awards : { $size: 1}}).pretty().count() 1 //10.- Buscar las personas de la colecci\u00f3n bios con 3 o m\u00e1s premios conseguidos (6) #que no tenga ni 2 ni 1 ni 0 ni no existe el campo > db.bios.find({ $nor: [ {awards: {$exists: false}}, {awards: {$size: 2}}, {awards: {$size: 1}}, {awards: {$size: 0}}]}).pretty().count() 6 #que tenga o 4 o 3 o 2 > db.bios.find({ $or: [ {awards: {$size: 4}}, {awards: {$size: 3}}, {awards: {$size: 2}}]}).pretty().count() 8 //1.- Buscar todos los libros con precio superior a 100 USD (7) #COMPRUEBO SI TODOS LOS PRECIOS SON EN USD > db.books.find().count() 333 > db.books.find({\"price.currency\": \"USD\"}).count() 333 > db.books.find({\"price.msrp\": {$gt: 100}}).pretty().count() 7 //3.- Buscar los libros que tengan el tag 'programming', 'agile' y \"java\" (5) #all para que salgan los 3 en los tags > db.books.find({tags: {$all : [\"programming\", \"agile\", \"java\"]}}).pretty().count() 5 //5.- Buscar los libros escritos por 3 autores (17) > db.books.find({author: {$size: 3}}).pretty().count() 17 Insertar varios: > db.stores.insertMany( [ { _id: 1, name: \"Java Hut\", description: \"Coffee and cakes\" }, { _id: 2, name: \"Burger Buns\", description: \"Gourmet hamburgers\" }, { _id: 3, name: \"Coffee Shop\", description: \"Just coffee\" }, { _id: 4, name: \"Clothes Clothes Clothes\", description: \"Discount clothing\" }, { _id: 5, name: \"Java Shopping\", description: \"Indonesian goods\" } ] ) Ver indices: > db.stores.getIndexes() Crear indices: db.stores.createIndex( { name: \"text\", description: \"text\" } ) Consulta una: > db.tweets.findOne() 2.1) Buscar quants twits tenim amb Obama President > db.tweets.find( { $text: { $search: \"Obama President\" } } ).count() 52 2.2) Buscar le textScore de cada twit amb Obama President > db.tweets.find({ $text: { $search: \"Obama President\" } }, { puntuacio: { $meta: \"textScore\" } }).sort( { puntuacio: { $meta: \"textScore\" } } ).pretty() - frase exacta :\"Yes we can\" > db.tweets.find( { $text: { $search: \"\\\"Yes we can\\\"\" } } ).count() 2 2.6) Busca les ciutats que estan a entre 20 i 50 km de Barcelona > db.cities.find({ \"loc\": { \"$near\": { \"$geometry\": { type: \"Point\" , coordinates: [2.15899, 41.38879]}, \"$maxDistance\": 50000, \"$minDistance\": 20000 } } }).count() 72 Update/delete/insert: Y los cambiamos por Miky > db.students.updateMany( { name: \"Mikel\" }, { $set: { name: \"Miky\" } }) Vemos cuantos usuarios tienen m\u00e1s de 50000 amigos: > db.tweets.find({ \"user.friends_count\" : { $gt: 50000}}).pretty().count() Incrementamos +1 a estos usuarios el contador de amigos: > db.tweets.updateMany({ \"user.friends_count\" : { $gt : 50000 }}, { $inc: { \"user.friends_count\" : +1}})","title":"MONGODB"},{"location":"docker/","text":"DOCKER INSTALACI\u00d3N Instalar Docker: $ sudo dnf remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine $ sudo dnf -y install dnf-plugins-core $ sudo dnf config-manager \\ --add-repo \\ https://download.docker.com/linux/fedora/docker-ce.repo $ sudo dnf install docker-ce docker-ce-cli containerd.io $ sudo systemctl start docker $ sudo docker run hello-world COMANDOS Crear un container Docker: docker run --rm -it fedora:27//isx46410800/netcat:latest /bin/bash docker run --rm --name ldap -h ldap -d imagen Descagar una imagen: docker pull fedora:27/imagen Ver imagenes de mi sistema: docker images Iniciar un container: docker start container Entrar dentro de un container en otra terminal: docker exec -it nomcontainer /bin/bash Entrar dentro de un container en detached: docker attach container Procesos de docker: docker ps -a docker top container \u00daltimo container creado: docker ps -l Document Root: docker info | grep -i root Memoria y cpu limitada y variables de entorno: docker run -m \"MB\" --cpuset-cpus 0-1 -e \"NAME=miguel\" Iniciar un container: docker start/stop IDcontainer Cambiar nombre container: docker rename IDcontainer NuevoNombre Borrar varias cosas: docker rm $(docker ps -aq) Docker version: docker version Info de un docker: docker info Lista de containers: docker container ls -a Borrar una imagen: docker rmi imagen Borrar un container: docker rm container Cambiar etiqueta de un container: docker tag imagen nombreNuevo:tag Borrar imagenes none: docker images -f dangling=true | xargs docker rmi Crear y subir una imagen a DockerHub: docker login docker tag imagen nuevoimagen:tag docker push nuevoimagen:tag Copiar un fichero a fuera del docker o dentro: docker cp file container:/opt/docker/. docker cp container:/opt/docker/. file Docker con puerto mapeado para el exterior: docker run --rm --name ldap -h ldap -p 389:389 -p 80:80 -it isx/ldap /bin/bash -p puertoMiMaquina:puertoContenedor -x dirActivo dentro del container Redes en Docker: docker network create NameRed docker network rm NameRed docker network inspect NameRed/container docker network create --subnet 172.19.0.0/16 NameRed Volumes en Docker: docker volume create NOMBREVOLUMEN docker volume ls docker volume inspect NOMVOLUMEN ls /var/lib/docker/volumes --privileged -v volumen:contenido docker run --rm --name ldap -h ldap -v NOMVOLUMEN:/var/lib/sambaloQueGuarda --privileged -it isx/ldap /bin/bash Docker Compose: docker-compose up #enciende todos los dockers del file compose.yml docker-compose -f fileCompose.yml up (-d) #elegimos que fichero encendemos del compose docker-compose down #apaga todo docker-compose ps docker-compose images docker-compose top nom_servei docker-compose port ldap 389 #servicio y puerto elegido docker-compose push/pull #subir o bajar images docker-compose logs ldap #logs del servicio elegido docker-compose pause/unpause ldap #pausar el servicio docker-compose start/stop ldap #iniciar servicio docker-compose scale ldap=2 #dos container ldap Docker SWARM: docker swarm init #inicia el docker swarm docker node ls # lista de nodos del swarm docker swarm join-tocken manager/worker #une workers o manager docker stack deploy -c docker_compose.yml nombreAPP #hace deploy docker stack ps NombreAPP #procesos docker stack ls #listado docker stack services nombreAPP #servicios docker stack rm NombreAPP #parar docker service ls docker service ps nombreservicio docker service inspect nomservicio docker service scale nomservicio=3 docker swarm leave --force #se desune del swarm docker swarm init --advertise-addr IP docker node update --label-add tipus=valor nomNode docker node inspect nomNode docker node update --availability active/drain/pause nomNode ARQUITECTURA Docker Host es el servidor f\u00edsico/real donde se encuentra instalado Docker. Docker servicio: Docker Client. Rest API: es el intermediario encargado de comunicar al Docker client con el Docker server. Docker Server. Arquitectura Imagen docker (Dockerfile): Capa 1 - From: Sistema operativo minimo a elegir. Capa 2 - Run: lo que se quiera instalar, ejemplo apache. Capa 3 - CMD: lo que se tiene que poner para que cuando se arranque la imagen empiece con ese comando. Normalmente la activaci\u00f3n de un servicio en detached. SON CAPAS DE SOLO LECTURA Y NO SE PUEDE MODIFICAR NI BORRAR FROM centos:7 RUN yum install -y httpd CMD[\"apachectl\",\"-DFOREGROUND\"] Contenedor es una capa addicional en tiempo real de ejecuci\u00f3n, el empaquetado de todo el dockerfile. CAPA DE ESCRITURA. Recuerda que la capa del contenedor es temporal y que al eliminar el contenedor, todo lo que haya dentro de ella desaparecer\u00e1. Se diferencia de una m\u00e1quina virtual es que un contenedor es como un proceso m\u00e1s del sistema mientras que una MV hay que bajarse una ISO, instalar y agregar RAM, CPU y HD de nuestra propia m\u00e1quina real. DOCKER IMAGES Poniendo docker + SistemaOperativo podemos adquirir im\u00e1genes oficiales de los propios creadores para poder descargar del repositorio de DockerHub para nuestros contenedores. Por defecto, sino podemos un tag a la distribuci\u00f3n, nos coger\u00e1 el tag latest sino tendremos que poner la versi\u00f3n concreta como docker pull mongo:3.6-jessie . Se actualiza el tag si te bajas una imagen pero est\u00e1 recientemente actualizada y la antigua se queda en none . Vemos las im\u00e1genes con: docker images DOCKERFILE El fichero para crear nuestra imagen Docker se llama Dockerfile . Para construir la imagen es docker build -t/--tag imagen:tag . \u00f3 -f /rutaDockerfile .: docker build -t isx46410800/centos:inicial . Si modificamos algo del Dockerfile, hay que volver hacer el comando anterior. docker build -t isx46410800/centos:detached images/centos/. Ver el historial de construcci\u00f3n de capas de mi imagen: docker history -H imagen:tag Borrar una imagen: docker rmi idImagen Borrar un contenedor: docker rm contenedorName Ver los contenedores: docker ps / docker ps -a COMANDOS DOCKERFILE: FROM: desde donde se baja la imagen de SO. RUN: para instalar paquetes. COPY: copia ficheros de fuera hacia el container, ponemos ruta absoluta o del directorio actual. ADD: lo mismo que copy pero se puede pasar URLs y copiar\u00eda la info de la url a donde indiquemos. ENV: crea variable de entorno. WORKDIR: directorio activo al entrar. LABEL: es una etiqueta que puede ir en cualquier sitio, son informativas, es metadata. USER: quien ejecuta la tarea, por defecto es root. EXPOSE: puertos por donde escucha y puedes indicar qu\u00e9 puertos va funcionar mi contenedor. VOLUME: indica donde metemos la data cuando el container se muere. CMD: comando por el cual se ejecuta el container, normalmente un servicio detached CMD [\"apachectl\", \"-DFOREGORUND\"] . Ejemplo Dockerfile: # De que sistema operativo partimos FROM centos:7 # Labels de metadata extra LABEL author=\"Miguel Amor\u00f3s\" LABEL description=\"Mi primer container con Dockerfile\" # Que paquetes a instalar RUN yum install -y httpd # Creamos variables de entorno ENV saludo \"Hola Miguel\" # Directorio activo WORKDIR /var/www/html # Copiamos un fichero de fuera COPY ./listaCompra.txt ~/listaCompra.txt # Prueba de la variable RUN echo \"$saludo\" > ~/saludo.txt # Usuario que ejecuta la tarea RUN echo \"$(whoami)\" > ~/user1.txt RUN useradd miguel RUN useradd miguelito RUN echo \"miguel\" | passwd --stdin miguel RUN echo \"miguelito\" | passwd --stdin miguelito RUN chown miguel /var/www/html USER miguel RUN echo \"$(whoami)\" > ~/user2.txt USER root # Volumen para meter la chicha de cuando se muere el container VOLUME /tmp/ # Como arrancar el container CMD [\"apachectl\", \"-DFOREGROUND\"] Podemos usar un fichero .dockerignore para ignorar ficheros que no queremos que copiemos en el container. Para ver cualquier CMD para dejar por ejemplo un servicio encendido en detached se usa el comando: docker history -h SO / en docker hub Buenas pr\u00e1cticas, cuantas menos lineas de codigo, menos capas se utilizan al construir la imagen: RUN \\ useradd miguel && \\ useradd miguelito CMD VS ENTRYPOINT CMD : Este comando se encarga de pasar valores por defecto a un contenedor. Entre estos valores se pueden pasar ejecutables. Este comando tiene tres posibles formas de pasar los par\u00e1metros: CMD [\u201cparametro1\u201d, \u201cparametro2\u201d, \u2026.] CMD [\"apachectl\", \"-DFOREGORUND\"] ENTRYPOINT : Este comando se ejecuta cuando se quiere ejecutar un ejecutable en el contenedor en su arranque. Los ejemplos tipo de su uso, son cuando se quiere levantar un servidor web, una base de datos, etc \u2026. ENTRYPOINT comando parametro1 parametro2 ENTRYPOINT cal 2020 ENTRYPOINT cal # Y pasar por comando los par\u00e1metros Como se ha comentado anteriormente el comando CMD se puede utilizar para pasar par\u00e1metros al comando ENRYPOINT. Una posible forma de realizarlo es: ENTRYPOINT [\"cal\"] CMD [\"2020\"] CENTOS-PHP-SSL Crear unaas llaves para certificado SSL: openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout dockerssl.key -out dockerssl.crt Ponemos de commom name localhost Dockerfile: # SO FROM centos:7 # paquetes de apache php y ssl RUN \\ yum -y install httpd php php-cli php-commom mod_ssl openssl # dir creado RUN mkdir /opt/docker # indice de comprobacion de php RUN echo \"<?php phpinfo(); ?>\" > /var/www/html/hola.php # web de prueba COPY startbootstrap /var/www/html # conf del ssl en el fichero de apache de conf COPY ssl.conf /etc/httpd/conf.d/default.conf # copia de certificados y startup COPY dockerssl.crt /opt/docker/dockerssl.crt COPY dockerssl.key /opt/docker/dockerssl.key COPY startup.sh /opt/docker/startup.sh # permisos del startup RUN chmod +x /opt/docker/startup.sh # escuchar puerto 443 EXPOSE 443 # arranque CMD [\"/opt/docker/startup.sh\"] Podemos eliminar imagenes none con el comando: docker images -f dangling=true | xargs docker rmi NGINX-PHP Dockerfile: # SO FROM centos:7 # copiar el repo de nginx COPY nginx.repo /etc/yum.repos.d/nginx.repo # instalar paquetes RUN \\ yum -y install nginx --enablerepo=nginx && \\ yum -y install https://repo.ius.io/ius-release-el7.rpm && \\ yum -y install \\ php71u-fpm \\ php71u-mysqlnd \\ php71u-soap \\ php71u-xml \\ php71u-zip \\ php71u-jason \\ php71u-mcrypt \\ php71u-mbstring \\ php71u-zip \\ php71u-gd \\ --enablerepo=ius-archive && yum clean all # dir RUN mkdir /opt/docker # puertos escuchando EXPOSE 80 443 # volumenes VOLUME /var/www/html /var/log/nginx /var/log/php-fpm /var/lib/php-fpm # copiamos files de conf COPY index.php /var/www/html/index.php COPY nginx.conf /etc/nginx/conf.d/default.conf COPY startup.sh /opt/docker/startup.sh RUN chmod +x /opt/docker/startup.sh # arranque CMD /opt/docker/startup.sh MULTI-STAGE-BUILD Ejemplo de instalar varias capas de sistemas operativos: # SO FROM maven:3.5-alpine as builder # copiamos la carpeta dentro COPY app /app # entramos y empaquetamos RUN cd /app && mvn package # desde java FROM openjdk:8-alpine # copiamos desde maven y lanzamos la app COPY --from=builder /app/target/my-app-1.0-SNAPSHOT.jar /opt/app.jar # ejecutamos la app CMD java -jar /opt/app.jar [isx46410800@miguel multi]$ docker build -t isx46410800/java:app . [isx46410800@miguel multi]$ docker run -d isx46410800/java:app [isx46410800@miguel multi]$ docker logs trusting_galois Hello World! Otro ejemplo: FROM centos as test RUN fallocate -l 10M /opt/file1 RUN fallocate -l 20M /opt/file2 RUN fallocate -l 30M /opt/file3 FROM alpine COPY --from=test /opt/file2 /opt/myfile El centos con los 3 files serian 260M pero solo coge de alpine que son 4 y coge el file que le interesa. El total de la imagen es 24M y no la suma de todo. PRUEBA REAL La idea de este articulo es que le des soluci\u00f3n al siguiente problema utilizando lo que has aprendido. En donde trabajas, solicitan una imagen Docker base para ser reutilizada. Tu tarea es crear un Dockerfile con las siguientes especificaciones y entregarlo a tu jefe: Sistema Operativo Base: CentOs o Debian (A tu elecci\u00f3n): Herramientas a instalar: Apache (\u00daltima versi\u00f3n) PHP 7.0 Debes usar buenas pr\u00e1cticas. Deber\u00e1s comprobar su funcionamiento creando un index.php con la funci\u00f3n de phpinfo. Dockerfile: # SO FROM centos:7 # Instalar apache RUN yum install -y httpd # A\u00f1adir repo de php para centos7 e instalamos version 7.0 RUN yum install -y http://rpms.remirepo.net/enterprise/remi-release-7.rpm && \\ yum update -y && \\ yum install -y yum-utils && \\ yum install -y php php-mcrypt php-cli php-gd php-curl php-mysql php-ldap php-zip php-fileinfo # Test de pagina index de php RUN echo \"<?php phpinfo(); ?>\" > /var/www/html/index.php # Volumenes VOLUME /var/www/html /var/log/php-fpm /var/lib/php-fpm # copia del startup y permisos COPY startup.sh opt/docker/startup.sh RUN chmod +x opt/docker/startup.sh # Arrancamos el servicio apache en segundo plano CMD [\"opt/docker/startup.sh\"] Startup.sh: #!/bin/bash # Iniciar contenedor echo \"iniciando container...\" # Encendiendo servicio apache apachectl -DFOREGROUND Imagen: docker build -t isx46410800/apache:php . Contenedor: docker run --name apache_php -p 80:80 -d isx46410800/apache:php Funcionamiento: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES abda827fb9f5 isx46410800/apache:php \"opt/docker/startup.\u2026\" 3 seconds ago Up 1 second 0.0.0.0:80->80/tcp apache_php Entramos a localhost:80 y nos saldr\u00e1 la web index.php DOCKER CONTAINERS Son una instancia de ejecuci\u00f3n de una imagen Son temporales Capa de lectura y escritura Podemos crear varios partiendo de una misma imagen LISTAR/MAPEO PUERTOS docker ps / docker ps -a / docker ps -q(ids) PuertoLocal-PuertoContainer: docker run --name jenkins -p 8080:8080 -d jenkins 0.0.0.0:8080 todas las interfaces de nuestra m\u00e1quina est\u00e1n mapeadas al puerto 8080. Si mapeamos la misma imagen con otros puertos, tenemos varias imagenes en diferentes puertos. docker run --name jenkins -p :8080 -d jenkins Cualquier primer puerto libre que coja mi maquina se mapea al 8080. INICIAR/DETENE/PAUSAR Renombrar un contenedor: docker rename nombre_viejo nombre_nuevo Parar contenedor: docker stop nombre/id Iniciar contenedor: docker start nombre/id Reiniciar contenedor: docker restart nombre/id Entrar con una terminal al contenedor: docker exec -it nombre /bin/bash docker exec -u root/user -it nombre /bin/bash jenkins@bh45fdiu ---> user@id VARIABLES DE ENTORNO En Dockerfile: ENV variable valor En la linea de construir container: docker run --name jenkins -e \"varible=valor\" -p :8080 -d jenkins MYSQL Se ha de instalar el mysql client en las versiones que descargamos de dockerhub, ya que nos falta eso para poder usarlo: yum install -y mysql / apt-get install mysql-client / dnf install mysql-community-server AYUDA MYSQL Creamos contenedor MYSQL siguiendo las instrucciones: docker run --name mysql-db --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -d mysql:5.7 docker run --name mysql-db --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -d mysql:5.7 fc84bdb48a389c9e7183fd633c0edfb03a7867104e1e867ef321a223f044fe87 docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fc84bdb48a38 mysql:5.7 \"docker-entrypoint.s\u2026\" 3 seconds ago Up 2 seconds 3306/tcp, 33060/tcp mysql-db Para que arranque con todo lo necesario el container: docker logs -f mysql-db Mensaje final de ready for connections por tal puerto. Para conectarnos tendr\u00edamos que haber mapeado el puerto, no obstante podemos conectarnos sabiendo la IP de nuestro container y a\u00f1adirsela al comando de mysql de conexion con docker inspect mysql-db : [isx46410800@miguel mysql]$ mysql -u root -h 172.17.0.3 -pjupiter Mapeando puerto(el de mysql del log) para tambi\u00e9n poder usarlo mi maquina local, con nuevas variables de entorno siguiendo la gu\u00eda, creando una db con usuario y passwd: docker run --name mysql-db2 --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -e \"MYSQL_DATABASE=docker-db\" -e \"MYSQL_USER=docker\" -e \"MYSQL_PASSWORD=docker\" -p 3333:3306 -d mysql:5.7 [isx46410800@miguel mysql]$ docker run --name mysql-db2 --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -e \"MYSQL_DATABASE=docker-db\" -e \"MYSQL_USER=docker\" -e \"MYSQL_PASSWORD=docker\" -p 3333:3306 -d mysql:5.7 b24dff85293ef892f2f9033c231e7a594a1261e9b5924e2a955691cc403eee11 [isx46410800@miguel mysql]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b24dff85293e mysql:5.7 \"docker-entrypoint.s\u2026\" 4 seconds ago Up 2 seconds 33060/tcp, 0.0.0.0:3333->3306/tcp mysql-db2 b3254fe3706b mysql:5.7 \"docker-entrypoint.s\u2026\" 3 minutes ago Up 3 minutes 3306/tcp, 33060/tcp mysql-db Para que arranque con todo lo necesario el container: docker logs -f mysql-db2 Comprobamos por localhost: [isx46410800@miguel mysql]$ mysql -u root -h 127.0.0.1 -pjupiter --port=3333 MONGODB Descargamos imagen mongodb Encendemos dos containers: [isx46410800@miguel images]$ docker run --name mongodb -p 27017:27017 -d mongo [isx46410800@miguel images]$ docker run --name mongodb2 -p 27018:27017 -d mongo Para ver cuanta memoria usa, se utiliza la orden: docker stats mongodb Con algun software de bbdd podemos conectarnos a este container poniendo la IP y el puerto y ya entrar\u00edamos remotamente. robomongo es un cliente de mondodb para estas conexiones APACHE/NGINX/TOMCAT Creamos nuestro container nginx oficial mapeado: [isx46410800@miguel images]$ docker run --name nginx -p 8888:80 -d nginx Creamos nuestro container apache(httpd) oficial mapeado: [isx46410800@miguel images]$ docker run --name apacheweb -p 9999:80 -d httpd Creamos nuestro container tomcat version alpine oficial mapeado: [isx46410800@miguel images]$ docker run --name tomcat -p 7070:8080 -d tomcat:9.0.8-jre8-alpine POSTGRES Descargamos imagen : docker pull postgres Creamos container postgres creando user, pass y db: docker run --name postgres -e \"POSTGRES_PASSWORD=jupiter\" -e \"POSTGRES_USER=docker\" -e \"POSTGRES_DB=docker-db\" -p 5432:5432 -d postgres Entramos y comprobamos: root@1ff7388f08b3:/# psql -d docker-db -U docker psql (13.0 (Debian 13.0-1.pgdg100+1)) Type \"help\" for help. docker-db=# docker-db=# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+--------+----------+------------+------------+------------------- docker-db | docker | UTF8 | en_US.utf8 | en_US.utf8 | postgres | docker | UTF8 | en_US.utf8 | en_US.utf8 | template0 | docker | UTF8 | en_US.utf8 | en_US.utf8 | =c/docker + | | | | | docker=CTc/docker template1 | docker | UTF8 | en_US.utf8 | en_US.utf8 | =c/docker + | | | | | docker=CTc/docker (4 rows) JENKINS Descargamos imagen : docker pull jenkins Creamos container jenkins: docker run --name jenkins -p 9090:8080 -d jenkins Luego tendr\u00edamos que copiar la contrase\u00f1a del fichero de password y arrancar la instalaci\u00f3n de Jenkins. LIMITAR RECURSOS Ayuda con: docker --help | grep \"xxxx\" MEMORIA Para gestionar le memoria que puede usar mi docker se usa -m \"500Mb\" : docker run --name web -m \"500Mb\" -d httpd Lo comprobamos con: docker stats web --> LIMIT 10/500mb CPU Vemos cuantas CPUs tenemos con: grep \"model name\" /proc/cpuinfo | wc -l --> 4 Indicar cual es la CPU que tiene usar cpuset-cpus 0 /0-1/0-3 : docker run --name web -m \"500Mb\" cpuset-cpus 0-2 -d httpd Comparte 3 cpus, la 0 , 1 y 2. COPIA DE ARCHIVOS De mi directorio al contenedor: docker cp index.html apache:/var/www/html Del contenedor a mi directorio: docker cp apache:/var/www/html/index.html /var/www/html/. CONTENEDOR A IMAGEN Para guardar todo lo a\u00f1adido dentro de un contenedor y convertirlo en una imagen guardada y actualizada se hace: docker commit imagen imagen-nueva Nota, todo lo que est\u00e1 dentro de un volumen NO SE GUARDAR\u00c1!! SOBREESCRIBIR CMD Para que el ultimo comando del docker no sea en la gran mayoria el /bin/bash o el servicio en foreground podemos poner otras \u00f3rdenes y el CMD ser\u00e1 diferente: docker run -p 8080:8080 -d centos python -m SimpleHTTPServer 8080 docker ps docker logs centos DESTRUIR CONTAINER Para destruir containers autom\u00e1ticamente se usa en la linea de docker: docker run --rm... DOCUMENT ROOT El directorio root de Docker est\u00e1 en: docker info | grep -i root --> /var/libdocker Lo podemos cambiar a\u00f1adiendo en el fichero /var/lib/systemd/system/docker.service : linea ExecStart: xxxxx --data-root /opt/docker Tendriamos ahora en /opt/docker el nuevo document root. Cargamos y reiniciamos: systemctl daemon-reload systemctl restart docker Podemos copiar todo el contenido de /var/lib/docker a la nueva carpeta y tendriamos todo ahi. DOCKER VOLUMES Los vol\u00famenes permiten almacenar data persistente del contenedor: Host Anonymous Named Volumes VOLUMES HOST Son los que se han de crear una carpeta antes y mapear a la carpeta del contenedor el cual queremos guardar la xixa: mkdir mysql docker run --name mysql-db -v mysql:/var/lib/sql -e \"MYSQL_ROOT_PASSWORD=jupiter\" -p 3306:3306 -d mysql:5-7 VOLUMES ANONYMOYS Son los que no ponemos ning\u00fan volumen de host y se nos a\u00f1ade a cualquier directorio al azar: docker run --name mysql-db -v /var/lib/sql -e \"MYSQL_ROOT_PASSWORD=jupiter\" -p 3306:3306 -d mysql:5-7 Lo podemos descubrir(Normalmente en /var/lib/docker/volumes // /user/home/docker/volumes ): docker inspect container | grep mount docker info | grep -i root VOLUMES NAMED VOLUMES Son los que creamos directamente con las ordenes: docker volume create my-vol Lo vemos con: docker volume ls Y se guardan en: /var/lib/docker/volumes // /user/home/docker/volumes docker run --name mysql-db -v my-vol:/var/lib/sql -e \"MYSQL_ROOT_PASSWORD=jupiter\" -p 3306:3306 -d mysql:5-7 Lo podemos descubrir(Normalmente en /user/home/docker/volumes ): docker volume inspect volumenName docker inspect container | grep mount docker info | grep -i root PRUEBA REAL Dockerfile: # SO FROM centos:7 # Instalar apache RUN yum install -y httpd # A\u00f1adir repo de php para centos7 e instalamos version 7.0 RUN yum install -y http://rpms.remirepo.net/enterprise/remi-release-7.rpm && \\ yum update -y && \\ yum install -y yum-utils && \\ yum install -y php php-mcrypt php-cli php-gd php-curl php-mysql php-ldap php-zip php-fileinfo # Test de pagina index de php RUN echo \"<?php phpinfo(); ?>\" > /var/www/html/index.php # copia del startup y permisos COPY startup.sh /opt/docker/startup.sh RUN chmod +x /opt/docker/startup.sh # Arrancamos el servicio apache en segundo plano CMD [\"/opt/docker/startup.sh\"] Startup.sh: [isx46410800@miguel prueba2]$ cat startup.sh #!/bin/bash # Iniciar contenedor echo \"iniciando container...\" # Encendiendo servicio apache apachectl -DFOREGROUND Creaci\u00f3n volumen: [isx46410800@miguel prueba2]$ mkdir data_apache Imagen: Sending build context to Docker daemon 4.096kB docker build -t apache_volume . Contenedor con -m 500mb limite, uso en la cpu 0, -e las variables de entorno -v del volumen y -p del puerto indicado: docker run --rm --name apache_volume -m 500Mb --cpuset-cpus 0 -v $PWD/data_apache:/var/www/html/ -e \"ENV=dev\" -e \"VIRTUALIZATION=docker\" -p 5555:80 -d apache_volume + Resultados: set VIRTUALIZATION=docker ENV=dev DOCKER NETWORK Tipos: Bridge Host None Overlay La red por defecto es docker0 que se obtiene de ip -a : 4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 La red por defecto de docker es bridge : docker network inspect bridge Entre containers de misma red se pueden hacer ping CREAR REDES Para crear redes: docker network create netA Para ver las redes: docker network ls | grep netA Opci\u00f3n -d para el driver de gesti\u00f3n de la red bridge: docker network create -d bridge --subnet 172.124.10.0/24 --gateway 172.124.10.1 netB VER REDES Para ver las redes creadas: docker network inspect netA AGREGAR/CONECTAR REDES Para agregar una red a un contenedor se una --net : [isx46410800@miguel images]$ docker run --rm --name test1 --net netA -d nginx [isx46410800@miguel images]$ docker run --rm --name test2 --net netB -d nginx [isx46410800@miguel images]$ docker run --rm --name test3 --net netB -dit centos Con contenedores de la misma red creadas con el network create, podemos hacer ping a la ip o al nombre del container, es como si tuviera un DNS resolver: test1-----> 172.18.0.2 -------> netA test2-----> 172.124.10.2 -----> netB test3-----> 172.124.10.3 -----> netB [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test2\" PING test2 (172.124.10.2) 56(84) bytes of data. 64 bytes from test2.netB (172.124.10.2): icmp_seq=1 ttl=64 time=0.148 ms 64 bytes from test2.netB (172.124.10.2): icmp_seq=2 ttl=64 time=0.090 ms 64 bytes from test2.netB (172.124.10.2): icmp_seq=3 ttl=64 time=0.101 ms --- test2 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 26ms rtt min/avg/max/mdev = 0.090/0.113/0.148/0.025 ms [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 172.124.10.2\" PING 172.124.10.2 (172.124.10.2) 56(84) bytes of data. 64 bytes from 172.124.10.2: icmp_seq=1 ttl=64 time=0.060 ms 64 bytes from 172.124.10.2: icmp_seq=2 ttl=64 time=0.131 ms 64 bytes from 172.124.10.2: icmp_seq=3 ttl=64 time=0.085 ms --- 172.124.10.2 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 53ms rtt min/avg/max/mdev = 0.060/0.092/0.131/0.029 ms [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test1\" ping: test1: Name or service not known [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 172.18.0.2\" PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. --- 172.18.0.2 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 61ms Para conectar con diferentes redes se utiliza connect pero solo se conectan con el nombre del container y no por la ip: docker network connect netB test1 Quiere decir que conectamos a test1 a la red de netB. \"Networks\": { \"netA\": { \"IPAMConfig\": null, ... }, \"netB\": { \"IPAMConfig\": {}, .... Comprobamos: [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test1\" PING test1 (172.124.10.4) 56(84) bytes of data. 64 bytes from test1.netB (172.124.10.4): icmp_seq=1 ttl=64 time=0.101 ms 64 bytes from test1.netB (172.124.10.4): icmp_seq=2 ttl=64 time=0.086 ms 64 bytes from test1.netB (172.124.10.4): icmp_seq=3 ttl=64 time=0.085 ms --- test1 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 44ms rtt min/avg/max/mdev = 0.085/0.090/0.101/0.013 ms [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 172.18.0.2\" PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. --- 172.18.0.2 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 80ms Para volver a desconectar se utiliza: docker network disconnect netB test1 [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test1\" ping: test1: Name or service not known ELIMINAR REDES Para eliminar redes: docker network remove netA netB ASIGNAR IPs Creamos una red: docker network create -d bridge --subnet 172.124.10.0/24 --gateway 172.124.10.1 mynet Asignamos una IP aleatoria que coger\u00e1 del rango que creamos: docker run --rm --name test3 --net mynet -dit centos Asignar una IP concreta con el --ip : docker run --rm --name test3 --net mynet --ip 172.124.10.50 -dit centos RED HOST Esta red ya existe por defecto con docker igual que la de brigde. Para conectarnos a esta red, que ser\u00eda la misma que la IP real de mi m\u00e1quina, tendr\u00eda todo, como el hostname, ser\u00eda: docker run --rm --name test3 --net host -dit centos [root@miguel /]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp4s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether b4:b5:2f:cb:e2:65 brd ff:ff:ff:ff:ff:ff inet 192.168.1.104/24 brd 192.168.1.255 scope global dynamic enp4s0 valid_lft 66351sec preferred_lft 66351sec inet6 fe80::227a:4836:6df:23b/64 scope link valid_lft forever preferred_lft forever 3: wlp3s0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc mq state DOWN group default qlen 1000 link/ether f2:aa:5b:7e:c0:70 brd ff:ff:ff:ff:ff:ff 4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:9f:2c:43:a0 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:9fff:fe2c:43a0/64 scope link valid_lft forever preferred_lft forever [root@miguel /]# hostname miguel RED NONE Esta red ya existe por defecto con docker igual que la de brigde. Sirve para que los container que creemos no tengan ninguna IP, no tendr\u00eda apartado network: docker run --rm --name test3 --net none -dit centos EXPONER IPs CONCRETAS Tomaremos como premisa que la IP de nuestro Docker Host es 192.168.100.2 Al exponer un puerto en un contenedor, por defecto, este utiliza todas las interfaces de nuestra m\u00e1quina. Ve\u00e1mos un ejemplo: docker run -d -p 8080:80 nginx 196a13fe6198e1a3e8d55aedda90882f6abd80f4cdf41b2f29219a9632e5e3a1 [docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 196a13fe6198 nginx \"nginx -g 'daemon of\u2026\" 5 seconds ago Up 2 seconds 0.0.0.0:8080->80/tcp frosty_jenning Si observamos la parte de ports, veremos un 0.0.0.0 . Esto significa que podremos acceder al servicio en el puerto 8080 utilizando localhost: 8080 , o 127.0.0.1:8080 , 192.168.100.2:8080 . Si quisi\u00e9ramos que sea accesible solamente v\u00eda localhost y no v\u00eda 192.168.100.2 , entonces har\u00edamos lo siguiente: docker run -d -p 127.0.0.1:8081:80 nginx 1d7e82ff15da55b8c774baae56827aef12d59ab848a5f5fb7f883d1f6d1ee6e1 docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1d7e82ff15da nginx \"nginx -g 'daemon of\u2026\" 3 seconds ago Up 1 second 127.0.0.1:8081->80/tcp musing_tesla Como observamos, ahora en vez de 0.0.0.0 vemos un 127.0.0.1 , lo que indica que nuestro servicio es accesible s\u00f3lo v\u00eda localhost y no usando 192.168.100.2 DOCKER COMPOSE Herramienta de Docker de aplicaciones multicontenedor. El archivo es docker-compose.yml y contiene: Contenedores Im\u00e1genes Vol\u00famenes Redes INSTALACI\u00d3N Docker-compose del curso Instalaci\u00f3n: sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose EJEMPLO Documentaci\u00f3n Siempre ha de ponerse si hay como secciones principales: Version Services Volumes Networks Ejemplo: version: '3' services: nginx: container_name: nginx image: nginx ports: - \"8080:80\" Para arrancarlo: docker-compose up -d Para apagarlo: docker-compose down VARIABLES ENTORNO Podemos poner las variables con la opci\u00f3n environment o a trav\u00e9s de un ficheros con todas las variables de entono con la opci\u00f3n env_file : version: '3' services: db: container_name: mysql image: mysql:5.7 ports: - \"3306:3306\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" version: '3' services: db: container_name: mysql image: mysql:5.7 ports: - \"3306:3306\" env_file: variables.env VOL\u00daMENES Para los vol\u00famenes, podemos crearlo a\u00f1andiendolo en su secci\u00f3n y luego para asignarlo a un contenedor, a\u00f1adimos la subsecci\u00f3n volumes: version: '3' services: nginx: container_name: nginx image: nginx ports: - \"8081:80\" volumes: - \"my-vol:/usr/share/nginx/html\" volumes: my-vol: Creamos el volumen Named my-vol y lo a\u00f1adimos al contenedor de nginx. El volumen se crea en la ruta del Document Root--> docker info | grep -i root . [isx46410800@miguel nginx]$ docker-compose -f docker-compose_volumes.yml up -d Creating network \"nginx_default\" with the default driver Creating volume \"nginx_my-vol\" with default driver Creating nginx ... Creating nginx ... done se llama de prefijo nginx, porque siempre coge el nombre del directorio actual. Si vamos al volumen y cambiamos el contenido, al volver a formarse saldr\u00e1 lo que hayamos puesto. Para un volumen de host, hemos de poner la ruta absoluta de la carpeta que usaremos como volumen, en este caso creamos el volumen de html : version: '3' services: nginx: container_name: nginx image: nginx ports: - \"8081:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/nginx/html:/usr/share/nginx/html\" REDES Para crear redes, se ha de crear la seccion de networks y de cada contenedor si son diferentes, indicar la subsecci\u00f3n network indicando la red: version: '3' services: web: container_name: apache image: httpd ports: - \"8081:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/apache/html:/var/www/html\" networks: - my-net web2: container_name: apache2 image: httpd ports: - \"8082:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/apache/html:/var/www/html\" networks: - my-net networks: my-net: Creamos la red my-net y al estar en una red creada tiene DNS y podemos contactar por nombre de container, por nombre de servicio o por IP. root@3893b20251af:/usr/local/apache2# ping web PING web (172.21.0.2) 56(84) bytes of data. 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=1 ttl=64 time=0.056 ms 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=2 ttl=64 time=0.041 ms ^C --- web ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 16ms rtt min/avg/max/mdev = 0.041/0.048/0.056/0.010 ms root@3893b20251af:/usr/local/apache2# ping apache PING apache (172.21.0.2) 56(84) bytes of data. 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=1 ttl=64 time=0.046 ms 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=2 ttl=64 time=0.056 ms ^C --- apache ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 65ms rtt min/avg/max/mdev = 0.046/0.051/0.056/0.005 ms root@3893b20251af:/usr/local/apache2# ping 172.21.0.2 PING 172.21.0.2 (172.21.0.2) 56(84) bytes of data. 64 bytes from 172.21.0.2: icmp_seq=1 ttl=64 time=0.080 ms ^C --- 172.21.0.2 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.080/0.080/0.080/0.000 ms BUILD DOCKERFILE Para poder poner en el docker-compose nuestra imagen personalizada de un Dockerfile : Podemos o solo construir la imagen indicando donde est\u00e1 seg\u00fan si se llama Dockerfile o con otro nombre y en qu\u00e9 carpeta. Si se llama Dockerfile y ruta del directorio ('.' si est\u00e1 aqu\u00ed), ponemos la opci\u00f3n build . Le ponemos tambi\u00e9n nombre de la imagen a construir: version: '3' services: web: container_name: apache image: isx46410800/httpd-build build: . ports: - \"8081:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/build/html:/var/www/html\" networks: - my-net networks: my-net: Si se llama diferente a Dockerfile, ponemos context para ver en que directorio est\u00e1 y dockerfile y el nombre del archivo: web2: container_name: apache2 image: isx46410800/httpd-build2 build: context: . (directorio donde est\u00e1 el dockerfile) dockerfile: Dockerfile2 ports: - \"8082:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/build/html:/var/www/html\" networks: - my-net La construimos con docker-compose build : [isx46410800@miguel build]$ docker-compose build Building web Step 1/1 : FROM httpd ---> 417af7dc28bc Successfully built 417af7dc28bc Successfully tagged isx46410800/httpd-build:latest O construir image y hacer container de golpe con docker-compose up -d : [isx46410800@miguel build]$ docker-compose up -d apache is up-to-date Recreating apache2 ... Recreating apache2 ... done [isx46410800@miguel build]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 240530fbf981 isx46410800/httpd-build2 \"httpd-foreground\" 4 seconds ago Up 2 seconds 0.0.0.0:8082->80/tcp apache2 e8722f8e391d isx46410800/httpd-build \"httpd-foreground\" 29 seconds ago Up 27 seconds 0.0.0.0:8081->80/tcp apache CMD CAMBIADO Para cambiar el CMD de por defecto cuando se crea un contenedor podemos cambiarlo a\u00f1adiendo la subsecci\u00f3n command : version: '3' services: web: container_name: centos image: centos command: python -m SimpleHTTPServer 8080 ports: - \"8080:8080\" networks: - my-net networks: my-net: LIMITAR RECURSOS Solo se puede en versi\u00f3n 2 con opciones como mem_limit o cpuset : version: '2' services: web: container_name: nginx image: nginx:alpine mem_limit: 20Mb cpuset: \"0\" POL\u00cdTICA DE REINICIO Existe la subsecci\u00f3n restart que indica cuando se reinicia un contenedor. Por defecto es restart: no , no se reinicie nunca pero est\u00e1n estas opciones: restart: no restart: always : siempre se reinicie cuando muera. restart: unless-stopped : siempre se reinicia a no ser que lo pare manualmente. restart: on failure : a no ser que tenga fallos distinto a 0, no se reinicia nunca. NOMBRE PROYECTO Cuando haces un docker-compose up -d coge el nombre de proyecto, redes, etc por el nombre del directorio actual, para cambiarlo: docker-compose -p proyecto_web up -d DIFERENTE DOCKER-COMPOSE Cuando haces un docker-compose up -d coge el nombre de docker-compose.yml, para cambiarlo por un diferente: docker-compose -f nombre_docker_compose.yml up -d OTROS COMANDOS docker-compose up #enciende todos los dockers del file compose.yml docker-compose -f fileCompose.yml up (-d) #elegimos que fichero encendemos del compose docker-compose down #apaga todo docker-compose ps docker-compose images docker-compose top nom_servei docker-compose port ldap 389 #servicio y puerto elegido docker-compose push/pull #subir o bajar images docker-compose logs ldap #logs del servicio elegido docker-compose pause/unpause ldap #pausar el servicio docker-compose start/stop ldap #iniciar servicio docker-compose scale ldap=2 #dos container ldap PROYECTOS DOCKER-COMPOSE MYSQL-WORDPRESS Podemos crear una base de datos mysql y un wordpress via web en el que la bbdd se comunique con el wordpress con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: bbdd: container_name: bd-mysql image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=wordpress\" - \"MYSQL_USER=wordpress\" - \"MYSQL_PASSWORD=wordpress\" ports: - \"3306:3306\" networks: - my-net wordpress: container_name: wordpress image: wordpress volumes: - \"$PWD/html:/var/www/html\" depends_on: - bbdd environment: - \"WORDPRESS_DB_HOST=bbdd:3306\" - \"WORDPRESS_DB_USER=wordpress\" - \"WORDPRESS_DB_PASSWORD=wordpress\" ports: - \"80:80\" networks: - my-net networks: my-net: Resultados: DRUPAL-POSTGRESQL Podemos crear una base de datos postgres y un drupal via web en el que la bbdd se comunique con el drupal con la subsecci\u00f3n depends_on . Al entrar en drupal nos pedir\u00e1 la contrase\u00f1a que le ponemos de variable y por defecto el user es postgres : docker-compose.yml : version: '3' services: postgresql: container_name: postgres image: postgres:11 volumes: - \"$PWD/postgresql:/var/lib/postgresql/data\" environment: - \"POSTGRESQL_PASSWORD=jupiter\" networks: - my-net drupal: container_name: drupal image: drupal:8-apache volumes: - \"drupal:/var/www/html\" ports: - \"81:80\" networks: - my-net volumes: drupal: networks: my-net: Resultados: PRESTASHOP-MYSQL Podemos crear una base de datos mysql y un prestashop via web en el que la bbdd se comunique con el prestashop con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: bbdd: container_name: bd-mysql image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=prestashop\" - \"MYSQL_USER=prestashop\" - \"MYSQL_PASSWORD=prestashop\" ports: - \"3306:3306\" networks: - my-net prestashop: container_name: prestashop image: prestashop/prestashop volumes: - \"$PWD/html:/var/www/html\" depends_on: - bbdd environment: - \"DB_SERVER=bbdd:3306\" - \"DB_USER=presta\" - \"DB_PASSWD=presta\" - \"DB_NAME=presta\" ports: - \"80:80\" networks: - my-net networks: my-net: Resultados: JOOMLA-MYSQL Podemos crear una base de datos mysql y un joomla via web en el que la bbdd se comunique con el joomla con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: bbdd: container_name: bd-mysql image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=joomla\" - \"MYSQL_USER=joomla\" - \"MYSQL_PASSWORD=joomla\" ports: - \"3306:3306\" networks: - my-net joomla: container_name: joomla image: joomla volumes: - \"$PWD/html:/var/www/html\" environment: - \"JOOMLA_DB_HOST=bbdd\" - \"JOOMLA_DB_USER=joomla\" - \"JOOMLA_DB_PASSWORD=joomla\" - \"JOOMLA_DB_NAME=joomla\" ports: - \"80:80\" networks: - my-net networks: my-net: Resultados: REACT-MONGODB-NODE.JS Podemos crear una base de datos mongo y un react ecommerce hecha en node.js via web en el que la bbdd se comunique con el react con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: mongo: container_name: mongo image: mongo ports: - \"27017:27017\" volumes: - \"$PWD/data:/data/db\" networks: - my-net react: container_name: react-nodejs image: reactioncommerce/reaction depends_on: - mongo environment: - \"ROOT_URL=http://localhost\" - \"MONGO_URL=mongodb://mongo:27017/reaction\" ports: - \"3000:3000\" networks: - my-net networks: my-net: Resultados: GUACAMOLE DOCUMENTACI\u00d3N Para sacar el fichero necesario de bbdd: $ docker run --rm guacamole/guacamole /opt/guacamole/bin/initdb.sh --postgres > initdb.sql Sirve para que desde el navegador te puedes conectar a escritorios remotos por ssh: docker-compose.yml : version: '3' services: db: container_name: guacamole-db networks: - net image: mysql:5.7 volumes: - $PWD/initdb.sql:/docker-entrypoint-initdb.d/initdb.sql - $PWD/data:/var/lib/mysql env_file: .env daemon: container_name: guacamole-daemon networks: - net image: guacamole/guacd depends_on: - db web: container_name: guacamole-web networks: - net image: guacamole/guacamole env_file: .env depends_on: - daemon proxy: container_name: guacamole-proxy networks: - net image: nginx ports: - \"80:80\" volumes: - $PWD/nginx.conf:/etc/nginx/nginx.conf depends_on: - web networks: net: Resultados: ZABBIX Sirve para monitorizar servidores: Dockerfile de Zabbix: FROM centos:7 ENV ZABBIX_REPO http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm RUN \\ yum -y install $ZABBIX_REPO && \\ yum -y install \\ zabbix-get \\ zabbix-server-mysql \\ zabbix-web-mysql \\ zabbix-agent EXPOSE 80 443 COPY ./bin/start.sh /start.sh COPY ./conf/zabbix-http.conf /etc/httpd/conf.d/zabbix.conf COPY ./conf/zabbix-server.conf /etc/zabbix/zabbix_server.conf COPY ./conf/zabbix-conf.conf /etc/zabbix/web/zabbix.conf.php VOLUME /usr/share/zabbix /var/log/httpd RUN chmod +x /start.sh CMD /start.sh docker-compose.yml : version: '3' services: zabbix: container_name: zabbix-web image: zabbix build: . volumes: - \"$PWD/html:/usr/share/zabbix\" ports: - \"80:80\" networks: - net db: container_name: zabbix-db image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_USER: zabbix MYSQL_PASSWORD: zabbix MYSQL_DATABASE: zabbix volumes: - \"$PWD/data:/var/lib/mysql\" - \"$PWD/conf/create.sql:/docker-entrypoint-initdb.d/zabbix.sql\" ports: - \"3306:3306\" networks: - net networks: net: Resultados: PHPMYADMIN-MYSL Crear un docker-compose v3 con dos servicios: db admin. En el servicio DB, debe ir una db con mysql:5.7 y las credenciales de tu preferencia. En el admin, debes usar la imagen oficial de phpmyadmin, y por medio de redes, comunicarla con mysql. Debes exponer el puerto de tu preferencia y para validar que funcione, debes loguearte en el UI de phpmyadmin v\u00eda navegador, usando las credenciales del root de mysql. Docker-compose.yml: version: '3' services: db: container_name: mysql-db image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=phpmyadmin\" - \"MYSQL_USER=miguel\" - \"MYSQL_PASSWORD=jupiter\" ports: - \"3306:3306\" networks: - my-net admin: container_name: phpmyadmin image: phpmyadmin/phpmyadmin depends_on: - db environment: - \"PMA_HOST=db\" - \"PMA_PASSWORD=jupiter\" - \"PMA_USER=miguel\" ports: - \"9090:80\" networks: - my-net networks: my-net: Resultados: DOCKER SWARM Orquestador de servicios en diferentes m\u00e1quinas obteniendo as\u00ed clusters en m\u00e1quinas. Tiene que haber m\u00ednimo un MANAGER , el resto son workers . Los nodos son los diferentes hosts que forman el swarm. Los stacks son el conjunts de APPs. La RED MESH es la red que hace que todos los nodes respondan a todos los servicios aunque no lo tengan en el suyo. Puerto 2377. TCP port 2377 for cluster management communications TCP and UDP port 7946 for communication among nodes UDP port 4789 for overlay network traffic El routing Mesh hace el load balance en puertos 80 y 9000. Las \u00f3rdenes docker stack / services solo se pueden hacer desde el manager. Los deploys se pueden hacer: Modo global: un servicio se despliega a todos aleatoriamente. Modo individual: para cada nodo, se despliega el servicio. Modo replicas: varias veces el mismo servicio. COMANDOS B\u00c1SICOS docker swarm init docker swarm init --advertise-addr IP docker swarm join-token manager/worker docker swarm leave --force docker node ls docker node update --availability active/drain/pause nodeName docker node update --label-add tipo=valor nodeName docker node inspect nodeName docker stack deploy -c docker-compose.yml nombreApp docker stack ps nombreApp docker stack ls docker stack rm nombreApp docker stack services nombreApp docker service ls docker service ps nombreServicio docker service inspect nombreServicio docker service scale nombreServicio=2 INICIALIZAR Al que queremos como manager, le indicamos la siguiente orden con la IP p\u00fablica, este caso en una AWS: docker swarm init --advertise-addr 35.177.139.97 Nos dar\u00e1 un token que para cualquier nodo worker que queramos agregar al cluster,tendremos que poner eso. En nuestro caso en una m\u00e1quina AWS y otro el de mi casa: docker swarm join --token SWMTKN-1-2et2rzxn0kyfzsh8dmop8n2grqri001owhomhk7ggfr3tbls4b-587tzjo1dxtmpbpmrqldtddu1 35.177.139.97:2377 DEPLOY SWARM Creamos un docker-compose.yml: version: \"3\" services: hello: image: isx46410800/k19:hello deploy: replicas: 6 ports: - \"80:80\" visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager] Desplegamos con la orden: docker stack deploy -c docker-compose.yml AppMiguel [fedora@ip-172-31-18-60 swarm]$ sudo docker stack deploy -c docker-compose.yml AppMiguel Creating network AppMiguel_default Creating service AppMiguel_hello Creating service AppMiguel_visualizer Comprobaciones de que estan los dos servicios k19:hello(6) y visualizer (1): [fedora@ip-172-31-18-60 swarm]$ docker stack ls NAME SERVICES ORCHESTRATOR AppMiguel 2 Swarm [fedora@ip-172-31-18-60 swarm]$ docker stack ps AppMiguel ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS bdbfuun9q7my AppMiguel_visualizer.1 dockersamples/visualizer:stable ip-172-31-18-60.eu-west-2.compute.internal Running Running about a minute ago w9f3dkx7rqic AppMiguel_hello.1 isx46410800/k19:hello ip-172-31-19-185.eu-west-2.compute.internal Running Running about a minute ago og22dynjynb1 AppMiguel_hello.2 isx46410800/k19:hello ip-172-31-18-60.eu-west-2.compute.internal Running Running about a minute ago 9qk5v9nixvc5 AppMiguel_hello.3 isx46410800/k19:hello miguel Running Running about a minute ago c0hgdykvxub7 AppMiguel_hello.4 isx46410800/k19:hello ip-172-31-19-185.eu-west-2.compute.internal Running Running about a minute ago rx4khrovr84t AppMiguel_hello.5 isx46410800/k19:hello ip-172-31-18-60.eu-west-2.compute.internal Running Running about a minute ago fyxes66lquup AppMiguel_hello.6 isx46410800/k19:hello miguel Running Running about a minute ago ESCALAR SERVICIOS Como vemos los dos servicios que tenemos se llaman: [fedora@ip-172-31-18-60 swarm]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS p46df6579rup AppMiguel_hello replicated 6/6 isx46410800/k19:hello *:80->80/tcp 9n3iyb7ofvfx AppMiguel_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080->8080/tcp Escalamos con docker service scale AppMiguel_hello=3 : [fedora@ip-172-31-18-60 swarm]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS p46df6579rup AppMiguel_hello replicated 3/3 isx46410800/k19:hello *:80->80/tcp 9n3iyb7ofvfx AppMiguel_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080->8080/tcp MODO GLOBAL Para que haya un servicio en cada hosts: version: \"3\" services: hello: image: isx46410800/k19:hello deploy: mode: global ports: - \"80:80\" visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager] NODO DRAIN/PAUSE/ACTIVE DRAIN: hace que el nodo, todos sus servicios se los pasa a otro. PAUSE: pausa el nodo, siguen sus servicios pero no acepta m\u00e1s. ACTIVE: volvemos activar el nodo. Orden: docker node update --availability active/drain/pause nodeName LABELS Podemos poner etiquetas a los nodos y hacer deploy segun etiquetas. Orden: docker node update --label-add tipo=valor nodeName [fedora@ip-172-31-18-60 swarm]$ docker node update --label-add sexo=hombre miguel miguel Y hacemos deploy segun etiquetas: version: \"3\" services: hello: image: isx46410800/k19:hello deploy: replicas: 6 placement: constraints: [node.labels.sexo == hombre] ports: - \"80:80\" visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager] DOCKER REGISTRY Ser\u00eda la misma funci\u00f3n que crear una cuenta en Dockerhub y despu\u00e9s hacer: docker login docker tag nombre isx4610800/nombre:tag docker commit isx4610800/nombre:tag docker push isx4610800/nombre:tag Documentaci\u00f3n Docker Registry Lo creamos: docker run --name registry -v $PWD/data:/var/lib/registry -p 5000:5000 registry:2 Tenemos que crear un diretorio data donde estemos y podemos ponerle cualquier puerto. [isx46410800@miguel registry]$ ls data [isx46410800@miguel registry]$ docker run --name registry -v $PWD/data:/var/lib/registry -p 5000:5000 -d registry:2 a52169f2861d43450071e5bedeb01380fc2a26fe9030975b127b4a2452e5f62e [isx46410800@miguel registry]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a52169f2861d registry:2 \"/entrypoint.sh /etc\u2026\" 3 seconds ago Up 1 second 0.0.0.0:5000->5000/tcp registry Subimos una imagen: [isx46410800@miguel registry]$ docker pull hello-world Using default tag: latest latest: Pulling from library/hello-world Digest: sha256:4cf9c47f86df71d48364001ede3a4fcd85ae80ce02ebad74156906caff5378bc Status: Image is up to date for hello-world:latest [isx46410800@miguel registry]$ docker tag hello-world:latest localhost:5000/hello:registry [isx46410800@miguel registry]$ docker push localhost:5000/hello:registry The push refers to repository [localhost:5000/hello] 9c27e219663c: Pushed registry: digest: sha256:90659bf80b44ce6be8234e6ff90a1ac34acbeb826903b02cfa0da11c82cbc042 size: 525 [isx46410800@miguel registry]$ ls data/docker/registry/v2/repositories/hello/ _layers _manifests _uploads Bajar la imagen del registry: docker pull localhost:5000/hello:registry Subir/Bajar una imagen desde nuestra IP o hac\u00eda nuestra IP: [isx46410800@miguel registry]$ sudo vi /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H unix:// --insecure-registry 192.168.1.144:5000 systemctl daemon-reload [isx46410800@miguel registry]$ docker push 192.168.1.144:5000/hello:registry Ya podremos hacer pull/push a esta IP o por ejemplo a una IP de AWS donde tuvieramos el registry.","title":"Docker"},{"location":"docker/#docker","text":"","title":"DOCKER"},{"location":"docker/#instalacion","text":"Instalar Docker: $ sudo dnf remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine $ sudo dnf -y install dnf-plugins-core $ sudo dnf config-manager \\ --add-repo \\ https://download.docker.com/linux/fedora/docker-ce.repo $ sudo dnf install docker-ce docker-ce-cli containerd.io $ sudo systemctl start docker $ sudo docker run hello-world","title":"INSTALACI\u00d3N"},{"location":"docker/#comandos","text":"Crear un container Docker: docker run --rm -it fedora:27//isx46410800/netcat:latest /bin/bash docker run --rm --name ldap -h ldap -d imagen Descagar una imagen: docker pull fedora:27/imagen Ver imagenes de mi sistema: docker images Iniciar un container: docker start container Entrar dentro de un container en otra terminal: docker exec -it nomcontainer /bin/bash Entrar dentro de un container en detached: docker attach container Procesos de docker: docker ps -a docker top container \u00daltimo container creado: docker ps -l Document Root: docker info | grep -i root Memoria y cpu limitada y variables de entorno: docker run -m \"MB\" --cpuset-cpus 0-1 -e \"NAME=miguel\" Iniciar un container: docker start/stop IDcontainer Cambiar nombre container: docker rename IDcontainer NuevoNombre Borrar varias cosas: docker rm $(docker ps -aq) Docker version: docker version Info de un docker: docker info Lista de containers: docker container ls -a Borrar una imagen: docker rmi imagen Borrar un container: docker rm container Cambiar etiqueta de un container: docker tag imagen nombreNuevo:tag Borrar imagenes none: docker images -f dangling=true | xargs docker rmi Crear y subir una imagen a DockerHub: docker login docker tag imagen nuevoimagen:tag docker push nuevoimagen:tag Copiar un fichero a fuera del docker o dentro: docker cp file container:/opt/docker/. docker cp container:/opt/docker/. file Docker con puerto mapeado para el exterior: docker run --rm --name ldap -h ldap -p 389:389 -p 80:80 -it isx/ldap /bin/bash -p puertoMiMaquina:puertoContenedor -x dirActivo dentro del container","title":"COMANDOS"},{"location":"docker/#redes-en-docker","text":"docker network create NameRed docker network rm NameRed docker network inspect NameRed/container docker network create --subnet 172.19.0.0/16 NameRed","title":"Redes en Docker:"},{"location":"docker/#volumes-en-docker","text":"docker volume create NOMBREVOLUMEN docker volume ls docker volume inspect NOMVOLUMEN ls /var/lib/docker/volumes --privileged -v volumen:contenido docker run --rm --name ldap -h ldap -v NOMVOLUMEN:/var/lib/sambaloQueGuarda --privileged -it isx/ldap /bin/bash","title":"Volumes en Docker:"},{"location":"docker/#docker-compose","text":"docker-compose up #enciende todos los dockers del file compose.yml docker-compose -f fileCompose.yml up (-d) #elegimos que fichero encendemos del compose docker-compose down #apaga todo docker-compose ps docker-compose images docker-compose top nom_servei docker-compose port ldap 389 #servicio y puerto elegido docker-compose push/pull #subir o bajar images docker-compose logs ldap #logs del servicio elegido docker-compose pause/unpause ldap #pausar el servicio docker-compose start/stop ldap #iniciar servicio docker-compose scale ldap=2 #dos container ldap","title":"Docker Compose:"},{"location":"docker/#docker-swarm","text":"docker swarm init #inicia el docker swarm docker node ls # lista de nodos del swarm docker swarm join-tocken manager/worker #une workers o manager docker stack deploy -c docker_compose.yml nombreAPP #hace deploy docker stack ps NombreAPP #procesos docker stack ls #listado docker stack services nombreAPP #servicios docker stack rm NombreAPP #parar docker service ls docker service ps nombreservicio docker service inspect nomservicio docker service scale nomservicio=3 docker swarm leave --force #se desune del swarm docker swarm init --advertise-addr IP docker node update --label-add tipus=valor nomNode docker node inspect nomNode docker node update --availability active/drain/pause nomNode","title":"Docker SWARM:"},{"location":"docker/#arquitectura","text":"Docker Host es el servidor f\u00edsico/real donde se encuentra instalado Docker. Docker servicio: Docker Client. Rest API: es el intermediario encargado de comunicar al Docker client con el Docker server. Docker Server. Arquitectura Imagen docker (Dockerfile): Capa 1 - From: Sistema operativo minimo a elegir. Capa 2 - Run: lo que se quiera instalar, ejemplo apache. Capa 3 - CMD: lo que se tiene que poner para que cuando se arranque la imagen empiece con ese comando. Normalmente la activaci\u00f3n de un servicio en detached. SON CAPAS DE SOLO LECTURA Y NO SE PUEDE MODIFICAR NI BORRAR FROM centos:7 RUN yum install -y httpd CMD[\"apachectl\",\"-DFOREGROUND\"] Contenedor es una capa addicional en tiempo real de ejecuci\u00f3n, el empaquetado de todo el dockerfile. CAPA DE ESCRITURA. Recuerda que la capa del contenedor es temporal y que al eliminar el contenedor, todo lo que haya dentro de ella desaparecer\u00e1. Se diferencia de una m\u00e1quina virtual es que un contenedor es como un proceso m\u00e1s del sistema mientras que una MV hay que bajarse una ISO, instalar y agregar RAM, CPU y HD de nuestra propia m\u00e1quina real.","title":"ARQUITECTURA"},{"location":"docker/#docker-images","text":"Poniendo docker + SistemaOperativo podemos adquirir im\u00e1genes oficiales de los propios creadores para poder descargar del repositorio de DockerHub para nuestros contenedores. Por defecto, sino podemos un tag a la distribuci\u00f3n, nos coger\u00e1 el tag latest sino tendremos que poner la versi\u00f3n concreta como docker pull mongo:3.6-jessie . Se actualiza el tag si te bajas una imagen pero est\u00e1 recientemente actualizada y la antigua se queda en none . Vemos las im\u00e1genes con: docker images","title":"DOCKER IMAGES"},{"location":"docker/#dockerfile","text":"El fichero para crear nuestra imagen Docker se llama Dockerfile . Para construir la imagen es docker build -t/--tag imagen:tag . \u00f3 -f /rutaDockerfile .: docker build -t isx46410800/centos:inicial . Si modificamos algo del Dockerfile, hay que volver hacer el comando anterior. docker build -t isx46410800/centos:detached images/centos/. Ver el historial de construcci\u00f3n de capas de mi imagen: docker history -H imagen:tag Borrar una imagen: docker rmi idImagen Borrar un contenedor: docker rm contenedorName Ver los contenedores: docker ps / docker ps -a COMANDOS DOCKERFILE: FROM: desde donde se baja la imagen de SO. RUN: para instalar paquetes. COPY: copia ficheros de fuera hacia el container, ponemos ruta absoluta o del directorio actual. ADD: lo mismo que copy pero se puede pasar URLs y copiar\u00eda la info de la url a donde indiquemos. ENV: crea variable de entorno. WORKDIR: directorio activo al entrar. LABEL: es una etiqueta que puede ir en cualquier sitio, son informativas, es metadata. USER: quien ejecuta la tarea, por defecto es root. EXPOSE: puertos por donde escucha y puedes indicar qu\u00e9 puertos va funcionar mi contenedor. VOLUME: indica donde metemos la data cuando el container se muere. CMD: comando por el cual se ejecuta el container, normalmente un servicio detached CMD [\"apachectl\", \"-DFOREGORUND\"] . Ejemplo Dockerfile: # De que sistema operativo partimos FROM centos:7 # Labels de metadata extra LABEL author=\"Miguel Amor\u00f3s\" LABEL description=\"Mi primer container con Dockerfile\" # Que paquetes a instalar RUN yum install -y httpd # Creamos variables de entorno ENV saludo \"Hola Miguel\" # Directorio activo WORKDIR /var/www/html # Copiamos un fichero de fuera COPY ./listaCompra.txt ~/listaCompra.txt # Prueba de la variable RUN echo \"$saludo\" > ~/saludo.txt # Usuario que ejecuta la tarea RUN echo \"$(whoami)\" > ~/user1.txt RUN useradd miguel RUN useradd miguelito RUN echo \"miguel\" | passwd --stdin miguel RUN echo \"miguelito\" | passwd --stdin miguelito RUN chown miguel /var/www/html USER miguel RUN echo \"$(whoami)\" > ~/user2.txt USER root # Volumen para meter la chicha de cuando se muere el container VOLUME /tmp/ # Como arrancar el container CMD [\"apachectl\", \"-DFOREGROUND\"] Podemos usar un fichero .dockerignore para ignorar ficheros que no queremos que copiemos en el container. Para ver cualquier CMD para dejar por ejemplo un servicio encendido en detached se usa el comando: docker history -h SO / en docker hub Buenas pr\u00e1cticas, cuantas menos lineas de codigo, menos capas se utilizan al construir la imagen: RUN \\ useradd miguel && \\ useradd miguelito","title":"DOCKERFILE"},{"location":"docker/#cmd-vs-entrypoint","text":"CMD : Este comando se encarga de pasar valores por defecto a un contenedor. Entre estos valores se pueden pasar ejecutables. Este comando tiene tres posibles formas de pasar los par\u00e1metros: CMD [\u201cparametro1\u201d, \u201cparametro2\u201d, \u2026.] CMD [\"apachectl\", \"-DFOREGORUND\"] ENTRYPOINT : Este comando se ejecuta cuando se quiere ejecutar un ejecutable en el contenedor en su arranque. Los ejemplos tipo de su uso, son cuando se quiere levantar un servidor web, una base de datos, etc \u2026. ENTRYPOINT comando parametro1 parametro2 ENTRYPOINT cal 2020 ENTRYPOINT cal # Y pasar por comando los par\u00e1metros Como se ha comentado anteriormente el comando CMD se puede utilizar para pasar par\u00e1metros al comando ENRYPOINT. Una posible forma de realizarlo es: ENTRYPOINT [\"cal\"] CMD [\"2020\"]","title":"CMD VS ENTRYPOINT"},{"location":"docker/#centos-php-ssl","text":"Crear unaas llaves para certificado SSL: openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout dockerssl.key -out dockerssl.crt Ponemos de commom name localhost Dockerfile: # SO FROM centos:7 # paquetes de apache php y ssl RUN \\ yum -y install httpd php php-cli php-commom mod_ssl openssl # dir creado RUN mkdir /opt/docker # indice de comprobacion de php RUN echo \"<?php phpinfo(); ?>\" > /var/www/html/hola.php # web de prueba COPY startbootstrap /var/www/html # conf del ssl en el fichero de apache de conf COPY ssl.conf /etc/httpd/conf.d/default.conf # copia de certificados y startup COPY dockerssl.crt /opt/docker/dockerssl.crt COPY dockerssl.key /opt/docker/dockerssl.key COPY startup.sh /opt/docker/startup.sh # permisos del startup RUN chmod +x /opt/docker/startup.sh # escuchar puerto 443 EXPOSE 443 # arranque CMD [\"/opt/docker/startup.sh\"] Podemos eliminar imagenes none con el comando: docker images -f dangling=true | xargs docker rmi","title":"CENTOS-PHP-SSL"},{"location":"docker/#nginx-php","text":"Dockerfile: # SO FROM centos:7 # copiar el repo de nginx COPY nginx.repo /etc/yum.repos.d/nginx.repo # instalar paquetes RUN \\ yum -y install nginx --enablerepo=nginx && \\ yum -y install https://repo.ius.io/ius-release-el7.rpm && \\ yum -y install \\ php71u-fpm \\ php71u-mysqlnd \\ php71u-soap \\ php71u-xml \\ php71u-zip \\ php71u-jason \\ php71u-mcrypt \\ php71u-mbstring \\ php71u-zip \\ php71u-gd \\ --enablerepo=ius-archive && yum clean all # dir RUN mkdir /opt/docker # puertos escuchando EXPOSE 80 443 # volumenes VOLUME /var/www/html /var/log/nginx /var/log/php-fpm /var/lib/php-fpm # copiamos files de conf COPY index.php /var/www/html/index.php COPY nginx.conf /etc/nginx/conf.d/default.conf COPY startup.sh /opt/docker/startup.sh RUN chmod +x /opt/docker/startup.sh # arranque CMD /opt/docker/startup.sh","title":"NGINX-PHP"},{"location":"docker/#multi-stage-build","text":"Ejemplo de instalar varias capas de sistemas operativos: # SO FROM maven:3.5-alpine as builder # copiamos la carpeta dentro COPY app /app # entramos y empaquetamos RUN cd /app && mvn package # desde java FROM openjdk:8-alpine # copiamos desde maven y lanzamos la app COPY --from=builder /app/target/my-app-1.0-SNAPSHOT.jar /opt/app.jar # ejecutamos la app CMD java -jar /opt/app.jar [isx46410800@miguel multi]$ docker build -t isx46410800/java:app . [isx46410800@miguel multi]$ docker run -d isx46410800/java:app [isx46410800@miguel multi]$ docker logs trusting_galois Hello World! Otro ejemplo: FROM centos as test RUN fallocate -l 10M /opt/file1 RUN fallocate -l 20M /opt/file2 RUN fallocate -l 30M /opt/file3 FROM alpine COPY --from=test /opt/file2 /opt/myfile El centos con los 3 files serian 260M pero solo coge de alpine que son 4 y coge el file que le interesa. El total de la imagen es 24M y no la suma de todo.","title":"MULTI-STAGE-BUILD"},{"location":"docker/#prueba-real","text":"La idea de este articulo es que le des soluci\u00f3n al siguiente problema utilizando lo que has aprendido. En donde trabajas, solicitan una imagen Docker base para ser reutilizada. Tu tarea es crear un Dockerfile con las siguientes especificaciones y entregarlo a tu jefe: Sistema Operativo Base: CentOs o Debian (A tu elecci\u00f3n): Herramientas a instalar: Apache (\u00daltima versi\u00f3n) PHP 7.0 Debes usar buenas pr\u00e1cticas. Deber\u00e1s comprobar su funcionamiento creando un index.php con la funci\u00f3n de phpinfo. Dockerfile: # SO FROM centos:7 # Instalar apache RUN yum install -y httpd # A\u00f1adir repo de php para centos7 e instalamos version 7.0 RUN yum install -y http://rpms.remirepo.net/enterprise/remi-release-7.rpm && \\ yum update -y && \\ yum install -y yum-utils && \\ yum install -y php php-mcrypt php-cli php-gd php-curl php-mysql php-ldap php-zip php-fileinfo # Test de pagina index de php RUN echo \"<?php phpinfo(); ?>\" > /var/www/html/index.php # Volumenes VOLUME /var/www/html /var/log/php-fpm /var/lib/php-fpm # copia del startup y permisos COPY startup.sh opt/docker/startup.sh RUN chmod +x opt/docker/startup.sh # Arrancamos el servicio apache en segundo plano CMD [\"opt/docker/startup.sh\"] Startup.sh: #!/bin/bash # Iniciar contenedor echo \"iniciando container...\" # Encendiendo servicio apache apachectl -DFOREGROUND Imagen: docker build -t isx46410800/apache:php . Contenedor: docker run --name apache_php -p 80:80 -d isx46410800/apache:php Funcionamiento: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES abda827fb9f5 isx46410800/apache:php \"opt/docker/startup.\u2026\" 3 seconds ago Up 1 second 0.0.0.0:80->80/tcp apache_php Entramos a localhost:80 y nos saldr\u00e1 la web index.php","title":"PRUEBA REAL"},{"location":"docker/#docker-containers","text":"Son una instancia de ejecuci\u00f3n de una imagen Son temporales Capa de lectura y escritura Podemos crear varios partiendo de una misma imagen","title":"DOCKER CONTAINERS"},{"location":"docker/#listarmapeo-puertos","text":"docker ps / docker ps -a / docker ps -q(ids) PuertoLocal-PuertoContainer: docker run --name jenkins -p 8080:8080 -d jenkins 0.0.0.0:8080 todas las interfaces de nuestra m\u00e1quina est\u00e1n mapeadas al puerto 8080. Si mapeamos la misma imagen con otros puertos, tenemos varias imagenes en diferentes puertos. docker run --name jenkins -p :8080 -d jenkins Cualquier primer puerto libre que coja mi maquina se mapea al 8080.","title":"LISTAR/MAPEO PUERTOS"},{"location":"docker/#iniciardetenepausar","text":"Renombrar un contenedor: docker rename nombre_viejo nombre_nuevo Parar contenedor: docker stop nombre/id Iniciar contenedor: docker start nombre/id Reiniciar contenedor: docker restart nombre/id Entrar con una terminal al contenedor: docker exec -it nombre /bin/bash docker exec -u root/user -it nombre /bin/bash jenkins@bh45fdiu ---> user@id","title":"INICIAR/DETENE/PAUSAR"},{"location":"docker/#variables-de-entorno","text":"En Dockerfile: ENV variable valor En la linea de construir container: docker run --name jenkins -e \"varible=valor\" -p :8080 -d jenkins","title":"VARIABLES DE ENTORNO"},{"location":"docker/#mysql","text":"Se ha de instalar el mysql client en las versiones que descargamos de dockerhub, ya que nos falta eso para poder usarlo: yum install -y mysql / apt-get install mysql-client / dnf install mysql-community-server AYUDA MYSQL Creamos contenedor MYSQL siguiendo las instrucciones: docker run --name mysql-db --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -d mysql:5.7 docker run --name mysql-db --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -d mysql:5.7 fc84bdb48a389c9e7183fd633c0edfb03a7867104e1e867ef321a223f044fe87 docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fc84bdb48a38 mysql:5.7 \"docker-entrypoint.s\u2026\" 3 seconds ago Up 2 seconds 3306/tcp, 33060/tcp mysql-db Para que arranque con todo lo necesario el container: docker logs -f mysql-db Mensaje final de ready for connections por tal puerto. Para conectarnos tendr\u00edamos que haber mapeado el puerto, no obstante podemos conectarnos sabiendo la IP de nuestro container y a\u00f1adirsela al comando de mysql de conexion con docker inspect mysql-db : [isx46410800@miguel mysql]$ mysql -u root -h 172.17.0.3 -pjupiter Mapeando puerto(el de mysql del log) para tambi\u00e9n poder usarlo mi maquina local, con nuevas variables de entorno siguiendo la gu\u00eda, creando una db con usuario y passwd: docker run --name mysql-db2 --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -e \"MYSQL_DATABASE=docker-db\" -e \"MYSQL_USER=docker\" -e \"MYSQL_PASSWORD=docker\" -p 3333:3306 -d mysql:5.7 [isx46410800@miguel mysql]$ docker run --name mysql-db2 --rm -e \"MYSQL_ROOT_PASSWORD=jupiter\" -e \"MYSQL_DATABASE=docker-db\" -e \"MYSQL_USER=docker\" -e \"MYSQL_PASSWORD=docker\" -p 3333:3306 -d mysql:5.7 b24dff85293ef892f2f9033c231e7a594a1261e9b5924e2a955691cc403eee11 [isx46410800@miguel mysql]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b24dff85293e mysql:5.7 \"docker-entrypoint.s\u2026\" 4 seconds ago Up 2 seconds 33060/tcp, 0.0.0.0:3333->3306/tcp mysql-db2 b3254fe3706b mysql:5.7 \"docker-entrypoint.s\u2026\" 3 minutes ago Up 3 minutes 3306/tcp, 33060/tcp mysql-db Para que arranque con todo lo necesario el container: docker logs -f mysql-db2 Comprobamos por localhost: [isx46410800@miguel mysql]$ mysql -u root -h 127.0.0.1 -pjupiter --port=3333","title":"MYSQL"},{"location":"docker/#mongodb","text":"Descargamos imagen mongodb Encendemos dos containers: [isx46410800@miguel images]$ docker run --name mongodb -p 27017:27017 -d mongo [isx46410800@miguel images]$ docker run --name mongodb2 -p 27018:27017 -d mongo Para ver cuanta memoria usa, se utiliza la orden: docker stats mongodb Con algun software de bbdd podemos conectarnos a este container poniendo la IP y el puerto y ya entrar\u00edamos remotamente. robomongo es un cliente de mondodb para estas conexiones","title":"MONGODB"},{"location":"docker/#apachenginxtomcat","text":"Creamos nuestro container nginx oficial mapeado: [isx46410800@miguel images]$ docker run --name nginx -p 8888:80 -d nginx Creamos nuestro container apache(httpd) oficial mapeado: [isx46410800@miguel images]$ docker run --name apacheweb -p 9999:80 -d httpd Creamos nuestro container tomcat version alpine oficial mapeado: [isx46410800@miguel images]$ docker run --name tomcat -p 7070:8080 -d tomcat:9.0.8-jre8-alpine","title":"APACHE/NGINX/TOMCAT"},{"location":"docker/#postgres","text":"Descargamos imagen : docker pull postgres Creamos container postgres creando user, pass y db: docker run --name postgres -e \"POSTGRES_PASSWORD=jupiter\" -e \"POSTGRES_USER=docker\" -e \"POSTGRES_DB=docker-db\" -p 5432:5432 -d postgres Entramos y comprobamos: root@1ff7388f08b3:/# psql -d docker-db -U docker psql (13.0 (Debian 13.0-1.pgdg100+1)) Type \"help\" for help. docker-db=# docker-db=# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+--------+----------+------------+------------+------------------- docker-db | docker | UTF8 | en_US.utf8 | en_US.utf8 | postgres | docker | UTF8 | en_US.utf8 | en_US.utf8 | template0 | docker | UTF8 | en_US.utf8 | en_US.utf8 | =c/docker + | | | | | docker=CTc/docker template1 | docker | UTF8 | en_US.utf8 | en_US.utf8 | =c/docker + | | | | | docker=CTc/docker (4 rows)","title":"POSTGRES"},{"location":"docker/#jenkins","text":"Descargamos imagen : docker pull jenkins Creamos container jenkins: docker run --name jenkins -p 9090:8080 -d jenkins Luego tendr\u00edamos que copiar la contrase\u00f1a del fichero de password y arrancar la instalaci\u00f3n de Jenkins.","title":"JENKINS"},{"location":"docker/#limitar-recursos","text":"Ayuda con: docker --help | grep \"xxxx\"","title":"LIMITAR RECURSOS"},{"location":"docker/#memoria","text":"Para gestionar le memoria que puede usar mi docker se usa -m \"500Mb\" : docker run --name web -m \"500Mb\" -d httpd Lo comprobamos con: docker stats web --> LIMIT 10/500mb","title":"MEMORIA"},{"location":"docker/#cpu","text":"Vemos cuantas CPUs tenemos con: grep \"model name\" /proc/cpuinfo | wc -l --> 4 Indicar cual es la CPU que tiene usar cpuset-cpus 0 /0-1/0-3 : docker run --name web -m \"500Mb\" cpuset-cpus 0-2 -d httpd Comparte 3 cpus, la 0 , 1 y 2.","title":"CPU"},{"location":"docker/#copia-de-archivos","text":"De mi directorio al contenedor: docker cp index.html apache:/var/www/html Del contenedor a mi directorio: docker cp apache:/var/www/html/index.html /var/www/html/.","title":"COPIA DE ARCHIVOS"},{"location":"docker/#contenedor-a-imagen","text":"Para guardar todo lo a\u00f1adido dentro de un contenedor y convertirlo en una imagen guardada y actualizada se hace: docker commit imagen imagen-nueva Nota, todo lo que est\u00e1 dentro de un volumen NO SE GUARDAR\u00c1!!","title":"CONTENEDOR A IMAGEN"},{"location":"docker/#sobreescribir-cmd","text":"Para que el ultimo comando del docker no sea en la gran mayoria el /bin/bash o el servicio en foreground podemos poner otras \u00f3rdenes y el CMD ser\u00e1 diferente: docker run -p 8080:8080 -d centos python -m SimpleHTTPServer 8080 docker ps docker logs centos","title":"SOBREESCRIBIR CMD"},{"location":"docker/#destruir-container","text":"Para destruir containers autom\u00e1ticamente se usa en la linea de docker: docker run --rm...","title":"DESTRUIR CONTAINER"},{"location":"docker/#document-root","text":"El directorio root de Docker est\u00e1 en: docker info | grep -i root --> /var/libdocker Lo podemos cambiar a\u00f1adiendo en el fichero /var/lib/systemd/system/docker.service : linea ExecStart: xxxxx --data-root /opt/docker Tendriamos ahora en /opt/docker el nuevo document root. Cargamos y reiniciamos: systemctl daemon-reload systemctl restart docker Podemos copiar todo el contenido de /var/lib/docker a la nueva carpeta y tendriamos todo ahi.","title":"DOCUMENT ROOT"},{"location":"docker/#docker-volumes","text":"Los vol\u00famenes permiten almacenar data persistente del contenedor: Host Anonymous Named Volumes","title":"DOCKER VOLUMES"},{"location":"docker/#volumes-host","text":"Son los que se han de crear una carpeta antes y mapear a la carpeta del contenedor el cual queremos guardar la xixa: mkdir mysql docker run --name mysql-db -v mysql:/var/lib/sql -e \"MYSQL_ROOT_PASSWORD=jupiter\" -p 3306:3306 -d mysql:5-7","title":"VOLUMES HOST"},{"location":"docker/#volumes-anonymoys","text":"Son los que no ponemos ning\u00fan volumen de host y se nos a\u00f1ade a cualquier directorio al azar: docker run --name mysql-db -v /var/lib/sql -e \"MYSQL_ROOT_PASSWORD=jupiter\" -p 3306:3306 -d mysql:5-7 Lo podemos descubrir(Normalmente en /var/lib/docker/volumes // /user/home/docker/volumes ): docker inspect container | grep mount docker info | grep -i root","title":"VOLUMES ANONYMOYS"},{"location":"docker/#volumes-named-volumes","text":"Son los que creamos directamente con las ordenes: docker volume create my-vol Lo vemos con: docker volume ls Y se guardan en: /var/lib/docker/volumes // /user/home/docker/volumes docker run --name mysql-db -v my-vol:/var/lib/sql -e \"MYSQL_ROOT_PASSWORD=jupiter\" -p 3306:3306 -d mysql:5-7 Lo podemos descubrir(Normalmente en /user/home/docker/volumes ): docker volume inspect volumenName docker inspect container | grep mount docker info | grep -i root","title":"VOLUMES NAMED VOLUMES"},{"location":"docker/#prueba-real_1","text":"Dockerfile: # SO FROM centos:7 # Instalar apache RUN yum install -y httpd # A\u00f1adir repo de php para centos7 e instalamos version 7.0 RUN yum install -y http://rpms.remirepo.net/enterprise/remi-release-7.rpm && \\ yum update -y && \\ yum install -y yum-utils && \\ yum install -y php php-mcrypt php-cli php-gd php-curl php-mysql php-ldap php-zip php-fileinfo # Test de pagina index de php RUN echo \"<?php phpinfo(); ?>\" > /var/www/html/index.php # copia del startup y permisos COPY startup.sh /opt/docker/startup.sh RUN chmod +x /opt/docker/startup.sh # Arrancamos el servicio apache en segundo plano CMD [\"/opt/docker/startup.sh\"] Startup.sh: [isx46410800@miguel prueba2]$ cat startup.sh #!/bin/bash # Iniciar contenedor echo \"iniciando container...\" # Encendiendo servicio apache apachectl -DFOREGROUND Creaci\u00f3n volumen: [isx46410800@miguel prueba2]$ mkdir data_apache Imagen: Sending build context to Docker daemon 4.096kB docker build -t apache_volume . Contenedor con -m 500mb limite, uso en la cpu 0, -e las variables de entorno -v del volumen y -p del puerto indicado: docker run --rm --name apache_volume -m 500Mb --cpuset-cpus 0 -v $PWD/data_apache:/var/www/html/ -e \"ENV=dev\" -e \"VIRTUALIZATION=docker\" -p 5555:80 -d apache_volume + Resultados: set VIRTUALIZATION=docker ENV=dev","title":"PRUEBA REAL"},{"location":"docker/#docker-network","text":"Tipos: Bridge Host None Overlay La red por defecto es docker0 que se obtiene de ip -a : 4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 La red por defecto de docker es bridge : docker network inspect bridge Entre containers de misma red se pueden hacer ping","title":"DOCKER NETWORK"},{"location":"docker/#crear-redes","text":"Para crear redes: docker network create netA Para ver las redes: docker network ls | grep netA Opci\u00f3n -d para el driver de gesti\u00f3n de la red bridge: docker network create -d bridge --subnet 172.124.10.0/24 --gateway 172.124.10.1 netB","title":"CREAR REDES"},{"location":"docker/#ver-redes","text":"Para ver las redes creadas: docker network inspect netA","title":"VER REDES"},{"location":"docker/#agregarconectar-redes","text":"Para agregar una red a un contenedor se una --net : [isx46410800@miguel images]$ docker run --rm --name test1 --net netA -d nginx [isx46410800@miguel images]$ docker run --rm --name test2 --net netB -d nginx [isx46410800@miguel images]$ docker run --rm --name test3 --net netB -dit centos Con contenedores de la misma red creadas con el network create, podemos hacer ping a la ip o al nombre del container, es como si tuviera un DNS resolver: test1-----> 172.18.0.2 -------> netA test2-----> 172.124.10.2 -----> netB test3-----> 172.124.10.3 -----> netB [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test2\" PING test2 (172.124.10.2) 56(84) bytes of data. 64 bytes from test2.netB (172.124.10.2): icmp_seq=1 ttl=64 time=0.148 ms 64 bytes from test2.netB (172.124.10.2): icmp_seq=2 ttl=64 time=0.090 ms 64 bytes from test2.netB (172.124.10.2): icmp_seq=3 ttl=64 time=0.101 ms --- test2 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 26ms rtt min/avg/max/mdev = 0.090/0.113/0.148/0.025 ms [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 172.124.10.2\" PING 172.124.10.2 (172.124.10.2) 56(84) bytes of data. 64 bytes from 172.124.10.2: icmp_seq=1 ttl=64 time=0.060 ms 64 bytes from 172.124.10.2: icmp_seq=2 ttl=64 time=0.131 ms 64 bytes from 172.124.10.2: icmp_seq=3 ttl=64 time=0.085 ms --- 172.124.10.2 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 53ms rtt min/avg/max/mdev = 0.060/0.092/0.131/0.029 ms [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test1\" ping: test1: Name or service not known [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 172.18.0.2\" PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. --- 172.18.0.2 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 61ms Para conectar con diferentes redes se utiliza connect pero solo se conectan con el nombre del container y no por la ip: docker network connect netB test1 Quiere decir que conectamos a test1 a la red de netB. \"Networks\": { \"netA\": { \"IPAMConfig\": null, ... }, \"netB\": { \"IPAMConfig\": {}, .... Comprobamos: [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test1\" PING test1 (172.124.10.4) 56(84) bytes of data. 64 bytes from test1.netB (172.124.10.4): icmp_seq=1 ttl=64 time=0.101 ms 64 bytes from test1.netB (172.124.10.4): icmp_seq=2 ttl=64 time=0.086 ms 64 bytes from test1.netB (172.124.10.4): icmp_seq=3 ttl=64 time=0.085 ms --- test1 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 44ms rtt min/avg/max/mdev = 0.085/0.090/0.101/0.013 ms [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 172.18.0.2\" PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. --- 172.18.0.2 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 80ms Para volver a desconectar se utiliza: docker network disconnect netB test1 [isx46410800@miguel images]$ docker exec test3 /bin/bash -c \"ping -c3 test1\" ping: test1: Name or service not known","title":"AGREGAR/CONECTAR REDES"},{"location":"docker/#eliminar-redes","text":"Para eliminar redes: docker network remove netA netB","title":"ELIMINAR REDES"},{"location":"docker/#asignar-ips","text":"Creamos una red: docker network create -d bridge --subnet 172.124.10.0/24 --gateway 172.124.10.1 mynet Asignamos una IP aleatoria que coger\u00e1 del rango que creamos: docker run --rm --name test3 --net mynet -dit centos Asignar una IP concreta con el --ip : docker run --rm --name test3 --net mynet --ip 172.124.10.50 -dit centos","title":"ASIGNAR IPs"},{"location":"docker/#red-host","text":"Esta red ya existe por defecto con docker igual que la de brigde. Para conectarnos a esta red, que ser\u00eda la misma que la IP real de mi m\u00e1quina, tendr\u00eda todo, como el hostname, ser\u00eda: docker run --rm --name test3 --net host -dit centos [root@miguel /]# ip a 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp4s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether b4:b5:2f:cb:e2:65 brd ff:ff:ff:ff:ff:ff inet 192.168.1.104/24 brd 192.168.1.255 scope global dynamic enp4s0 valid_lft 66351sec preferred_lft 66351sec inet6 fe80::227a:4836:6df:23b/64 scope link valid_lft forever preferred_lft forever 3: wlp3s0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc mq state DOWN group default qlen 1000 link/ether f2:aa:5b:7e:c0:70 brd ff:ff:ff:ff:ff:ff 4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:9f:2c:43:a0 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:9fff:fe2c:43a0/64 scope link valid_lft forever preferred_lft forever [root@miguel /]# hostname miguel","title":"RED HOST"},{"location":"docker/#red-none","text":"Esta red ya existe por defecto con docker igual que la de brigde. Sirve para que los container que creemos no tengan ninguna IP, no tendr\u00eda apartado network: docker run --rm --name test3 --net none -dit centos","title":"RED NONE"},{"location":"docker/#exponer-ips-concretas","text":"Tomaremos como premisa que la IP de nuestro Docker Host es 192.168.100.2 Al exponer un puerto en un contenedor, por defecto, este utiliza todas las interfaces de nuestra m\u00e1quina. Ve\u00e1mos un ejemplo: docker run -d -p 8080:80 nginx 196a13fe6198e1a3e8d55aedda90882f6abd80f4cdf41b2f29219a9632e5e3a1 [docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 196a13fe6198 nginx \"nginx -g 'daemon of\u2026\" 5 seconds ago Up 2 seconds 0.0.0.0:8080->80/tcp frosty_jenning Si observamos la parte de ports, veremos un 0.0.0.0 . Esto significa que podremos acceder al servicio en el puerto 8080 utilizando localhost: 8080 , o 127.0.0.1:8080 , 192.168.100.2:8080 . Si quisi\u00e9ramos que sea accesible solamente v\u00eda localhost y no v\u00eda 192.168.100.2 , entonces har\u00edamos lo siguiente: docker run -d -p 127.0.0.1:8081:80 nginx 1d7e82ff15da55b8c774baae56827aef12d59ab848a5f5fb7f883d1f6d1ee6e1 docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1d7e82ff15da nginx \"nginx -g 'daemon of\u2026\" 3 seconds ago Up 1 second 127.0.0.1:8081->80/tcp musing_tesla Como observamos, ahora en vez de 0.0.0.0 vemos un 127.0.0.1 , lo que indica que nuestro servicio es accesible s\u00f3lo v\u00eda localhost y no usando 192.168.100.2","title":"EXPONER IPs CONCRETAS"},{"location":"docker/#docker-compose_1","text":"Herramienta de Docker de aplicaciones multicontenedor. El archivo es docker-compose.yml y contiene: Contenedores Im\u00e1genes Vol\u00famenes Redes","title":"DOCKER COMPOSE"},{"location":"docker/#instalacion_1","text":"Docker-compose del curso Instalaci\u00f3n: sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose","title":"INSTALACI\u00d3N"},{"location":"docker/#ejemplo","text":"Documentaci\u00f3n Siempre ha de ponerse si hay como secciones principales: Version Services Volumes Networks Ejemplo: version: '3' services: nginx: container_name: nginx image: nginx ports: - \"8080:80\" Para arrancarlo: docker-compose up -d Para apagarlo: docker-compose down","title":"EJEMPLO"},{"location":"docker/#variables-entorno","text":"Podemos poner las variables con la opci\u00f3n environment o a trav\u00e9s de un ficheros con todas las variables de entono con la opci\u00f3n env_file : version: '3' services: db: container_name: mysql image: mysql:5.7 ports: - \"3306:3306\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" version: '3' services: db: container_name: mysql image: mysql:5.7 ports: - \"3306:3306\" env_file: variables.env","title":"VARIABLES ENTORNO"},{"location":"docker/#volumenes","text":"Para los vol\u00famenes, podemos crearlo a\u00f1andiendolo en su secci\u00f3n y luego para asignarlo a un contenedor, a\u00f1adimos la subsecci\u00f3n volumes: version: '3' services: nginx: container_name: nginx image: nginx ports: - \"8081:80\" volumes: - \"my-vol:/usr/share/nginx/html\" volumes: my-vol: Creamos el volumen Named my-vol y lo a\u00f1adimos al contenedor de nginx. El volumen se crea en la ruta del Document Root--> docker info | grep -i root . [isx46410800@miguel nginx]$ docker-compose -f docker-compose_volumes.yml up -d Creating network \"nginx_default\" with the default driver Creating volume \"nginx_my-vol\" with default driver Creating nginx ... Creating nginx ... done se llama de prefijo nginx, porque siempre coge el nombre del directorio actual. Si vamos al volumen y cambiamos el contenido, al volver a formarse saldr\u00e1 lo que hayamos puesto. Para un volumen de host, hemos de poner la ruta absoluta de la carpeta que usaremos como volumen, en este caso creamos el volumen de html : version: '3' services: nginx: container_name: nginx image: nginx ports: - \"8081:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/nginx/html:/usr/share/nginx/html\"","title":"VOL\u00daMENES"},{"location":"docker/#redes","text":"Para crear redes, se ha de crear la seccion de networks y de cada contenedor si son diferentes, indicar la subsecci\u00f3n network indicando la red: version: '3' services: web: container_name: apache image: httpd ports: - \"8081:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/apache/html:/var/www/html\" networks: - my-net web2: container_name: apache2 image: httpd ports: - \"8082:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/apache/html:/var/www/html\" networks: - my-net networks: my-net: Creamos la red my-net y al estar en una red creada tiene DNS y podemos contactar por nombre de container, por nombre de servicio o por IP. root@3893b20251af:/usr/local/apache2# ping web PING web (172.21.0.2) 56(84) bytes of data. 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=1 ttl=64 time=0.056 ms 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=2 ttl=64 time=0.041 ms ^C --- web ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 16ms rtt min/avg/max/mdev = 0.041/0.048/0.056/0.010 ms root@3893b20251af:/usr/local/apache2# ping apache PING apache (172.21.0.2) 56(84) bytes of data. 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=1 ttl=64 time=0.046 ms 64 bytes from 3893b20251af (172.21.0.2): icmp_seq=2 ttl=64 time=0.056 ms ^C --- apache ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 65ms rtt min/avg/max/mdev = 0.046/0.051/0.056/0.005 ms root@3893b20251af:/usr/local/apache2# ping 172.21.0.2 PING 172.21.0.2 (172.21.0.2) 56(84) bytes of data. 64 bytes from 172.21.0.2: icmp_seq=1 ttl=64 time=0.080 ms ^C --- 172.21.0.2 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.080/0.080/0.080/0.000 ms","title":"REDES"},{"location":"docker/#build-dockerfile","text":"Para poder poner en el docker-compose nuestra imagen personalizada de un Dockerfile : Podemos o solo construir la imagen indicando donde est\u00e1 seg\u00fan si se llama Dockerfile o con otro nombre y en qu\u00e9 carpeta. Si se llama Dockerfile y ruta del directorio ('.' si est\u00e1 aqu\u00ed), ponemos la opci\u00f3n build . Le ponemos tambi\u00e9n nombre de la imagen a construir: version: '3' services: web: container_name: apache image: isx46410800/httpd-build build: . ports: - \"8081:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/build/html:/var/www/html\" networks: - my-net networks: my-net: Si se llama diferente a Dockerfile, ponemos context para ver en que directorio est\u00e1 y dockerfile y el nombre del archivo: web2: container_name: apache2 image: isx46410800/httpd-build2 build: context: . (directorio donde est\u00e1 el dockerfile) dockerfile: Dockerfile2 ports: - \"8082:80\" volumes: - \"/home/isx46410800/Documents/curso_docker/docker-compose/build/html:/var/www/html\" networks: - my-net La construimos con docker-compose build : [isx46410800@miguel build]$ docker-compose build Building web Step 1/1 : FROM httpd ---> 417af7dc28bc Successfully built 417af7dc28bc Successfully tagged isx46410800/httpd-build:latest O construir image y hacer container de golpe con docker-compose up -d : [isx46410800@miguel build]$ docker-compose up -d apache is up-to-date Recreating apache2 ... Recreating apache2 ... done [isx46410800@miguel build]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 240530fbf981 isx46410800/httpd-build2 \"httpd-foreground\" 4 seconds ago Up 2 seconds 0.0.0.0:8082->80/tcp apache2 e8722f8e391d isx46410800/httpd-build \"httpd-foreground\" 29 seconds ago Up 27 seconds 0.0.0.0:8081->80/tcp apache","title":"BUILD DOCKERFILE"},{"location":"docker/#cmd-cambiado","text":"Para cambiar el CMD de por defecto cuando se crea un contenedor podemos cambiarlo a\u00f1adiendo la subsecci\u00f3n command : version: '3' services: web: container_name: centos image: centos command: python -m SimpleHTTPServer 8080 ports: - \"8080:8080\" networks: - my-net networks: my-net:","title":"CMD CAMBIADO"},{"location":"docker/#limitar-recursos_1","text":"Solo se puede en versi\u00f3n 2 con opciones como mem_limit o cpuset : version: '2' services: web: container_name: nginx image: nginx:alpine mem_limit: 20Mb cpuset: \"0\"","title":"LIMITAR RECURSOS"},{"location":"docker/#politica-de-reinicio","text":"Existe la subsecci\u00f3n restart que indica cuando se reinicia un contenedor. Por defecto es restart: no , no se reinicie nunca pero est\u00e1n estas opciones: restart: no restart: always : siempre se reinicie cuando muera. restart: unless-stopped : siempre se reinicia a no ser que lo pare manualmente. restart: on failure : a no ser que tenga fallos distinto a 0, no se reinicia nunca.","title":"POL\u00cdTICA DE REINICIO"},{"location":"docker/#nombre-proyecto","text":"Cuando haces un docker-compose up -d coge el nombre de proyecto, redes, etc por el nombre del directorio actual, para cambiarlo: docker-compose -p proyecto_web up -d","title":"NOMBRE PROYECTO"},{"location":"docker/#diferente-docker-compose","text":"Cuando haces un docker-compose up -d coge el nombre de docker-compose.yml, para cambiarlo por un diferente: docker-compose -f nombre_docker_compose.yml up -d","title":"DIFERENTE DOCKER-COMPOSE"},{"location":"docker/#otros-comandos","text":"docker-compose up #enciende todos los dockers del file compose.yml docker-compose -f fileCompose.yml up (-d) #elegimos que fichero encendemos del compose docker-compose down #apaga todo docker-compose ps docker-compose images docker-compose top nom_servei docker-compose port ldap 389 #servicio y puerto elegido docker-compose push/pull #subir o bajar images docker-compose logs ldap #logs del servicio elegido docker-compose pause/unpause ldap #pausar el servicio docker-compose start/stop ldap #iniciar servicio docker-compose scale ldap=2 #dos container ldap","title":"OTROS COMANDOS"},{"location":"docker/#proyectos-docker-compose","text":"","title":"PROYECTOS DOCKER-COMPOSE"},{"location":"docker/#mysql-wordpress","text":"Podemos crear una base de datos mysql y un wordpress via web en el que la bbdd se comunique con el wordpress con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: bbdd: container_name: bd-mysql image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=wordpress\" - \"MYSQL_USER=wordpress\" - \"MYSQL_PASSWORD=wordpress\" ports: - \"3306:3306\" networks: - my-net wordpress: container_name: wordpress image: wordpress volumes: - \"$PWD/html:/var/www/html\" depends_on: - bbdd environment: - \"WORDPRESS_DB_HOST=bbdd:3306\" - \"WORDPRESS_DB_USER=wordpress\" - \"WORDPRESS_DB_PASSWORD=wordpress\" ports: - \"80:80\" networks: - my-net networks: my-net: Resultados:","title":"MYSQL-WORDPRESS"},{"location":"docker/#drupal-postgresql","text":"Podemos crear una base de datos postgres y un drupal via web en el que la bbdd se comunique con el drupal con la subsecci\u00f3n depends_on . Al entrar en drupal nos pedir\u00e1 la contrase\u00f1a que le ponemos de variable y por defecto el user es postgres : docker-compose.yml : version: '3' services: postgresql: container_name: postgres image: postgres:11 volumes: - \"$PWD/postgresql:/var/lib/postgresql/data\" environment: - \"POSTGRESQL_PASSWORD=jupiter\" networks: - my-net drupal: container_name: drupal image: drupal:8-apache volumes: - \"drupal:/var/www/html\" ports: - \"81:80\" networks: - my-net volumes: drupal: networks: my-net: Resultados:","title":"DRUPAL-POSTGRESQL"},{"location":"docker/#prestashop-mysql","text":"Podemos crear una base de datos mysql y un prestashop via web en el que la bbdd se comunique con el prestashop con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: bbdd: container_name: bd-mysql image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=prestashop\" - \"MYSQL_USER=prestashop\" - \"MYSQL_PASSWORD=prestashop\" ports: - \"3306:3306\" networks: - my-net prestashop: container_name: prestashop image: prestashop/prestashop volumes: - \"$PWD/html:/var/www/html\" depends_on: - bbdd environment: - \"DB_SERVER=bbdd:3306\" - \"DB_USER=presta\" - \"DB_PASSWD=presta\" - \"DB_NAME=presta\" ports: - \"80:80\" networks: - my-net networks: my-net: Resultados:","title":"PRESTASHOP-MYSQL"},{"location":"docker/#joomla-mysql","text":"Podemos crear una base de datos mysql y un joomla via web en el que la bbdd se comunique con el joomla con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: bbdd: container_name: bd-mysql image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=joomla\" - \"MYSQL_USER=joomla\" - \"MYSQL_PASSWORD=joomla\" ports: - \"3306:3306\" networks: - my-net joomla: container_name: joomla image: joomla volumes: - \"$PWD/html:/var/www/html\" environment: - \"JOOMLA_DB_HOST=bbdd\" - \"JOOMLA_DB_USER=joomla\" - \"JOOMLA_DB_PASSWORD=joomla\" - \"JOOMLA_DB_NAME=joomla\" ports: - \"80:80\" networks: - my-net networks: my-net: Resultados:","title":"JOOMLA-MYSQL"},{"location":"docker/#react-mongodb-nodejs","text":"Podemos crear una base de datos mongo y un react ecommerce hecha en node.js via web en el que la bbdd se comunique con el react con la subsecci\u00f3n depends_on : docker-compose.yml : version: '3' services: mongo: container_name: mongo image: mongo ports: - \"27017:27017\" volumes: - \"$PWD/data:/data/db\" networks: - my-net react: container_name: react-nodejs image: reactioncommerce/reaction depends_on: - mongo environment: - \"ROOT_URL=http://localhost\" - \"MONGO_URL=mongodb://mongo:27017/reaction\" ports: - \"3000:3000\" networks: - my-net networks: my-net: Resultados:","title":"REACT-MONGODB-NODE.JS"},{"location":"docker/#guacamole","text":"DOCUMENTACI\u00d3N Para sacar el fichero necesario de bbdd: $ docker run --rm guacamole/guacamole /opt/guacamole/bin/initdb.sh --postgres > initdb.sql Sirve para que desde el navegador te puedes conectar a escritorios remotos por ssh: docker-compose.yml : version: '3' services: db: container_name: guacamole-db networks: - net image: mysql:5.7 volumes: - $PWD/initdb.sql:/docker-entrypoint-initdb.d/initdb.sql - $PWD/data:/var/lib/mysql env_file: .env daemon: container_name: guacamole-daemon networks: - net image: guacamole/guacd depends_on: - db web: container_name: guacamole-web networks: - net image: guacamole/guacamole env_file: .env depends_on: - daemon proxy: container_name: guacamole-proxy networks: - net image: nginx ports: - \"80:80\" volumes: - $PWD/nginx.conf:/etc/nginx/nginx.conf depends_on: - web networks: net: Resultados:","title":"GUACAMOLE"},{"location":"docker/#zabbix","text":"Sirve para monitorizar servidores: Dockerfile de Zabbix: FROM centos:7 ENV ZABBIX_REPO http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm RUN \\ yum -y install $ZABBIX_REPO && \\ yum -y install \\ zabbix-get \\ zabbix-server-mysql \\ zabbix-web-mysql \\ zabbix-agent EXPOSE 80 443 COPY ./bin/start.sh /start.sh COPY ./conf/zabbix-http.conf /etc/httpd/conf.d/zabbix.conf COPY ./conf/zabbix-server.conf /etc/zabbix/zabbix_server.conf COPY ./conf/zabbix-conf.conf /etc/zabbix/web/zabbix.conf.php VOLUME /usr/share/zabbix /var/log/httpd RUN chmod +x /start.sh CMD /start.sh docker-compose.yml : version: '3' services: zabbix: container_name: zabbix-web image: zabbix build: . volumes: - \"$PWD/html:/usr/share/zabbix\" ports: - \"80:80\" networks: - net db: container_name: zabbix-db image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_USER: zabbix MYSQL_PASSWORD: zabbix MYSQL_DATABASE: zabbix volumes: - \"$PWD/data:/var/lib/mysql\" - \"$PWD/conf/create.sql:/docker-entrypoint-initdb.d/zabbix.sql\" ports: - \"3306:3306\" networks: - net networks: net: Resultados:","title":"ZABBIX"},{"location":"docker/#phpmyadmin-mysl","text":"Crear un docker-compose v3 con dos servicios: db admin. En el servicio DB, debe ir una db con mysql:5.7 y las credenciales de tu preferencia. En el admin, debes usar la imagen oficial de phpmyadmin, y por medio de redes, comunicarla con mysql. Debes exponer el puerto de tu preferencia y para validar que funcione, debes loguearte en el UI de phpmyadmin v\u00eda navegador, usando las credenciales del root de mysql. Docker-compose.yml: version: '3' services: db: container_name: mysql-db image: mysql:5.7 volumes: - \"$PWD/data:/var/lib/mysql\" environment: - \"MYSQL_ROOT_PASSWORD=jupiter\" - \"MYSQL_DATABASE=phpmyadmin\" - \"MYSQL_USER=miguel\" - \"MYSQL_PASSWORD=jupiter\" ports: - \"3306:3306\" networks: - my-net admin: container_name: phpmyadmin image: phpmyadmin/phpmyadmin depends_on: - db environment: - \"PMA_HOST=db\" - \"PMA_PASSWORD=jupiter\" - \"PMA_USER=miguel\" ports: - \"9090:80\" networks: - my-net networks: my-net: Resultados:","title":"PHPMYADMIN-MYSL"},{"location":"docker/#docker-swarm_1","text":"Orquestador de servicios en diferentes m\u00e1quinas obteniendo as\u00ed clusters en m\u00e1quinas. Tiene que haber m\u00ednimo un MANAGER , el resto son workers . Los nodos son los diferentes hosts que forman el swarm. Los stacks son el conjunts de APPs. La RED MESH es la red que hace que todos los nodes respondan a todos los servicios aunque no lo tengan en el suyo. Puerto 2377. TCP port 2377 for cluster management communications TCP and UDP port 7946 for communication among nodes UDP port 4789 for overlay network traffic El routing Mesh hace el load balance en puertos 80 y 9000. Las \u00f3rdenes docker stack / services solo se pueden hacer desde el manager. Los deploys se pueden hacer: Modo global: un servicio se despliega a todos aleatoriamente. Modo individual: para cada nodo, se despliega el servicio. Modo replicas: varias veces el mismo servicio.","title":"DOCKER SWARM"},{"location":"docker/#comandos-basicos","text":"docker swarm init docker swarm init --advertise-addr IP docker swarm join-token manager/worker docker swarm leave --force docker node ls docker node update --availability active/drain/pause nodeName docker node update --label-add tipo=valor nodeName docker node inspect nodeName docker stack deploy -c docker-compose.yml nombreApp docker stack ps nombreApp docker stack ls docker stack rm nombreApp docker stack services nombreApp docker service ls docker service ps nombreServicio docker service inspect nombreServicio docker service scale nombreServicio=2","title":"COMANDOS B\u00c1SICOS"},{"location":"docker/#inicializar","text":"Al que queremos como manager, le indicamos la siguiente orden con la IP p\u00fablica, este caso en una AWS: docker swarm init --advertise-addr 35.177.139.97 Nos dar\u00e1 un token que para cualquier nodo worker que queramos agregar al cluster,tendremos que poner eso. En nuestro caso en una m\u00e1quina AWS y otro el de mi casa: docker swarm join --token SWMTKN-1-2et2rzxn0kyfzsh8dmop8n2grqri001owhomhk7ggfr3tbls4b-587tzjo1dxtmpbpmrqldtddu1 35.177.139.97:2377","title":"INICIALIZAR"},{"location":"docker/#deploy-swarm","text":"Creamos un docker-compose.yml: version: \"3\" services: hello: image: isx46410800/k19:hello deploy: replicas: 6 ports: - \"80:80\" visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager] Desplegamos con la orden: docker stack deploy -c docker-compose.yml AppMiguel [fedora@ip-172-31-18-60 swarm]$ sudo docker stack deploy -c docker-compose.yml AppMiguel Creating network AppMiguel_default Creating service AppMiguel_hello Creating service AppMiguel_visualizer Comprobaciones de que estan los dos servicios k19:hello(6) y visualizer (1): [fedora@ip-172-31-18-60 swarm]$ docker stack ls NAME SERVICES ORCHESTRATOR AppMiguel 2 Swarm [fedora@ip-172-31-18-60 swarm]$ docker stack ps AppMiguel ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS bdbfuun9q7my AppMiguel_visualizer.1 dockersamples/visualizer:stable ip-172-31-18-60.eu-west-2.compute.internal Running Running about a minute ago w9f3dkx7rqic AppMiguel_hello.1 isx46410800/k19:hello ip-172-31-19-185.eu-west-2.compute.internal Running Running about a minute ago og22dynjynb1 AppMiguel_hello.2 isx46410800/k19:hello ip-172-31-18-60.eu-west-2.compute.internal Running Running about a minute ago 9qk5v9nixvc5 AppMiguel_hello.3 isx46410800/k19:hello miguel Running Running about a minute ago c0hgdykvxub7 AppMiguel_hello.4 isx46410800/k19:hello ip-172-31-19-185.eu-west-2.compute.internal Running Running about a minute ago rx4khrovr84t AppMiguel_hello.5 isx46410800/k19:hello ip-172-31-18-60.eu-west-2.compute.internal Running Running about a minute ago fyxes66lquup AppMiguel_hello.6 isx46410800/k19:hello miguel Running Running about a minute ago","title":"DEPLOY SWARM"},{"location":"docker/#escalar-servicios","text":"Como vemos los dos servicios que tenemos se llaman: [fedora@ip-172-31-18-60 swarm]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS p46df6579rup AppMiguel_hello replicated 6/6 isx46410800/k19:hello *:80->80/tcp 9n3iyb7ofvfx AppMiguel_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080->8080/tcp Escalamos con docker service scale AppMiguel_hello=3 : [fedora@ip-172-31-18-60 swarm]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS p46df6579rup AppMiguel_hello replicated 3/3 isx46410800/k19:hello *:80->80/tcp 9n3iyb7ofvfx AppMiguel_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080->8080/tcp","title":"ESCALAR SERVICIOS"},{"location":"docker/#modo-global","text":"Para que haya un servicio en cada hosts: version: \"3\" services: hello: image: isx46410800/k19:hello deploy: mode: global ports: - \"80:80\" visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager]","title":"MODO GLOBAL"},{"location":"docker/#nodo-drainpauseactive","text":"DRAIN: hace que el nodo, todos sus servicios se los pasa a otro. PAUSE: pausa el nodo, siguen sus servicios pero no acepta m\u00e1s. ACTIVE: volvemos activar el nodo. Orden: docker node update --availability active/drain/pause nodeName","title":"NODO DRAIN/PAUSE/ACTIVE"},{"location":"docker/#labels","text":"Podemos poner etiquetas a los nodos y hacer deploy segun etiquetas. Orden: docker node update --label-add tipo=valor nodeName [fedora@ip-172-31-18-60 swarm]$ docker node update --label-add sexo=hombre miguel miguel Y hacemos deploy segun etiquetas: version: \"3\" services: hello: image: isx46410800/k19:hello deploy: replicas: 6 placement: constraints: [node.labels.sexo == hombre] ports: - \"80:80\" visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager]","title":"LABELS"},{"location":"docker/#docker-registry","text":"Ser\u00eda la misma funci\u00f3n que crear una cuenta en Dockerhub y despu\u00e9s hacer: docker login docker tag nombre isx4610800/nombre:tag docker commit isx4610800/nombre:tag docker push isx4610800/nombre:tag Documentaci\u00f3n Docker Registry Lo creamos: docker run --name registry -v $PWD/data:/var/lib/registry -p 5000:5000 registry:2 Tenemos que crear un diretorio data donde estemos y podemos ponerle cualquier puerto. [isx46410800@miguel registry]$ ls data [isx46410800@miguel registry]$ docker run --name registry -v $PWD/data:/var/lib/registry -p 5000:5000 -d registry:2 a52169f2861d43450071e5bedeb01380fc2a26fe9030975b127b4a2452e5f62e [isx46410800@miguel registry]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a52169f2861d registry:2 \"/entrypoint.sh /etc\u2026\" 3 seconds ago Up 1 second 0.0.0.0:5000->5000/tcp registry Subimos una imagen: [isx46410800@miguel registry]$ docker pull hello-world Using default tag: latest latest: Pulling from library/hello-world Digest: sha256:4cf9c47f86df71d48364001ede3a4fcd85ae80ce02ebad74156906caff5378bc Status: Image is up to date for hello-world:latest [isx46410800@miguel registry]$ docker tag hello-world:latest localhost:5000/hello:registry [isx46410800@miguel registry]$ docker push localhost:5000/hello:registry The push refers to repository [localhost:5000/hello] 9c27e219663c: Pushed registry: digest: sha256:90659bf80b44ce6be8234e6ff90a1ac34acbeb826903b02cfa0da11c82cbc042 size: 525 [isx46410800@miguel registry]$ ls data/docker/registry/v2/repositories/hello/ _layers _manifests _uploads Bajar la imagen del registry: docker pull localhost:5000/hello:registry Subir/Bajar una imagen desde nuestra IP o hac\u00eda nuestra IP: [isx46410800@miguel registry]$ sudo vi /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H unix:// --insecure-registry 192.168.1.144:5000 systemctl daemon-reload [isx46410800@miguel registry]$ docker push 192.168.1.144:5000/hello:registry Ya podremos hacer pull/push a esta IP o por ejemplo a una IP de AWS donde tuvieramos el registry.","title":"DOCKER REGISTRY"},{"location":"files/","text":"Archivos importantes de Linux Usuarios del sistema (user.pass,uid,gid,gecos,home,shell) /etc/passwd Grupos del sistema (gnamegroup,pass,gid,list users) /etc/group Contrase\u00f1as de los usuarios (user,pass,last passwd change,min dias para cambiar pass,max dias con misma pass,warning dias aviso pass,inactivity,expire account) /etc/shadow Dominio DNS /etc/resolv.conf Lo que monta el sistema al encenderse(filesystem,mountpoint,type,options,dump,check): /etc/fstab Hosts del sistema (IP->nombre) /etc/hosts # #192.168.1.41 miguel Cambiar host de nombre: /etc/hostname miguel File para hacer crons: /etc/crontab Grub del sistema: /boot/grub2/grub.cfg Negar Ips ssh: /etc/hosts.deny Ficheros SSH /etc/ssh/sshd_config /etc/ssh/ssh_config Ficheros xinetd: /etc/xinetd.d Cosas exportables: /etc/exports Samba: /etc/samba/smb.conf Named: /etc/named APACHE HTTP: /etc/httpd/conf/httpd.conf /var/www/html/index.html Mail: /var/spool/mail /etc/mail/sendmailcf-mc Volumenes en Docker: /var/lib/docker/volumes Usuarios con los que hemos hecho contacto SSH: /.ssh/known_hosts /.ssh/authorized_keys","title":"Archivos Destacados"},{"location":"files/#archivos-importantes-de-linux","text":"Usuarios del sistema (user.pass,uid,gid,gecos,home,shell) /etc/passwd Grupos del sistema (gnamegroup,pass,gid,list users) /etc/group Contrase\u00f1as de los usuarios (user,pass,last passwd change,min dias para cambiar pass,max dias con misma pass,warning dias aviso pass,inactivity,expire account) /etc/shadow Dominio DNS /etc/resolv.conf Lo que monta el sistema al encenderse(filesystem,mountpoint,type,options,dump,check): /etc/fstab Hosts del sistema (IP->nombre) /etc/hosts # #192.168.1.41 miguel Cambiar host de nombre: /etc/hostname miguel File para hacer crons: /etc/crontab Grub del sistema: /boot/grub2/grub.cfg Negar Ips ssh: /etc/hosts.deny Ficheros SSH /etc/ssh/sshd_config /etc/ssh/ssh_config Ficheros xinetd: /etc/xinetd.d Cosas exportables: /etc/exports Samba: /etc/samba/smb.conf Named: /etc/named APACHE HTTP: /etc/httpd/conf/httpd.conf /var/www/html/index.html Mail: /var/spool/mail /etc/mail/sendmailcf-mc Volumenes en Docker: /var/lib/docker/volumes Usuarios con los que hemos hecho contacto SSH: /.ssh/known_hosts /.ssh/authorized_keys","title":"Archivos importantes de Linux"},{"location":"gitlab/","text":"Comandos para GIT git add . git status git commit -m \"...\" git init . git config --global user.email git config --global user.name \"isx46410800\" git config --global user.email \"miguel14amoros@gmail.com\" git config --global --list git branch -va git checkout branch git checkout -b branch git checkout -d/-D branch git checkout -- file git checkout head~3 git merge branch git show hash git log branch /hash commit git diff branch...branch git remote remove/add origin master/branch git push/pull/fetch -u origin master/branch git reset ~2 git reset HEAD~1 git div #gestionar conflictos de archivos git tag / git tag -l / git tag -l \"v1.0.0\"` git tag -a v1.4 -m \"my version 1.4\" git tag v1.4-lw git show v1.4 git push origin v1.5 / git push origin --tags git tag -d v1.4 git push origin --delete git checkout -b version2 v2.0.0 git blame file Obtener claves para GIT ssh-keygen Copiamos la publica en repo git Comprobamos con ssh -T xxx@gitlab.com Github pages Tutorial GithHub pages Creamos repositorio con extensi\u00f3n github.io->https://github.com/isx46410800/miguelamoros.github.io Clonamos, metemos la chicha de MKdocs. Hacemos un mkdocs build y un mkdocs gh-deploy y nos dar\u00e1 un link de nuestra web est\u00e1tica generada por mkdocs en Github. https://isx46410800.github.io/miguelamoros.github.io GitKraken Aplicaci\u00f3n de interfaz gr\u00e1fica para gestionar Git. Descargar GitKraken Git Tags/Releases Sirve para poner hasta donde es de mi c\u00f3digo las diferentes versiones. Crear tag version: Ejemplo v.1.0.0 : Primer n\u00famero es major number, cambio de n\u00famero es cambio grande de versi\u00f3n. Segundo n\u00famero es minor number, cambio no tan trascendente, un cambio de alguna funci\u00f3n, interfaz.. Tercer n\u00famero es un patx, correci\u00f3n de bugs. Listar tags: git tag / git tag -l / git tag -l \"v1.0.0\" Crear tags: git tag -a v1.4 -m \"my version 1.4\" git show v1.4 git tag v1.4-lw # etiqueta en .git ligera Subir tag porque el git push no sube los tags: git push origin v1.5 git push origin --tags #varios a la vez Borrar tags: git tag -d v1.4 git push origin --delete <tagname> Cambio de ramas a esa versi\u00f3n: git checkout -b version2 v2.0.0 Gitflow Flujo de trabajo en las que se puede a\u00f1adir nuevas caracter\u00edsticas, funciones, releases,etc... Deben existir las dos ramas master y develop. Creamos el GitFlow: git flow init Esto crear\u00e1 tres ramas auxiliares por defecto: feature/ release/ hotfix/ Features A\u00f1adir una nueva caracter\u00edstica o funci\u00f3n, lo crea como si fuera una nueva branch, feature/nameFeature: # Crear caracter\u00edstica git flow feature start create-contat-form # Confirmar los cambios que se hayan realizado git status git add -A git commit -m \"Create contact-form.php\" # Finalizar caracter\u00edstica git flow feature finish create-contat-form #Creaci\u00f3n de una rama de funci\u00f3n -Sin las extensiones de git-flow: git checkout develop git checkout -b feature_branch -Cuando se utiliza la extensi\u00f3n de git-flow: git flow feature start feature_branch #Finalizar feature -Sin las extensiones de git-flow: git checkout develop git merge feature_branch -Con las extensiones de git-flow: git flow feature finish feature_branch Hotfix Las ramas de mantenimiento o \"correcci\u00f3n\" (hotfix) se utilizan para reparar r\u00e1pidamente las publicaciones de producci\u00f3n. Las ramas de correcci\u00f3n son muy similares a las ramas de publicaci\u00f3n y a las de funci\u00f3n, salvo porque se basan en la maestra en vez de la de desarrollo. Es la \u00fanica rama que deber\u00eda bifurcarse directamente a partir de la maestra. Una vez que la soluci\u00f3n est\u00e9 completa, deber\u00eda fusionarse en la maestra y la de desarrollo (o la rama de publicaci\u00f3n actual), y la maestra deber\u00eda etiquetarse con un n\u00famero de versi\u00f3n actualizado. Tener una l\u00ednea de desarrollo espec\u00edfica para la soluci\u00f3n de errores permite que tu equipo aborde las incidencias sin interrumpir el resto del flujo de trabajo ni esperar al siguiente ciclo de publicaci\u00f3n. Puedes considerar las ramas de mantenimiento como ramas de publicaci\u00f3n ad hoc que trabajan directamente con la maestra. Una rama de correcci\u00f3n puede crearse utilizando los siguientes m\u00e9todos: # iniciar -Sin las extensiones de git-flow: git checkout master git checkout -b hotfix_branch -Cuando se utilizan las extensiones de git-flow: git flow hotfix start hotfix_branch # finalizar - sin git checkout master git merge hotfix_branch git checkout develop git merge hotfix_branch git branch -D hotfix_branch -con $ git flow hotfix finish hotfix_branch Releases Mandar una nueva versi\u00f3n a producci\u00f3n: # Crear liberaci\u00f3n git flow release start 1.0.0 # Confirmar los cambios que se hayan realizado git status git add -A git commit -m \"Add release notes\" # Finalizar liberaci\u00f3n git flow release finish 1.0.0 # Subir cambios de la rama develop git checkout develop git push # Subir cambios de la rama master git checkout master git push # iniciar release -Sin las extensiones de git-flow: git checkout develop git checkout -b release/0.1.0 -Cuando se utilizan las extensiones de git-flow: git flow release start 0.1.0 Switched to a new branch 'release/0.1.0' # finalizar -Sin las extensiones de git-flow: git checkout master git merge release/0.1.0 -con la extensi\u00f3n de git-flow: git flow release finish '0.1.0' Conclusi\u00f3n: En cada m\u00e1quina y directorio donde tengamos el repositorio la primera vez se debe inicializar el flujo de trabajo con git flow init. # Una vez finalizado un release o un hotfix se deben confirmar los cambios con un git push sobre develop y master # Se recomienda subir las etiquetas al repositorio con git push \u2013tags para tener un control de versiones sobre la rama de master. Emulador CMDER Descargar","title":"Gitlab"},{"location":"gitlab/#comandos-para-git","text":"git add . git status git commit -m \"...\" git init . git config --global user.email git config --global user.name \"isx46410800\" git config --global user.email \"miguel14amoros@gmail.com\" git config --global --list git branch -va git checkout branch git checkout -b branch git checkout -d/-D branch git checkout -- file git checkout head~3 git merge branch git show hash git log branch /hash commit git diff branch...branch git remote remove/add origin master/branch git push/pull/fetch -u origin master/branch git reset ~2 git reset HEAD~1 git div #gestionar conflictos de archivos git tag / git tag -l / git tag -l \"v1.0.0\"` git tag -a v1.4 -m \"my version 1.4\" git tag v1.4-lw git show v1.4 git push origin v1.5 / git push origin --tags git tag -d v1.4 git push origin --delete git checkout -b version2 v2.0.0 git blame file","title":"Comandos para GIT"},{"location":"gitlab/#obtener-claves-para-git","text":"ssh-keygen Copiamos la publica en repo git Comprobamos con ssh -T xxx@gitlab.com","title":"Obtener claves para GIT"},{"location":"gitlab/#github-pages","text":"Tutorial GithHub pages Creamos repositorio con extensi\u00f3n github.io->https://github.com/isx46410800/miguelamoros.github.io Clonamos, metemos la chicha de MKdocs. Hacemos un mkdocs build y un mkdocs gh-deploy y nos dar\u00e1 un link de nuestra web est\u00e1tica generada por mkdocs en Github. https://isx46410800.github.io/miguelamoros.github.io","title":"Github pages"},{"location":"gitlab/#gitkraken","text":"Aplicaci\u00f3n de interfaz gr\u00e1fica para gestionar Git. Descargar GitKraken","title":"GitKraken"},{"location":"gitlab/#git-tagsreleases","text":"Sirve para poner hasta donde es de mi c\u00f3digo las diferentes versiones. Crear tag version: Ejemplo v.1.0.0 : Primer n\u00famero es major number, cambio de n\u00famero es cambio grande de versi\u00f3n. Segundo n\u00famero es minor number, cambio no tan trascendente, un cambio de alguna funci\u00f3n, interfaz.. Tercer n\u00famero es un patx, correci\u00f3n de bugs. Listar tags: git tag / git tag -l / git tag -l \"v1.0.0\" Crear tags: git tag -a v1.4 -m \"my version 1.4\" git show v1.4 git tag v1.4-lw # etiqueta en .git ligera Subir tag porque el git push no sube los tags: git push origin v1.5 git push origin --tags #varios a la vez Borrar tags: git tag -d v1.4 git push origin --delete <tagname> Cambio de ramas a esa versi\u00f3n: git checkout -b version2 v2.0.0","title":"Git Tags/Releases"},{"location":"gitlab/#gitflow","text":"Flujo de trabajo en las que se puede a\u00f1adir nuevas caracter\u00edsticas, funciones, releases,etc... Deben existir las dos ramas master y develop. Creamos el GitFlow: git flow init Esto crear\u00e1 tres ramas auxiliares por defecto: feature/ release/ hotfix/","title":"Gitflow"},{"location":"gitlab/#features","text":"A\u00f1adir una nueva caracter\u00edstica o funci\u00f3n, lo crea como si fuera una nueva branch, feature/nameFeature: # Crear caracter\u00edstica git flow feature start create-contat-form # Confirmar los cambios que se hayan realizado git status git add -A git commit -m \"Create contact-form.php\" # Finalizar caracter\u00edstica git flow feature finish create-contat-form #Creaci\u00f3n de una rama de funci\u00f3n -Sin las extensiones de git-flow: git checkout develop git checkout -b feature_branch -Cuando se utiliza la extensi\u00f3n de git-flow: git flow feature start feature_branch #Finalizar feature -Sin las extensiones de git-flow: git checkout develop git merge feature_branch -Con las extensiones de git-flow: git flow feature finish feature_branch","title":"Features"},{"location":"gitlab/#hotfix","text":"Las ramas de mantenimiento o \"correcci\u00f3n\" (hotfix) se utilizan para reparar r\u00e1pidamente las publicaciones de producci\u00f3n. Las ramas de correcci\u00f3n son muy similares a las ramas de publicaci\u00f3n y a las de funci\u00f3n, salvo porque se basan en la maestra en vez de la de desarrollo. Es la \u00fanica rama que deber\u00eda bifurcarse directamente a partir de la maestra. Una vez que la soluci\u00f3n est\u00e9 completa, deber\u00eda fusionarse en la maestra y la de desarrollo (o la rama de publicaci\u00f3n actual), y la maestra deber\u00eda etiquetarse con un n\u00famero de versi\u00f3n actualizado. Tener una l\u00ednea de desarrollo espec\u00edfica para la soluci\u00f3n de errores permite que tu equipo aborde las incidencias sin interrumpir el resto del flujo de trabajo ni esperar al siguiente ciclo de publicaci\u00f3n. Puedes considerar las ramas de mantenimiento como ramas de publicaci\u00f3n ad hoc que trabajan directamente con la maestra. Una rama de correcci\u00f3n puede crearse utilizando los siguientes m\u00e9todos: # iniciar -Sin las extensiones de git-flow: git checkout master git checkout -b hotfix_branch -Cuando se utilizan las extensiones de git-flow: git flow hotfix start hotfix_branch # finalizar - sin git checkout master git merge hotfix_branch git checkout develop git merge hotfix_branch git branch -D hotfix_branch -con $ git flow hotfix finish hotfix_branch","title":"Hotfix"},{"location":"gitlab/#releases","text":"Mandar una nueva versi\u00f3n a producci\u00f3n: # Crear liberaci\u00f3n git flow release start 1.0.0 # Confirmar los cambios que se hayan realizado git status git add -A git commit -m \"Add release notes\" # Finalizar liberaci\u00f3n git flow release finish 1.0.0 # Subir cambios de la rama develop git checkout develop git push # Subir cambios de la rama master git checkout master git push # iniciar release -Sin las extensiones de git-flow: git checkout develop git checkout -b release/0.1.0 -Cuando se utilizan las extensiones de git-flow: git flow release start 0.1.0 Switched to a new branch 'release/0.1.0' # finalizar -Sin las extensiones de git-flow: git checkout master git merge release/0.1.0 -con la extensi\u00f3n de git-flow: git flow release finish '0.1.0' Conclusi\u00f3n: En cada m\u00e1quina y directorio donde tengamos el repositorio la primera vez se debe inicializar el flujo de trabajo con git flow init. # Una vez finalizado un release o un hotfix se deben confirmar los cambios con un git push sobre develop y master # Se recomienda subir las etiquetas al repositorio con git push \u2013tags para tener un control de versiones sobre la rama de master.","title":"Releases"},{"location":"gitlab/#emulador-cmder","text":"Descargar","title":"Emulador CMDER"},{"location":"jenkins/","text":"Jenkins Instalaci\u00f3n FEDORA Actualizar repositorios: sudo dnf update -y Instalar Java: sudo dnf install -y java Agregar repositorios de Jenkins: sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo sudo rpm --import http://pkg.jenkins.io/redhat/jenkins.io.key sudo rpm --import http://pkg.jenkins.io/redhat-stable/jenkins.io.key Instalar Jenkins: sudo dnf install -y jenkins Encender el servicio Jenkins: sudo systemctl start jenkins sudo systemctl status jenkins UBUNTU/DEBIAN Actualizar repositorios: sudo apt update Instalar Java: sudo apt install openjdk-8-jdk Agregar repositorios de Jenkins: wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add - sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' Instalar Jenkins: sudo apt update sudo apt install jenkins Encender el servicio Jenkins: sudo systemctl start jenkins sudo systemctl start jenkins DOCKER En un fichero docker-compose.yml: docker-compose up -d version: '3' services: jenkins: container_name: jenkins image: jenkins/jenkins ports: - \"9090:8080\" #cambiamos el 9090 de local nuestro volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net networks: net: NOTAS A TENER EN CUENTA Al instalar se crea el usuario y grupo Jenkins Jenkins trabaja en el directorio /var/lib/jenkins Los archivos de log est\u00e1n en /var/log/jenkins/jenkins.log Los par\u00e1metros de configuraci\u00f3n se encuentran en /etc/sysconfig/jenkins Por defecto, el puerto donde trabaja Jenkins es el 8080 La contrase\u00f1a de administrar Jenkins se encuentra en /var/jenkins_home/secrets/ini... PROYECTO CON PARAMETROS Aqu\u00ed podemos definir en la opci\u00f3n de this project is parameterized->string parameter se puede definir variable con valor para utilizarlas en la construcci\u00f3n del job con un build de execute shell . Tambi\u00e9n con choice parameter podemos hacer una variable con diferentes opciones a elegir: Tambi\u00e9n con boolean parameter podemos hacer una variable con true/false a elegir: Le pasamos los argumentos por las variables definidas en los par\u00e1metros y en el script. SSH Creacion SSH container Vamos a crear un container con ssh server para poder conectarnos alli y hacer cosas con Jenkins. Creamos un Dockerfile con Centos e instalamos el ssh, creamos su directorio ssh y creamos unas llaves con ssh-keygen -f nombre-key para pasarle la publica al ssh y asi conectarnos directamente sin password. Modificamos el docker-compose.yml a\u00f1adiendo el servicio de ssh para ello creamos un nuevo servicio con una image: build: context: ssh y luego haremos un docker-compose build y nos generar\u00e1 una imagen a trav\u00e9s del dockerfile de dentro de donde pongamos la ubicacion en context : # Instalamos un container con SO centos FROM centos:7 # Instalamos el ssh server para poder conectarnos por ssh alli RUN yum -y install openssh-server # Creamos un usuario con pass por stdin y creamos su dir ssh y con permisos RUN useradd remote_user && \\ echo \"1234\" | passwd remote_user --stdin && \\ mkdir /home/remote_user/.ssh && \\ chmod 700 /home/remote_user/.ssh # Copiamos nuestra clave publica ssh y la copiamos en el authorized(se crea) para conectarnos sin passwd COPY remotessh-key.pub /home/remote_user/.ssh/authorized_keys # Cambiamos propetario y grupo a todo lo que haya abajo del home remoteuser y damos permisos RUN chown remote_user:remote_user -R /home/remote_user && \\ chmod 600 /home/remote_user/.ssh/authorized_keys # Para que no de errores por primera vez en un container RUN /usr/sbin/sshd-keygen > /dev/null 2>&1 # activamos servicio ssh detached CMD /usr/sbin/sshd -D version: '3' services: jenkins: container_name: jenkins image: jenkins/jenkins ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net remote_host: container_name: remote_host image: remote_host build: context: ssh networks: - net networks: net: Hacemos el Docker-compose [isx46410800@miguel jenkins]$ docker-compose up -d jenkins is up-to-date Creating remote_host ... Creating remote_host ... done [isx46410800@miguel jenkins]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 172b5c2a9f99 remote_host \"/bin/sh -c '/usr/sb\u2026\" 6 seconds ago Up 3 seconds remote_host 4f52a64e7618 jenkins/jenkins \"/sbin/tini -- /usr/\u2026\" 5 hours ago Up 3 hours 50000/tcp, 0.0.0.0:9090->8080/tcp jenkins Credenciales Para comprobar que el SSH y JENKINS se ven y comunican, hacemos primero un ping desde Jenkins con ping remote_host y despues nos conectamos por ssh con el usuario creado alli ssh remote_user@remote_host o copiando la llave publica a Jenkins y desde ahi ssh -i remotessh-key remote_user@remote_host Configurar en Credentials -System - Global - credentials para poner las credenciales de SSH con el usuario creado en dockerfile y la llave privada creada. Luego vamos a Manage - system configuration - ssh remote host y ponemos el nombre del servicio ssh del docker, puerto y las credenciales creadas antes. Damos a check conection y comprobamos que sale successfully. Ejercicio mandar un job a maquina remota En este ejercicio lo que hacemos es que desde jenkins, mandamos un job creando un build - execute shell via ssh remote con las credenciales creadas de ssh a una m\u00e1quina remota. El resultado lo veremos dentro de esta maquina remota. BASE DE DATOS JENKINS Modificamos el docker-compose y creamos un servicio que ser\u00e1 una bbdd de mysql creando un volumen para que la xixa se guarde ah\u00ed al salir. Indicamos un nuevo campo de environment para poner el campo de la pass de root MYSQL_ROOT_PASSWORD=1234 . version: '3' services: jenkins: container_name: jenkins image: jenkins/jenkins ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net remote_host: container_name: remote_host image: remote_host build: context: ssh networks: - net db_host: container_name: db image: mysql:5.7 environment: - \"MYSQL_ROOT_PASSWORD=1234\" volumes: - $PWD/db_data:/var/lib/mysql networks: - net networks: net: Nos conectamos al container nuevo y para entrar a la bbdd se pone el comando mysql -u root -p . A\u00f1adimos lo siguiente en el Dockerfile para poder utilizar mysql por ssh y aws: # Instalamos mysql para poder conectarnos a la bbdd con mysql como comando RUN yum -y install mysql # Instalamos aws cli para amazon que est\u00e1 en un paquete de epel-pip RUN yum -y install epel-release && yum -y install python-pip && pip install --upgrade pip && yum -y install awscli Una vez cambiado hacemos un docker-compose build para que vuelva construir todo con los cambios nuevos y despues enchegar de nuevo con las nuevas construcciones docker-compose up -d . Hacemos un ping desde ssh container a db container para comprobar conexion: [root@e1825be6ec48 /]# ping db_host PING db_host (172.21.0.4) 56(84) bytes of data. 64 bytes from db.jenkins_net (172.21.0.4): icmp_seq=1 ttl=64 time=0.162 ms 64 bytes from db.jenkins_net (172.21.0.4): icmp_seq=2 ttl=64 time=0.083 ms Despu\u00e9s de esto nos conectamos a la bbdd del container desde ssh con opcion -h de host: [root@e1825be6ec48 /]# mysql -u root -h db_host -p Creacion bbdd simple MySQL [(none)]> show databases MySQL [(none)]> create database testdb; MySQL [(none)]> use testdb; MySQL [testdb]> create table info (name varchar(20), surname varchar(20), age int(2)); MySQL [testdb]> show tables; MySQL [testdb]> desc info; MySQL [testdb]> insert into info values('Miguel', 'Amoros', 27); Creaci\u00f3n Buckets en amazon Amazon Simple Storage Service (Amazon S3) es almacenamiento para Internet. Puede usar Amazon S3 para almacenar y recuperar cualquier cantidad de datos en cualquier momento y desde cualquier parte de la Web. Puede realizar estas tareas usando la Consola de administraci\u00f3n de AWS, que es una sencilla e intuitiva interfaz web. Amazon S3 almacena datos a modo de objetos dentro de buckets. Un objeto es un archivo y cualquier metadato opcional que describe el archivo. Para almacenar un archivo en Amazon S3, lo carga a un bucket. Al cargar un archivo como objeto, puede configurar permisos en el objeto y en cualquier metadato. Los buckets son contenedores de objetos. Puede tener uno o m\u00e1s buckets. Puede controlar el acceso de cada bucket, decidiendo qui\u00e9n puede crear, eliminar y enumerar objetos en \u00e9l. Tambi\u00e9n puede elegir la regi\u00f3n geogr\u00e1fica donde Amazon S3 almacenar\u00e1 el bucket y su contenido y ver los registros de acceso para el bucket y sus objetos. AWS - BUCKETS - CREATE BUCKET # jenkins-udemy-miguel Creamos un usuario de autenticaci\u00f3n para subir cosas al bucket: AWS-IAM-USERS-CREATE USER Opcion attach - full access - crear - download .csv key Dump de la bbdd [root@e1825be6ec48 /]# mysqldump -u root -h db_host -p1234 testdb > /tmp/dbdump.sql -- MySQL dump 10.14 Distrib 5.5.65-MariaDB, for Linux (x86_64) -- -- Host: db_host Database: testdb -- ------------------------------------------------------ -- Server version 5.7.31 /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */; /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */; /*!40101 SET NAMES utf8 */; /*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */; /*!40103 SET TIME_ZONE='+00:00' */; /*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */; /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */; /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */; /*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */; -- -- Table structure for table `info` -- DROP TABLE IF EXISTS `info`; /*!40101 SET @saved_cs_client = @@character_set_client */; /*!40101 SET character_set_client = utf8 */; CREATE TABLE `info` ( `name` varchar(20) DEFAULT NULL, `surname` varchar(20) DEFAULT NULL, `age` int(2) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=latin1; /*!40101 SET character_set_client = @saved_cs_client */; -- -- Dumping data for table `info` -- LOCK TABLES `info` WRITE; /*!40000 ALTER TABLE `info` DISABLE KEYS */; INSERT INTO `info` VALUES ('Miguel','Amoros',27); /*!40000 ALTER TABLE `info` ENABLE KEYS */; UNLOCK TABLES; /*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */; /*!40101 SET SQL_MODE=@OLD_SQL_MODE */; /*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */; /*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */; /*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */; /*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */; /*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */; /*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */; -- Dump completed on 2020-09-25 18:19:57 Configuramos a trav\u00e9s del aws cli de amazon para poder subir el DUMP al bucket de s3 de amazon. A trav\u00e9s de las credenciales obtenidas en bucket configuramos las variables de entorno. Las configuramos en el container de bbdd: ayuda Ahora con las credenciales podremos copiar el dump al bucket de amazon: ayuda [root@e1825be6ec48 /]# aws s3 cp /tmp/dbdump.sql s3://jenkins-udemy-miguel upload: tmp/dbdump.sql to s3://jenkins-udemy-miguel/dbdump.sql DUMP AUTOMATIZADO Creamos un script dentro del container de nuestra bbdd para poder hacer desde jenkins una conexion a la bbdd remota y subir a amazon el dump al bucket de almacenaje. #!/bin/bash # definimos unas variables DB_HOST=$1 DB_PASSWORD=$2 DB_NAME=$3 DATE=%(date +$H-%M-%S) AWS_SECRET=$4 BUCKET_NAME=$5 # hacemos el dump de a bbdd diciendo el nombre host servicio, pass y name de la bbdd, exportamos las variables aws para subir al bucket mysqldump -u root -h $DB_HOST -p$DB_PASSWORD $DB_NAME > /tmp/db-$DATE.sql && \\ export AWS_ACCESS_KEY_ID=AKIA5RIFOUI3AQMRXFFQ && \\ export AWS_SECRET_ACCESS_KEY=$AWS_SECRET && \\ aws s3 cp /tmp/db-$DATE.sql s3://$BUCKET_NAME Configuramos ahora las credenciales de la bbdd en jenkins con una variable de db_name y el passwd de nuestra bbdd que era 1234: Configuramos ahora las credenciales del s3 bucket en jenkins poniendo la passwd secret key: Ahora configuramos en Jenkins las variables parametrizadas del script de bbdd: Despu\u00e9s en la opci\u00f3n de entorno de ejecuci\u00f3n selecionamos la opci\u00f3n de usar secret text y ponemos las credenciales creadas anteriormente y la variable del script creado en la bbdd. Build por ssh: Automatizamos: A\u00f1adimos en el docker-compose estas lineas para que el script creado en tmp de la bbdd no se borre cuando se elimine, por lo tanto la chicha del script de fuera lo mandamos alli copiado: volumes: - $PWD/dumpremotessh-aws.sh:/tmp/dumpremote.sh Ahora si creamos en mysql otra db y en amazon otro bucket, cambiamos los parametros del job y nos crea lo mismo sin cambiar el script. Podemos tambien hacerlo manualmente y en vez de llamar al script, lo copiamos dentro y hace lo mismo (opci\u00f3n m\u00e1s fea). ANSIBLE Automatizaci\u00f3n de tareas hecho en python. Creamos un nuevo dockerfile: # sistema basado en jenkins FROM jenkins/jenkins # instalamos pip como root USER root RUN curl \"https://bootstrap.pypa.io/get-pip.py\" -o \"get-pip.py\" && python get-pip.py RUN pip install -U ansible USER jenkins Modificamos el docker-compose: jenkins: container_name: jenkins image: jenkins-ansible build: context: jenkins-ansible ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net Hacemos docker-compose build y up -d Creamos un fichero hosts con lenguaje ansible para crear nuestro primer fichero de inventario. # ARCHIVO DE INVENTARIO ANSIBLE # todas las variables se definen asi [all:vars] # todas las maquinas se conectaran por ssh ansible_connection = ssh [test] # aque maquina me voy a conectar con el nombre test1 y con que usuario y donde esta la llave privada para conectarme test1 ansible_host=remote_host ansible_user=remote_user ansible_private_key_file=/var/jenkins_home/ansible/remotessh-key Despues lo copiamos dentro de [isx46410800@miguel jenkins]$ cp hosts jenkins_home/ansible/ para que est\u00e9 dentro del container jenkins-ansible ya que aqui est\u00e1 el volumen de la xixa del container que se guarda. Comprobamos conexion de nuestro inventario ansible-jenkins con la m\u00e1quina ssh remote_host: jenkins@7cafd0984215:~/ansible$ ansible -m ping -i hosts test1 -m de modulo -i fichero y maquina test1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } Playbooks Los Playbooks describen configuraciones, despliegue, y orquestaci\u00f3n en Ansible. \u200b El formato del Playbook es YAML. \u200b Cada Playbook asocia un grupo de hosts a un conjunto de roles. Cada rol est\u00e1 representado por llamadas a lo que Ansible define como Tareas. Creamos primer fichero playbook: cat play.yml - hosts: test1 tasks: - shell: echo \"Hola Mundo desde Ansible y Jenkins\" > /tmp/hola-ansible.txt Para comprobar el funcionamiento: jenkins@7cafd0984215:~/ansible$ ansible-playbook -i hosts play.yml lo que hace es desde jenkins conectar el playbook a la maquina creada en ansible test1(que es remote_host de ssh container) por ssh. Instalamos el modulo ansible en jenkins y creamos un job con build de ansible playbook. Ponemos la ruta del playbook y la ruta del file hosts para la conexion. asi nos ahorramos poner toda la ruta de arriba, lo hacemos automatizado. Modificamos el fichero play.yml para pasar el texto por parametro: A\u00f1adimos los parametros y la variable extra para que en el script coja la variavle MSG con el parametro texto de arriba( seria como a\u00f1adir la opcion -e \"MSG=hola\" en hardcode): - hosts: test1 tasks: - debug: var: MSG TAGS Ponemos tags en nuestro script: - hosts: test1 tasks: - debug: var: MSG - debug: msg: \"Yo no me voy a ejecutar :(\" tags: no-exec - debug: msg: \"Yo s\u00ed me voy a ejecutar :)\" tags: si-exec solo se ejecutan las tareas que ponen en RUN de tags en jenkins, el resto no: PLUGIN: ANSICOLOR para que salga en colo en jenkins el resultado del job activando la opci\u00f3n color en configuracion del job. DB MYSQL Creamos en el container db una bbdd de people con registros en la tabla registro. De un file con 50 nombres, hacemos un script para meterlos todos en la bbdd: #!/bin/bash #iniciamos contador count=0 #mientras sea menos de 50 personas del archivo, coger los campos while [ $count -lt 50 ] do count=$((count+1)) nombre=$(nl people.txt | grep -w $count | tr -s '[:blank:]' ',' | cut -d',' -f3) apellido=$(nl people.txt | grep -w $count | tr -s '[:blank:]' ',' | cut -d',' -f4) edat=$(shuf -i 20-25 -n1) mysql -u root -p1234 people -e \"insert into registro values($id, '$nombre', '$apellido', $edat)\" echo \"$count, $nombre, $apellido importado\" sleep 5 done copiamos el script en el container db y lo ejecutamos para que se llene la bbdd creada. NGINX SERVER Creamos un container con nginx server y php a partir del container con ssh: # a partir de la imagen de ssh generada ya FROM remote_host # a\u00f1adimos el repo del web server nginx para centos COPY ./conf/nginx.repo /etc/yum.repos.d/nginx.repo # instalamos los paquetes necesarios y de php RUN \\ yum -y install nginx-1.12.2 openssl --enablerepo=nginx && \\ yum -y install https://repo.ius.io/ius-release-el7.rpm \\ https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm && \\ yum -y install \\ php71u-fpm \\ php71u-cli \\ php71u-mysqlnd \\ php71u-soap \\ php71u-xml \\ php71u-zip \\ php71u-json \\ php71u-mcrypt \\ php71u-mbstring \\ php71u-zip \\ php71u-gd \\ --enablerepo=ius-archive && yum clean all # abrimos los puertos por donde escuchar EXPOSE 80 443 # nos quedamos con los volumenes VOLUME /var/www/html /var/log/nginx /var/log/php-fpm /var/lib/php-fpm # comando para dar permisos al usuario creado d ssh RUN setfacl -R -m u:remote_user:rwx /var/www/html # copiamos el fichero de configuracion COPY ./conf/nginx.conf /etc/nginx/conf.d/default.conf # copiamos el fichero de empezar COPY ./bin/start.sh /start.sh # damos permisos de ejecucucion RUN chmod +x /start.sh # arranca el container con el script CMD /start.sh Modificamos el docker-compose para a\u00f1adir el nuevo container nginx-php con ssh: web: container_name: web image: ansible-web build: context: jenkins-ansible/web ports: - \"80:80\" networks: - net creamos un servicio web con el nombre container y la imagen ansible-web que se crea a trav\u00e9s del dockerfile con la ruta en context. Hacemos un docker-compose build y up. NOTA: desactivo con systemctl stop httpd porque escucha por el puerto 80 del web que queremos crear. Entramos al container web y a\u00f1adimos el indice de index.php: [root@7d0d237e1686 /]# cat /var/www/html/index.php <?php phpinfo(); ?> Hacemos esto solo de prueba para nuestro navegador Creamos una tabla que muestra la informaci\u00f3n via web: [isx46410800@miguel jenkins-ansible]$ docker cp table.j2 web:/var/www/html/index.php Para integrar el webserver en nuestro inventario de Ansible modificamos el fichero host de /jenkins_home/ansible/hosts y a\u00f1adimos el nuevo alias y el nombre servicio: web1 ansible_host=web ansible_user=remote_user ansible_private_key_file=/var/jenkins_home/ansible/remotessh-key Comprobamos yendo al container jenkins que es donde est\u00e1 instalado Ansible y lo comprobamos como la otra vez: jenkins@7cafd0984215:~/ansible$ pwd /var/jenkins_home/ansible **jenkins@7cafd0984215:~/ansible$ ansible -i hosts -m ping web1 web1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } **jenkins@7cafd0984215:~/ansible$ ansible -i hosts -m ping all test1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } web1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } Ahora vamos hacer lo anterior pero de manera automatizada en Jenkins. Para ello creamos un playbook nuevo: - hosts: web1 tasks: - name: Transfiere el template hacia web1 template: src: table.j2 dest: /var/www/html/index.php Cambiamos unos datos del fichero table.j2 donde contenia los datos a mostrar en el index.php para poder pasar las cosas por parametros en Jenkins: $sql = \"SELECT id, nombre, apellido, edat FROM registro where edat <= 25 and edat >=20\"; ----> CAMBIOS $sql = \"SELECT id, nombre, apellido, edat FROM registro {% IF EDAD is defined %} where edat = {{ EDAD }} {% endif %}\";---- queremos decir que si el parametro que pasamos EDAD est\u00e1 defenido haga la consulta donde la edad sea igual al parametro. Damos permisos para solucionar un fallo de poner escribir dentro del container web en la carpeta de html y despues dentro del container jenkins, probamos siempre lo del playbook: [root@7d0d237e1686 /]# chown remote_user:remote_user -R /var/www/html/ jenkins@7cafd0984215:~/ansible$ ansible-playbook -i hosts people.yml jenkins@7cafd0984215:~/ansible$ ansible-playbook -i hosts people.yml -e \"EDAD=22\" con y sin parametros, y el cambio lo vemos en el index.php del container web. Vamos a jenkins y automatizamos la tarea, poniendo una variable de opcion, el path del playbook y del fichero de hosts para conectar con la maquina y despues una extra variable que sera la variable que pasamos como parametro. SECURITY JENKINS Por defecto no est\u00e1 activado, pero si queremos que cualquier persona se pueda loguear al jenkins via navegador vamos a Manage Jenkins- Conf global Security y clicamos en la opcion de desactivar seguridad. Se puede activar la opci\u00f3n Allow users to sign up para permitir a usuarios crearse una cuenta para entrar a Jenkins igual que la otra opci\u00f3n de que tengan permisos especiales los usuarios registrados. Activamos lo de registrarse, nos ddesconectamos y creamos dos cuentas: Instalamos un potente plugin de seguidad que sirve para gestionar los roles y dar permisos a los usuarios: Role-based Authorization Strategy Entramos de nuevo a la conf de seguridad con el uuario admin y le damos a este role de usuarios. Veremos que nos aparece una nueva pesta\u00f1a de menu para que pueda gestionar los roles: MANAGE USERS Vamos a manage jenkins-manage users aqui podremos crear/borrar/modificar usuarios sin tener que hacerlos creando cuentas: MANAGE ROLES Vamos a manage jenkins-manage and assign roles y manage roles para gestionar los roles de un usuario: Creamos un nuevo role en role to add como por ejemplo que solo sea de lectura el role del usuario, solo podr\u00e1 ver jobs sin ejecutar ni nada mas: Ahora asignamos este role creado de solo-lectura a uno de los uusuarios. Vamos a manage jenkins-manage and assign roles y assign role. Veremos al loguearlos despues que solo puede ver, solo lectura. Si modificamos el manage role y le ponemos que pueda read los jobs, al loguearse veremos que pueda ver los jobs almenos. Ahora creamos un role de poder ejecutar y ver los jobs y se lo asignamos: Ahora lo que queremos hacer es que un usuario en vez de ver todos los jobs, solo veas los que le digamos y pueda hacer build solo a esos. Para ello le quitamos el read the jobs y creamos un item role y le a\u00f1adimos un patron para ver solo jobs con ese patron. TRIPS AND TICKS Variables de entorno Lista de variables de entorno propias de Jenkins: echo \"BUILD_NUMBER: $BUILD_NUMBER\" echo \"BUILD_ID: $BUILD_ID\" echo \"BUILD_URL: $BUILD_URL\" echo \"JOB_NAME: $JOB_NAME\" echo \"JAVA_HOME: $JAVA_HOME\" echo \"JENKINS_URL: $JENKINS_URL\" lista variables Resultado de un simple job: Console Output Started by user admin Running as SYSTEM Building in workspace /var/jenkins_home/workspace/7-ENV [7-ENV] $ /bin/sh -xe /tmp/jenkins7847738549255029537.sh + echo BUILD_NUMBER: 1 BUILD_NUMBER: 1 + echo BUILD_ID: 1 BUILD_ID: 1 + echo BUILD_URL: http://localhost:9090/job/7-ENV/1/ BUILD_URL: http://localhost:9090/job/7-ENV/1/ + echo JOB_NAME: 7-ENV JOB_NAME: 7-ENV + echo JAVA_HOME: /usr/local/openjdk-8 JAVA_HOME: /usr/local/openjdk-8 + echo JENKINS_URL: http://localhost:9090/ JENKINS_URL: http://localhost:9090/ Finished: SUCCESS Podemos crear propias en manage jenkins- conf sistem y clicamos en la opcion de variables de entorno: echo \"PLATAFORMA: $PLATAFORMA\" echo \"PAIS: $PAIS\" + echo PLATAFORMA: UDEMY PLATAFORMA: UDEMY + echo PAIS: ESPA\u00d1A PAIS: ESPA\u00d1A Cambio URL Podemos crear propias en manage jenkins- conf sistem y clicamos en la opcion de Jenkins Location: Cambiamos la url por la de dns (/etc/hosts): 192.168.1.44 host2 127.0.0.1 loopback.jenkins http://loopback.jenkins:9090/ CRON Podemos ver una chuleta de crontab A la hora de construir un job hay que dar en la opci\u00f3n de Build triggers - execute periodically 5 * * * * cada 5 minutos Podemos poner una H en un * y quiere decir que coger\u00e1 cuando pueda de ese momento para que haya menos carga de jobs por si hay otras tareas tambi\u00e9n y no se sobrecargue. GATILLAR JOBS Quiere decir que lancemos un job sin necesidad sin entrar a jenkins y construir el job, sino desde un script desde la terminal. Vamos a Manage and Assign Roles - Manage Roles y creamos uno que se llame trigger-jobs. Creamos un usuario jenkins y le asignamos este rol. Va relacionado con la opci\u00f3n Crumb Issuer de seguridad global,ya viene por defecto. Instalamos un plugin para evitar error: Buscando en Internet he visto que el error se produce porque a partir de cierta versi\u00f3n de Jenkins (2.176.x) es necesario que ambas peticiones (para obtener el crumb y para lanzar el job) est\u00e9n dentro de la misma \"sesi\u00f3n web\" (ver https://jenkins.io/doc/upgrade-guide/2.176/#upgrading-to-jenkins-lts-2-176-3). Siguiendo la recomendaci\u00f3n en esa misma p\u00e1gina, instal\u00e9 el plugin \"Strict Crumb Issuer\" y lo configur\u00e9 para que no fuera necesario estar en la misma sesi\u00f3n web: [isx46410800@miguel jenkins]$ cat crumb.sh # generamos el crum, el usuario que queremos, -s de silencioso el output y la url de jenkins crumb=$(curl -u \"jenkins:1234\" -s 'http://127.0.0.1:9090/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)') # autenticamos el crumb a traves de variable pasada de crumb curl -u \"jenkins:1234\" -H \"$crumb\" -X POST http://127.0.0.1:9090/job/7-ENV/build?delay=0sec Ahora con parametros: [isx46410800@miguel jenkins]$ cat crumb.sh # generamos el crum, el usuario que queremos, -s de silencioso el output y la url de jenkins crumb=$(curl -u \"jenkins:1234\" -s 'http://127.0.0.1:9090/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)') #con parametros curl -u \"jenkins:1234\" -H \"$crumb\" -X POST http://127.0.0.1:9090/job/6-db-playbook-ansible-nginx-php/buildWithParameters?EDAD=23 [isx46410800@miguel jenkins]$ bash crumb.sh nos sale el index-php solo con los de 22 MAIL Configurar envio de notificaciones Plugin a instalar Email Extension Plugin Vamos a manage jenkins-conf sistem - E-mail Notification Vamos a Amazon - SES - Stmp settings y copiamos la direccion del mail email-smtp.eu-west-2.amazonaws.com Despues le damos a crear credenciales stmp de amazon y ponemos un usuario jenkins-user : [isx46410800@miguel jenkins]$ cat credentials.csv IAM User Name,Smtp Username,Smtp Password \"jenkins-user\",AKIA5RIFOUI3LWLFOOG7,BFW538mmwDzTr4eaMMAzSVlQA57NeH1/Hqvnn3ABJsZ6 Creamos un email de admin en amazon: Probamos el email: Test e-mail recipient \ufffc Test configuration: miguel14amoros@gmail.com Email was successfully sent Gmail como server de correo Ponemos nuestro gmail como direccion de correo y luego rellenamos la parte de correo: Email de error Cogemos un build e indicamos en la opcion post-build nuestro correo para si falla, enviarnos email. Escribimos algo mal y recibimos el email. Lo ponemos correcto y recibimos email de que todo va bien. Si sigue yendo bien, no recibimos email. MAVEN Instalacion Instalamos el plugin Maven Integration Ejemplo de git maven: maven sample app Configuracion de un job Configuracion del job: Los workspace son las mesas de trabajo donde se deja lo clonado de git y ahi tenemos toda la xixa para trabajar en jenkins. Configuracion e instalamos maven: A\u00f1adimos el paso de construir tarea de maven: lo que hace todo el proceso es descargar el codigo fuente de git, instalar la version de maven indicada y despues ejecuta el comando de -B -DskipTests clean package de maven que jenkins coja el codigo fuente y lo construya(package) un .jar de la app y se ejecuta en un workspaces donde jenkins crea un pom.xml que necesita maven. Despues a\u00f1adimos que despues de todo esto haga un test: A\u00f1adimos otra opci\u00f3n de desplegar el jar: + java -jar /var/jenkins_home/workspace/8-MavenJob/target/my-app-1.0-SNAPSHOT.jar Registrar los resultados A\u00f1adimos acci\u00f3n para ejecutar despues(post build) con la opcion de publicar los resultados de tests Junit(Publish JUnit test result report)--> target/surefire-reports Vemos que nos sale una grafica y una nueva pesta\u00f1a de test results: Archivar los jar A\u00f1adimos otra acci\u00f3n post build de archivar los *.jar y vemos que nos aparece una nueva pesta\u00f1a para descargar el archivo jar: Podemos a\u00f1adir la alerta de email si falla: GIT SERVER Creamos en el docker-compose un git-server siguiendo estas instruciones Cambiamos el puerto local del servicio web para que no se colpasen: web: container_name: web image: ansible-web build: context: jenkins-ansible/web ports: - \"8888:80\" networks: - net git: container_name: git-server hostname: gitlab.example.com ports: - \"443:443\" - \"80:80\" volumes: - \"/srv/gitlab/config:/etc/gitlab\" - \"/srv/gitlab/logs:/var/log/gitlab\" - \"/srv/gitlab/data:/var/opt/gitlab\" image: gitlab/gitlab-ce networks: - net Ponemos la url en /etc/hosts para asignar la ip al servicio mejor: 127.0.0.1 gitlab.example.com Entramos, nos registramos con root y 12345678 y creamos un grupo llamado jenkinsci . Despues creamos un proyecto, lo llamamos maven . Despues vamos a usuarios y creamos un usuario nuevo miguel con acceso regular. Luego editamos el usuario y le ponemos una contrase\u00f1a 12345678 . Luego vamos al proyecto creado de jenkinsci/maven y vamos a manage settings y a\u00f1adimos como usuario developer al user creado. NOTA: lo pondremos en modo mantainer, un nivel superior, para poder hacer el primer push al crear la rama master con git pusg -u origin master. Despues clonamos el repo de maven con el simple app maven y clonamos el nuevo repo vacio y copiamos los archivos de uno a otro, hacemos un push y ya tenemos todo el contenido. CAMBIO URL MAVEN/GIT/JENKINS Vemos la url de mi repo git en: [isx46410800@miguel maven]$ cat .git/config [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \"origin\"] url = http://gitlab.example.com/jenkinsci/maven.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \"master\"] remote = origin merge = refs/heads/master En jenkins vamos a credenciales y le damos al de la llave naranja y creamos las credenciales del git de dentro del docker: Una vez hecho esto, vamos a configurar el job que teniamos de maven y cambiamos el SCM por la url de nuestro git creado. Deberiamos poner la url de nuestro git http://gitlab.example.com/jenkinsci/maven.git pero como nuestro servicio especificado en docker-compose lo tenemos como git, ponemos http://git/jenkinsci/maven.git . Ponemos las credenciales de nuestro git y construimos el build viendo que lo descarga de nuestro gir y funciona. Vamos al container de git-server dentro donde se esconde el contenido del repo maven: root@gitlab:/var/opt/gitlab/git-data/repositories/@hashed/6b/86/6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b.git Creamos dentro el directorio mkdir custom_hooks y el file post-receive #!/bin/bash # Get branch name from ref head if ! [ -t 0 ]; then read -a ref fi IFS='/' read -ra REF <<< \"${ref[2]}\" branch=\"${REF[2]}\" # preguntamos por el nombre del branch(master) # si es master hacemos el gatillar con crumb if [ $branch == \"master\" ]; then crumb=$(curl -u \"jenkins:1234\" -s 'http://jenkins.local:9090/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)') curl -u \"jenkins:1234\" -H \"$crumb\" -X POST http://jenkins.local:9090/job/8-MavenJob/build?delay=0sec if [ $? -eq 0 ] ; then echo \"*** Ok\" else echo \"*** Error\" fi fi Con esto lo que queremos hacer es que cuando hagamos un push al repo git, como hay cambios, se haga automatico un job en el job de maven. Despues le damos chmod +x post-receive y chown git:git custom_hooks Hacemos un push y se deber\u00eda hacer automatico el build de maven job. JOB DSL Instalamos el plugin Job DSL nos permite crear jobs codigo SEED JOB es el job padre que har\u00e1 ejecutar a los jobs hijos. Construimos un job y vamos a la opci\u00f3n build - process job DSLs Documentaci\u00f3n de job dsl SEED JOB Ejemplo estructura: job('job_dsl_example') { } DESCRIPCION Indicamos la descripcion del job hijo: job('job_dsl_example') { description('This is my awesome Job') } Con la descripcion te crea un job hijo que te dice la descripcion indicada PAR\u00c1METROS Para poner parametros en el job: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } } Te crea el job fijo con una descripcion y tres variables parametrizadas. SCM La administracion del codigo fuente: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } } Con SCM definimos la url y la branch del codigo fuente git en este caso. TRIGGERS Cron de tareas: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } } Definimos un trigger en este caso con un cron. STEPS Son los pasos que va hacer nuestro job, lo que se va ir ejecutando. job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { shell(\"echo 'Hello World'\") } } Paso de hacer un hello world MAILER Sirve para indicar el aviso de notificaciones por correo: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { shell(\"echo 'Hello World'\") shell(\"echo 'Hello World2'\") } publishers { mailer('me@example.com', true, true) } } Indicamos el aviso de notificaciones. JOB DE ANSIBLE EN DSL En este ejemplo vamos a hacer el job n\u00famero de 6 de ansible con gnix php jenkins en JOBDSL: esto es lo que teniamos en el job6 de ansible. EJEMPLO JOBDSL, LO M\u00c1S UTILIZADO: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { wrappers { colorizeOutput(colorMap = 'xterm') } ansiblePlaybook('/etc/ansible/plays/i2b-cl/some_playbook.yml') { inventoryPath('/etc/ansible/plays/i2b-cl/hosts') tags('cool') forks(1) colorizedOutput(true) additionalParameters('--vault-password-file $HOME/pass-vault/i2b-cl.txt') extraVars { extraVar(\"whoami\", '${param1}', false) extraVar(\"my_pass\", 'some_pass', true) } } } publishers { mailer('me@example.com', true, true) } } AYUDA ANSIBLE DSL Creamos nuestro archivo jobdsl de ansible.js: job('ansible-dsl') { description('Este es un job de ansible con dsl') parameters { choiceParam('EDAD', ['20', '21', '22', '23', '24', '25']) } steps { wrappers { colorizeOutput(colorMap = 'xterm') } ansiblePlaybook('/var/jenkins_home/ansible/people.yml') { inventoryPath('/var/jenkins_home/ansible/hosts') colorizedOutput(true) extraVars { extraVar(\"EDAD\", '${EDAD}', false) } } } } Nos da un error que ya nos daba en su momento y lo que tenemos que hacer es entrar al contenedor web y cambiar los permisos: chown remote_user:remote_user -R /var/www/html/ JOB DE MAVEN EN DSL Seguimos el job8 de maven pero ahora en DSL: job('maven_dsl') { description('Maven dsl project') scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master', {node -> node / 'extensions' << '' }) } steps { maven { mavenInstallation('jenkins-maven') goals('-B -DskipTests clean package') } maven { mavenInstallation('jenkins-maven') goals('test') } shell(''' echo \"**************************\" echo \"Desplegando el jar\" echo \"**************************\" java -jar /var/jenkins_home/workspace/8-MavenJob/target/my-app-1.0-SNAPSHOT.jar ''') } publishers { archiveArtifacts('target/*.jar') archiveJunit('target/surefire-reports/*.xml') mailer('miguel14amoros@gmail.com', true, true) } } DSL en GIT Vamos a nuestro git-server http://gitlab.example.com:443 Creamos un nuevo proyecto dsl y lo clonamos y creamos un fichero copiando todo lo hecho en jobdsl padre: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { shell(\"echo 'Hello World'\") shell(\"echo 'Hello World2'\") } publishers { mailer('me@example.com', true, true) } } job('ansible-dsl') { description('Este es un job de ansible con dsl') parameters { choiceParam('EDAD', ['20', '21', '22', '23', '24', '25']) } steps { wrappers { colorizeOutput(colorMap = 'xterm') } ansiblePlaybook('/var/jenkins_home/ansible/people.yml') { inventoryPath('/var/jenkins_home/ansible/hosts') colorizedOutput(true) extraVars { extraVar(\"EDAD\", '${EDAD}', false) } } } } job('maven_dsl') { description('Maven dsl project') scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master', {node -> node / 'extensions' << '' }) } steps { maven { mavenInstallation('jenkins-maven') goals('-B -DskipTests clean package') } maven { mavenInstallation('jenkins-maven') goals('test') } shell(''' echo \"**************************\" echo \"Desplegando el jar\" echo \"**************************\" java -jar /var/jenkins_home/workspace/8-MavenJob/target/my-app-1.0-SNAPSHOT.jar ''') } publishers { archiveArtifacts('target/*.jar') archiveJunit('target/surefire-reports/*.xml') mailer('miguel14amoros@gmail.com', true, true) } } PIPELINES Flujo de trabajo por el que tiene que pasar nuestro c\u00f3digo para llegar a producci\u00f3n. Jenkins es, fundamentalmente, un motor de automatizaci\u00f3n que soporta un n\u00famero de patrones de automatizaci\u00f3n. Pipeline a\u00f1ade un poderoso conjunto de herramientas de automatizaci\u00f3n a Jenkins, soportando casos de uso que van desde la simple integraci\u00f3n continua hasta las tuber\u00edas completas de CD. Al modelar una serie de tareas relacionadas, los usuarios pueden aprovechar las muchas caracter\u00edsticas de Pipeline: C\u00f3digo: Pipeline se implementa en c\u00f3digo y normalmente se comprueba en el control de la fuente, dando a los equipos la capacidad de editar, revisar e iterar en su tuber\u00eda de entrega. Duradero: Los oleoductos pueden sobrevivir tanto a los reinicios planificados como a los no planificados del maestro Jenkins. Pausable: Los oleoductos pueden opcionalmente detenerse y esperar la entrada o aprobaci\u00f3n humana antes de continuar el recorrido del oleoducto. Vers\u00e1til: Los oleoductos soportan complejos requisitos de CD del mundo real, incluyendo la capacidad de bifurcarse/unirse, hacer bucles y realizar trabajos en paralelo. Extensible: El plugin Pipeline soporta extensiones personalizadas para su nota al pie de p\u00e1gina DSL:dsl:[] y m\u00faltiples opciones para la integraci\u00f3n con otros plugins. Mientras que Jenkins siempre ha permitido formas rudimentarias de encadenar Trabajos de Estilo Libre para realizar tareas secuenciales, [4] Pipeline hace de este concepto un ciudadano de primera clase en Jenkins. Construido sobre el valor central de Jenkins de la extensibilidad, Pipeline es tambi\u00e9n extensible tanto por los usuarios con las Bibliotecas Compartidas de Pipeline como por los desarrolladores de plugins. [5] El siguiente diagrama de flujo es un ejemplo de un escenario de CD f\u00e1cilmente modelado en la tuber\u00eda de Jenkins: Plugin Pipeline JENKINSFILE Estructura: pipeline { agent any stages { stage('Build') { steps { echo 'Building..' } } stage('Test') { steps { echo 'Testing..' } } stage('Deploy') { steps { echo 'Deploying....' } } } } AGENT: es quien ejecuta el pipeline. ANY quiere decir que cualquiera que est\u00e9 libre lo ejecute, sino, hay que especificar el agente. MULTIPLE-STEPS pipeline { agent any stages { stage('Build') { steps { sh 'echo \"Este es mi primer pipeline\"' sh ''' echo \"Por cierto, puedo ejecutar m\u00e1s acciones aqu\u00ed\" ls -lah ''' } } } } POST-ACTIONS pipeline { agent any stages { stage('Test') { steps { sh 'echo \"Fail!\"; exit 1' } } } post { always { echo 'Siempre me voy a ejecutar :D' } success { echo 'Solo me ejecutar\u00e9 si el build no falla' } failure { echo 'Solo me ejecutar\u00e9 si el build falla' } unstable { echo 'Solo me ejecutar\u00e9 si me marco como inestable' } changed { echo 'El pipeline estaba fallando pero ahora est\u00e1 correcto o visceversa' } } } RETRY pipeline { agent any stages { stage('Timeout') { steps { retry(3) { sh 'No voy a funcionar :c' } } } } } TIMEOUT pipeline { agent any stages { stage('Deploy') { steps { retry(3) { sh 'echo hola' } timeout(time: 3, unit: 'SECONDS') { sh 'sleep 5' } } } } } ######### pipeline { agent any stages { stage('Deploy') { steps { timeout(time: 2, unit: 'SECONDS') { retry(5) { sh 'sleep 3' } } } } } } VARIABLES ENV pipeline { agent any environment { NOMBRE = 'ricardo' APELLIDO = 'gonzalez' } stages { stage('Build') { steps { sh 'echo $NOMBRE $APELLIDO' } } } } CREDENCIALES pipeline { agent any environment { secretito = credentials('TEST') } stages { stage('Example stage 1') { steps { sh 'echo $secretito' } } } } CI/CD BUILD Instalamos Docker dentro de un container Jenkins con el dockerfile de la carpeta pipelines y modificamos el Jenkins del docker-compose para poner el de la imagen creada por el dockerfile: version: '3' services: jenkins: container_name: jenkins image: jenkins/docker build: context: pipelines ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home - /var/run/docker.sock:/var/run/docker.sock networks: - net Cambiamos permisos para tener docker dentro con usuario jenkins: [isx46410800@miguel jenkins]$ docker exec -it -u root jenkins /bin/bash chown jenkins /var/run/docker.sock Copiamos la carpeta de maven dentro de la carpeta pipelines: [isx46410800@miguel jenkins]$ cp -r maven/ pipelines/java-app Iniciamos un container: docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn -B -Dskiptests clean package lo que hacemos es crear un contenedor con los volumes donde va el contenido de maven, volcamos el contenido de javaapp a app, -w para indicar el directorio activo, la version de maven, el comando hacer para generar un jar y --rm para que se elimine. Tendremos el jar construido en nuestro java-app/target/*.jar Creamos script automatizado: #!/bin/bash echo \"*************\" echo \"Construyendo jar de mi app java\" echo \"*************\" # Con esto construiriamos el container pero no deja la orden directa: #docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn -B -Dskiptests clean package # Para luego pasarle como argumento la orden docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine \"$@\" Ejecutamos: ./jenkins/build/mvn.sh mvn -B -DskipTests clean package Creamos un dockerfile con solo java y el jar creado en /jenkins/build/. Lo ejecutamos: [isx46410800@miguel build]$ docker build -f Dockerfile-java -t test . Comprobamos lo creado: [isx46410800@miguel build]$ docker run --rm -it test sh / # ls /app app.jar / # Creamos un docker-compose para automatizar esta creacion de la imagen: version: '3' services: app: image: \"app:$BUILD_TAG\" build: context: . dockerfile: Dockerfile-java Comprobamos: [isx46410800@miguel build]$ export BUILD_TAG=12 [isx46410800@miguel build]$ docker-compose -f docker-compose-build.yml build Crear un script para automatizar la creaci\u00f3n del docker-compose de la imagen: #!/bin/bash # Copia el jar cp -f java-app/target/*.jar jenkins/build/ echo \"######################\" echo \"*** Building image ***\" echo \"######################\" cd jenkins/build/ && docker-compose -f docker-compose-build.yml build --no-cache Lo comprobamos: [isx46410800@miguel pipelines]$ bash jenkins/build/build.sh ###################### *** Building image *** ###################### Building app Step 1/4 : FROM openjdk:8-jre-alpine ---> f7a292bbb70c Step 2/4 : RUN mkdir /app ---> Running in 3997da6947f6 Removing intermediate container 3997da6947f6 ---> f5f751fbe6ab Step 3/4 : COPY *.jar /app/app.jar ---> 9dc51ae21e48 Step 4/4 : CMD java -jar /app/app.jar ---> Running in dd03ae766c0e Removing intermediate container dd03ae766c0e ---> 48409229a4e8 Successfully built 48409229a4e8 Successfully tagged app:13 Lo agregamos al Jenkinsfile: pipeline { agent any stages { stage('Build') { steps { sh ''' ./jenkins/build/mvn.sh mvn -B -DskipTests clean package ./jenkins/build/build.sh ''' } } stage('Test') { steps { sh 'echo test' } } stage('Push') { steps { sh 'echo push' } } stage('Deploy') { steps { sh 'echo deploy' } } } } TEST Para hacer el test de maven de la aplicaci\u00f3n se utiliza el mvn test : [isx46410800@miguel build]$ docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn test Vemos los test en java-app/target/surefire-reports: [isx46410800@miguel pipelines]$ ll java-app/target/surefire-reports/ total 12 -rw-r--r--. 1 root root 270 Sep 30 02:45 com.mycompany.app.AppTest.txt -rw-r--r--. 1 root root 4764 Sep 30 02:45 TEST-com.mycompany.app.AppTest.xml Ahora queremos automatizar los tests con un script: [isx46410800@miguel pipelines]$ mkdir jenkins/test [isx46410800@miguel pipelines]$ vi jenkins/test/test.sh #!/bin/bash echo \"################\" echo \"*** Testing ***\" echo \"################\" docker run --rm -v /root/.m2:/root/.m2 -v /home/ricardo/jenkins/jenkins_home/workspace/pipeline-docker-maven/java-app:/app -w /app maven:3-alpine \"$@\" [isx46410800@miguel pipelines]$ chmod +x jenkins/test/test.sh Comprobamos: [isx46410800@miguel pipelines]$ bash jenkins/test/test.sh mvn test ################ *** Testing *** ################ Agregamos el test al Jenkinsfile: stage('Test') { steps { sh './jenkins/test/test.sh mvn test' } } PUSH A MAQUINA REMOTA AWS Nos creamos una maquina virtual o maquina en amazon: [isx46410800@miguel .ssh]$ ssh -i mykeypair.pem fedora@18.133.221.84 Tenemos que tener unas llaves ssh creadas en la maquina remota para poder conectarnos sin contrase\u00f1a: [fedora@ip-172-31-28-138 ~]$ ssh-keygen -f ssh-aws-jenkins Creamos un DOCKER REGISTRY : [fedora@ip-172-31-28-138 .ssh]$ docker run -d -p 5000:5000 --name registry registry:2 Ayuda Vemos que est\u00e1: [fedora@ip-172-31-28-138 .ssh]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2ebffab5d6d6 registry:2 \"/entrypoint.sh /etc\u2026\" 50 seconds ago Up 49 seconds 0.0.0.0:5000->5000/tcp registry En contenido est\u00e1 en /var/lib/registry Creamos un directorio para meter las cosas en este volumen de registros: [fedora@ip-172-31-28-138 ~]$ mkdir tmp_registry [fedora@ip-172-31-28-138 ~]$ docker run -d -p 5000:5000 --name registry -v $PWD/tmp_registry:/var/lib/registry registry:2 Estamos en el AWS en nuestra maquina remota, por lo tanto estamos en local, localhost y queremos ver como bajamos un container y lo subimos a nuestro docker de registros creado anteriormente: [fedora@ip-172-31-28-138 ~]$ docker pull hello-world [fedora@ip-172-31-28-138 ~]$ docker tag hello-world localhost:5000/hello-world [fedora@ip-172-31-28-138 ~]$ docker push localhost:5000/hello-world [fedora@ip-172-31-28-138 ~]$ ll tmp_registry/ total 4 drwxr-xr-x. 3 root root 4096 Oct 1 18:38 docker [fedora@ip-172-31-28-138 ~]$ ll tmp_registry/docker/registry/v2/repositories/hello-world/ total 12 drwxr-xr-x. 3 root root 4096 Oct 1 18:38 _layers drwxr-xr-x. 4 root root 4096 Oct 1 18:38 _manifests drwxr-xr-x. 2 root root 4096 Oct 1 18:38 _uploads Como pusimos que el contenido que vaya al contenedor de registros se guarde en nuestra carpeta creada de tmp_registry, vemos ahi la xixa nueva. Ahora queremos que desde la maquina de casa se pueda subir cosas a este contenedor de registros de AWS: [isx46410800@miguel pipelines]$ sudo vim /lib/systemd/system/docker.service # A\u00f1adimos lo siguiente en la linea de EXECSTART de SERVICE(ip/puerto de aws) --insecure-registry 18.133.221.84:5000 # a\u00f1adimos el puerto 5000 en el security group de la maquina para poder verse amazon y mi maquina por ese puerto # comprobamos la conexion desde mi maquina a AWS con telnet [isx46410800@miguel pipelines]$ telnet 18.133.221.84 5000 [isx46410800@miguel pipelines]$ sudo systemctl daemon-reload [isx46410800@miguel pipelines]$ sudo systemctl restart docker Probamos ahora subirlo desde casa al docker registry de AWS: [isx46410800@miguel pipelines]$ docker pull hello-world [isx46410800@miguel pipelines]$ docker tag hello-world:latest 18.133.221.84:5000/hello-world-casa [isx46410800@miguel pipelines]$ docker push 18.133.221.84:5000/hello-world-casa [fedora@ip-172-31-28-138 ~]$ ll tmp_registry/docker/registry/v2/repositories/ total 8 drwxr-xr-x. 5 root root 4096 Oct 1 18:38 hello-world drwxr-xr-x. 5 root root 4096 Oct 1 18:56 hello-world-casa CERTIFICADO SSL REGISTRY CON AUTENTICACION Creamos unos directorios tmp-jenkins/certs Creamos el fichero nginx.conf : server { listen 80; # reemplaza segun tus registros DNS server_name ec2-18-133-221-84.eu-west-2.compute.amazonaws.com; location ^~ /.well-known/acme-challenge/ { default_type \"text/plain\"; root /mnt; } } Arrancamos el contenedor: [fedora@ip-172-31-28-138 certs]$ docker run --rm -v $PWD/nginx.conf:/etc/nginx/conf.d/default.conf -v $PWD/letsencrypt:/etc/letsencrypt -p 80:80 -it nginx:alpine sh Instalamos certbot dentro del container que sirve para crear certificados SSL gratuidos durante 3 meses: / # nginx / # apk add --update certbot # certbot certonly --email miguel14amoros@gmail.com --agree-tos --non-interactive --webroot -w \"/mnt\" - d 18.133.221.84 PUSH de imagen con scrip a nuestro registry de amazon o dockerhub. Creamos un directorio en pipelines/jenkins/push: #!/bin/bash echo \"########################\" echo \"*** Preparing to push ***\" echo \"########################\" REGISTRY=\"isx46410800\" // \"18.133.211.84:5000\" IMAGE=\"app\" echo \"*** Logging in ***\" docker login echo \"*** Tagging image ***\" docker tag $IMAGE:$BUILD_TAG $REGISTRY/$IMAGE:$BUILD_TAG echo \"*** Pushing image ***\" docker push $REGISTRY/$IMAGE:$BUILD_TAG Tenemos ya bajada una imagen llamada APP y un export BUILD_TAG=13 Probamos primero y lo agregamos al Jenkinsfile: [isx46410800@miguel pipelines]$ bash jenkins/push/push.sh pipeline { agent any stages { stage('Build') { steps { sh ''' ./jenkins/build/mvn.sh mvn -B -DskipTests clean package ./jenkins/build/build.sh ''' } } stage('Test') { steps { sh './jenkins/test/test.sh mvn test' } } stage('Push') { steps { sh './jenkins/push/push.sh' } } stage('Deploy') { steps { sh 'echo deploy' } } } } DEPLOY En deploy/deploy.sh #!/bin/bash # Transferimos variables echo app > /tmp/.auth echo $BUILD_TAG >> /tmp/.auth # Copiamos el fichero a AWS scp -i ~/.ssh/mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth Lo copiamos a nuestra AWS: scp -i mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth Creamos en AWS un docker-compose: version: '3' services: app: image: \"$REGISTRY/$IMAGE:$TAG\" container_name: app Exportamos las variables: [fedora@ip-172-31-28-138 jenkins]$ export REGISTRY=\"isx46410800\" [fedora@ip-172-31-28-138 jenkins]$ export IMAGE=$(sed -n '1p' /tmp/.auth) [fedora@ip-172-31-28-138 jenkins]$ export TAG=$(sed -n '2p' /tmp/.auth) Comprobamos que descarga la imagen: [fedora@ip-172-31-28-138 jenkins]$ docker-compose up -d Creamos otro fichero publish para pasar las cosas a la remota: [isx46410800@miguel jenkins]$ cat deploy/publish.sh #!/bin/bash export REGISTRY=\"isx46410800\" export IMAGE=$(sed -n '1p' /tmp/.auth) export TAG=$(sed -n '2p' /tmp/.auth) docker login cd ~/jenkins && docker-compose up -d A\u00f1adimos en deploy/deploy.sh: # Transferimos variables echo \"app\" > /tmp/.auth echo $BUILD_TAG >> /tmp/.auth # Copiamos el fichero a AWS scp -i ~/.ssh/mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth scp -i ~/.ssh/mykeypair.pem ./jenkins/deploy/publish.sh fedora@18.133.221.84:/tmp/publish.sh [isx46410800@miguel pipelines]$ bash jenkins/deploy/deploy.sh En AWS ejecutamos el /tmp/publish.sh y se arranca el docker-compose creado en ~/jenkins. Ahora hacemos que se ejecute directamente todo esto desde el deploy.sh en la maquina remota: #!/bin/bash # Transferimos variables echo \"app\" > /tmp/.auth echo $BUILD_TAG >> /tmp/.auth # Copiamos el fichero a AWS scp -i ~/.ssh/mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth scp -i ~/.ssh/mykeypair.pem ./jenkins/deploy/publish.sh fedora@18.133.221.84:/tmp/publish.sh ssh -i ~/.ssh/mykeypair.pem fedora@18.133.221.84 /tmp/publish.sh A\u00f1adimos al Jenkinsfile la parte del deploy: stage('Deploy') { steps { sh './jenkins/deploy/deploy.sh' } } CI/CD Creamos un proyecto de pipeline-maven en nuestro git-server y seguimos los pasos que nos indica el repositorio vacio para poder meter todo el contenido de pipelines en nuestro git. [isx46410800@miguel pipelines]$ git init Initialized empty Git repository in /home/isx46410800/Documents/jenkins/pipelines/.git/ [isx46410800@miguel pipelines]$ git remote add origin http://gitlab.example.com/jenkinsci/pipeline-maven.git [isx46410800@miguel pipelines]$ rm -rf java-app/.git/ [isx46410800@miguel pipelines]$ git add Jenkinsfile java-app/ jenkins/ [isx46410800@miguel pipelines]$ git commit -m \"contenido jenkins ci/cd pipeline\"; git push -u origin master Cambiamos la ruta del deploy.sh por /opt y lo copiamos al container de jenkins para que use la llave ssh: [isx46410800@miguel pipelines]$ docker cp jenkins/deploy/deploy.sh jenkins:/opt/. jenkins@ee5ab67daa7d:/$ chmod +x /opt/deploy.sh Creamos un proyecto de tipo pipeline pipeline-docker-maven Configuramos el pipeline con SCM de git: Modificamos de los ficheros test.sh y deploy.sh la ruta absoluta: test.sh #!/bin/bash echo \"################\" echo \"*** Testing ***\" echo \"################\" PROJECT=\"/home/isx46410800/Documents/jenkins/jenkins_home/workspace/pipeline-docker-maven\" docker run --rm -v /root/.m2:/root/.m2 -v $PROJECT/java-app:/app -w /app maven:3-alpine \"$@\" +++++++++++++++++++++ mvn.sh #!/bin/bash echo \"*************\" echo \"Construyendo jar de mi app java\" echo \"*************\" # Con esto construiriamos el container pero no deja la orden directa: #docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn -B -Dskiptests clean package # Para luego pasarle como argumento la orden PROJECT=\"/home/isx46410800/Documents/jenkins/jenkins_home/workspace/pipeline-docker-maven\" docker run --rm -v /root/.m2:/root/.m2 -v $PROJECT/java-app:/app -w /app maven:3-alpine \"$@\" Despues entramos al container jenkins para hacer la conexion ssh manual para que no nos pida lo de autenticar conexion en los cripts: ssh -i /opt/mykeypair.pem fedora@18.133.221.84 Hemos copiado mi llave ssh de amazon a opt dentro de jenkins y la ruta de la llave del deploy.sh tambien. [isx46410800@miguel .ssh]$ docker cp mykeypair.pem jenkins:/opt/. A\u00f1adimos unos post-actions al Jenkisfile para nos de siempre un test de resultados y tambien por si va bien el build de maven guarde el jar: stage('Build') { steps { sh ''' ./jenkins/build/mvn.sh mvn -B -DskipTests clean package ./jenkins/build/build.sh ''' } post { success { archiveArtifacts artifacts 'java-app/target/*.jar', fingerprint: true } } } stage('Test') { steps { sh './jenkins/test/test.sh mvn test' } post { always { junit 'java-app/target/surefire-reports/*.xml' } } } Resultados finales: bajamos el codigo fuente de la app maven, la compilamos, subimos la imagen a dockerhub y mandamos los archivos a AWS para hacer el deploy alli.","title":"Jenkins"},{"location":"jenkins/#jenkins","text":"","title":"Jenkins"},{"location":"jenkins/#instalacion","text":"","title":"Instalaci\u00f3n"},{"location":"jenkins/#fedora","text":"Actualizar repositorios: sudo dnf update -y Instalar Java: sudo dnf install -y java Agregar repositorios de Jenkins: sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo sudo rpm --import http://pkg.jenkins.io/redhat/jenkins.io.key sudo rpm --import http://pkg.jenkins.io/redhat-stable/jenkins.io.key Instalar Jenkins: sudo dnf install -y jenkins Encender el servicio Jenkins: sudo systemctl start jenkins sudo systemctl status jenkins","title":"FEDORA"},{"location":"jenkins/#ubuntudebian","text":"Actualizar repositorios: sudo apt update Instalar Java: sudo apt install openjdk-8-jdk Agregar repositorios de Jenkins: wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add - sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' Instalar Jenkins: sudo apt update sudo apt install jenkins Encender el servicio Jenkins: sudo systemctl start jenkins sudo systemctl start jenkins","title":"UBUNTU/DEBIAN"},{"location":"jenkins/#docker","text":"En un fichero docker-compose.yml: docker-compose up -d version: '3' services: jenkins: container_name: jenkins image: jenkins/jenkins ports: - \"9090:8080\" #cambiamos el 9090 de local nuestro volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net networks: net:","title":"DOCKER"},{"location":"jenkins/#notas-a-tener-en-cuenta","text":"Al instalar se crea el usuario y grupo Jenkins Jenkins trabaja en el directorio /var/lib/jenkins Los archivos de log est\u00e1n en /var/log/jenkins/jenkins.log Los par\u00e1metros de configuraci\u00f3n se encuentran en /etc/sysconfig/jenkins Por defecto, el puerto donde trabaja Jenkins es el 8080 La contrase\u00f1a de administrar Jenkins se encuentra en /var/jenkins_home/secrets/ini...","title":"NOTAS A TENER EN CUENTA"},{"location":"jenkins/#proyecto-con-parametros","text":"Aqu\u00ed podemos definir en la opci\u00f3n de this project is parameterized->string parameter se puede definir variable con valor para utilizarlas en la construcci\u00f3n del job con un build de execute shell . Tambi\u00e9n con choice parameter podemos hacer una variable con diferentes opciones a elegir: Tambi\u00e9n con boolean parameter podemos hacer una variable con true/false a elegir: Le pasamos los argumentos por las variables definidas en los par\u00e1metros y en el script.","title":"PROYECTO CON PARAMETROS"},{"location":"jenkins/#ssh","text":"","title":"SSH"},{"location":"jenkins/#creacion-ssh-container","text":"Vamos a crear un container con ssh server para poder conectarnos alli y hacer cosas con Jenkins. Creamos un Dockerfile con Centos e instalamos el ssh, creamos su directorio ssh y creamos unas llaves con ssh-keygen -f nombre-key para pasarle la publica al ssh y asi conectarnos directamente sin password. Modificamos el docker-compose.yml a\u00f1adiendo el servicio de ssh para ello creamos un nuevo servicio con una image: build: context: ssh y luego haremos un docker-compose build y nos generar\u00e1 una imagen a trav\u00e9s del dockerfile de dentro de donde pongamos la ubicacion en context : # Instalamos un container con SO centos FROM centos:7 # Instalamos el ssh server para poder conectarnos por ssh alli RUN yum -y install openssh-server # Creamos un usuario con pass por stdin y creamos su dir ssh y con permisos RUN useradd remote_user && \\ echo \"1234\" | passwd remote_user --stdin && \\ mkdir /home/remote_user/.ssh && \\ chmod 700 /home/remote_user/.ssh # Copiamos nuestra clave publica ssh y la copiamos en el authorized(se crea) para conectarnos sin passwd COPY remotessh-key.pub /home/remote_user/.ssh/authorized_keys # Cambiamos propetario y grupo a todo lo que haya abajo del home remoteuser y damos permisos RUN chown remote_user:remote_user -R /home/remote_user && \\ chmod 600 /home/remote_user/.ssh/authorized_keys # Para que no de errores por primera vez en un container RUN /usr/sbin/sshd-keygen > /dev/null 2>&1 # activamos servicio ssh detached CMD /usr/sbin/sshd -D version: '3' services: jenkins: container_name: jenkins image: jenkins/jenkins ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net remote_host: container_name: remote_host image: remote_host build: context: ssh networks: - net networks: net: Hacemos el Docker-compose [isx46410800@miguel jenkins]$ docker-compose up -d jenkins is up-to-date Creating remote_host ... Creating remote_host ... done [isx46410800@miguel jenkins]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 172b5c2a9f99 remote_host \"/bin/sh -c '/usr/sb\u2026\" 6 seconds ago Up 3 seconds remote_host 4f52a64e7618 jenkins/jenkins \"/sbin/tini -- /usr/\u2026\" 5 hours ago Up 3 hours 50000/tcp, 0.0.0.0:9090->8080/tcp jenkins","title":"Creacion SSH container"},{"location":"jenkins/#credenciales","text":"Para comprobar que el SSH y JENKINS se ven y comunican, hacemos primero un ping desde Jenkins con ping remote_host y despues nos conectamos por ssh con el usuario creado alli ssh remote_user@remote_host o copiando la llave publica a Jenkins y desde ahi ssh -i remotessh-key remote_user@remote_host Configurar en Credentials -System - Global - credentials para poner las credenciales de SSH con el usuario creado en dockerfile y la llave privada creada. Luego vamos a Manage - system configuration - ssh remote host y ponemos el nombre del servicio ssh del docker, puerto y las credenciales creadas antes. Damos a check conection y comprobamos que sale successfully.","title":"Credenciales"},{"location":"jenkins/#ejercicio-mandar-un-job-a-maquina-remota","text":"En este ejercicio lo que hacemos es que desde jenkins, mandamos un job creando un build - execute shell via ssh remote con las credenciales creadas de ssh a una m\u00e1quina remota. El resultado lo veremos dentro de esta maquina remota.","title":"Ejercicio mandar un job a maquina remota"},{"location":"jenkins/#base-de-datos-jenkins","text":"Modificamos el docker-compose y creamos un servicio que ser\u00e1 una bbdd de mysql creando un volumen para que la xixa se guarde ah\u00ed al salir. Indicamos un nuevo campo de environment para poner el campo de la pass de root MYSQL_ROOT_PASSWORD=1234 . version: '3' services: jenkins: container_name: jenkins image: jenkins/jenkins ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net remote_host: container_name: remote_host image: remote_host build: context: ssh networks: - net db_host: container_name: db image: mysql:5.7 environment: - \"MYSQL_ROOT_PASSWORD=1234\" volumes: - $PWD/db_data:/var/lib/mysql networks: - net networks: net: Nos conectamos al container nuevo y para entrar a la bbdd se pone el comando mysql -u root -p . A\u00f1adimos lo siguiente en el Dockerfile para poder utilizar mysql por ssh y aws: # Instalamos mysql para poder conectarnos a la bbdd con mysql como comando RUN yum -y install mysql # Instalamos aws cli para amazon que est\u00e1 en un paquete de epel-pip RUN yum -y install epel-release && yum -y install python-pip && pip install --upgrade pip && yum -y install awscli Una vez cambiado hacemos un docker-compose build para que vuelva construir todo con los cambios nuevos y despues enchegar de nuevo con las nuevas construcciones docker-compose up -d . Hacemos un ping desde ssh container a db container para comprobar conexion: [root@e1825be6ec48 /]# ping db_host PING db_host (172.21.0.4) 56(84) bytes of data. 64 bytes from db.jenkins_net (172.21.0.4): icmp_seq=1 ttl=64 time=0.162 ms 64 bytes from db.jenkins_net (172.21.0.4): icmp_seq=2 ttl=64 time=0.083 ms Despu\u00e9s de esto nos conectamos a la bbdd del container desde ssh con opcion -h de host: [root@e1825be6ec48 /]# mysql -u root -h db_host -p","title":"BASE DE DATOS JENKINS"},{"location":"jenkins/#creacion-bbdd-simple","text":"MySQL [(none)]> show databases MySQL [(none)]> create database testdb; MySQL [(none)]> use testdb; MySQL [testdb]> create table info (name varchar(20), surname varchar(20), age int(2)); MySQL [testdb]> show tables; MySQL [testdb]> desc info; MySQL [testdb]> insert into info values('Miguel', 'Amoros', 27);","title":"Creacion bbdd simple"},{"location":"jenkins/#creacion-buckets-en-amazon","text":"Amazon Simple Storage Service (Amazon S3) es almacenamiento para Internet. Puede usar Amazon S3 para almacenar y recuperar cualquier cantidad de datos en cualquier momento y desde cualquier parte de la Web. Puede realizar estas tareas usando la Consola de administraci\u00f3n de AWS, que es una sencilla e intuitiva interfaz web. Amazon S3 almacena datos a modo de objetos dentro de buckets. Un objeto es un archivo y cualquier metadato opcional que describe el archivo. Para almacenar un archivo en Amazon S3, lo carga a un bucket. Al cargar un archivo como objeto, puede configurar permisos en el objeto y en cualquier metadato. Los buckets son contenedores de objetos. Puede tener uno o m\u00e1s buckets. Puede controlar el acceso de cada bucket, decidiendo qui\u00e9n puede crear, eliminar y enumerar objetos en \u00e9l. Tambi\u00e9n puede elegir la regi\u00f3n geogr\u00e1fica donde Amazon S3 almacenar\u00e1 el bucket y su contenido y ver los registros de acceso para el bucket y sus objetos. AWS - BUCKETS - CREATE BUCKET # jenkins-udemy-miguel Creamos un usuario de autenticaci\u00f3n para subir cosas al bucket: AWS-IAM-USERS-CREATE USER Opcion attach - full access - crear - download .csv key","title":"Creaci\u00f3n Buckets en amazon"},{"location":"jenkins/#dump-de-la-bbdd","text":"[root@e1825be6ec48 /]# mysqldump -u root -h db_host -p1234 testdb > /tmp/dbdump.sql -- MySQL dump 10.14 Distrib 5.5.65-MariaDB, for Linux (x86_64) -- -- Host: db_host Database: testdb -- ------------------------------------------------------ -- Server version 5.7.31 /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */; /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */; /*!40101 SET NAMES utf8 */; /*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */; /*!40103 SET TIME_ZONE='+00:00' */; /*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */; /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */; /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */; /*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */; -- -- Table structure for table `info` -- DROP TABLE IF EXISTS `info`; /*!40101 SET @saved_cs_client = @@character_set_client */; /*!40101 SET character_set_client = utf8 */; CREATE TABLE `info` ( `name` varchar(20) DEFAULT NULL, `surname` varchar(20) DEFAULT NULL, `age` int(2) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=latin1; /*!40101 SET character_set_client = @saved_cs_client */; -- -- Dumping data for table `info` -- LOCK TABLES `info` WRITE; /*!40000 ALTER TABLE `info` DISABLE KEYS */; INSERT INTO `info` VALUES ('Miguel','Amoros',27); /*!40000 ALTER TABLE `info` ENABLE KEYS */; UNLOCK TABLES; /*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */; /*!40101 SET SQL_MODE=@OLD_SQL_MODE */; /*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */; /*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */; /*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */; /*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */; /*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */; /*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */; -- Dump completed on 2020-09-25 18:19:57 Configuramos a trav\u00e9s del aws cli de amazon para poder subir el DUMP al bucket de s3 de amazon. A trav\u00e9s de las credenciales obtenidas en bucket configuramos las variables de entorno. Las configuramos en el container de bbdd: ayuda Ahora con las credenciales podremos copiar el dump al bucket de amazon: ayuda [root@e1825be6ec48 /]# aws s3 cp /tmp/dbdump.sql s3://jenkins-udemy-miguel upload: tmp/dbdump.sql to s3://jenkins-udemy-miguel/dbdump.sql","title":"Dump de la bbdd"},{"location":"jenkins/#dump-automatizado","text":"Creamos un script dentro del container de nuestra bbdd para poder hacer desde jenkins una conexion a la bbdd remota y subir a amazon el dump al bucket de almacenaje. #!/bin/bash # definimos unas variables DB_HOST=$1 DB_PASSWORD=$2 DB_NAME=$3 DATE=%(date +$H-%M-%S) AWS_SECRET=$4 BUCKET_NAME=$5 # hacemos el dump de a bbdd diciendo el nombre host servicio, pass y name de la bbdd, exportamos las variables aws para subir al bucket mysqldump -u root -h $DB_HOST -p$DB_PASSWORD $DB_NAME > /tmp/db-$DATE.sql && \\ export AWS_ACCESS_KEY_ID=AKIA5RIFOUI3AQMRXFFQ && \\ export AWS_SECRET_ACCESS_KEY=$AWS_SECRET && \\ aws s3 cp /tmp/db-$DATE.sql s3://$BUCKET_NAME Configuramos ahora las credenciales de la bbdd en jenkins con una variable de db_name y el passwd de nuestra bbdd que era 1234: Configuramos ahora las credenciales del s3 bucket en jenkins poniendo la passwd secret key: Ahora configuramos en Jenkins las variables parametrizadas del script de bbdd: Despu\u00e9s en la opci\u00f3n de entorno de ejecuci\u00f3n selecionamos la opci\u00f3n de usar secret text y ponemos las credenciales creadas anteriormente y la variable del script creado en la bbdd. Build por ssh: Automatizamos: A\u00f1adimos en el docker-compose estas lineas para que el script creado en tmp de la bbdd no se borre cuando se elimine, por lo tanto la chicha del script de fuera lo mandamos alli copiado: volumes: - $PWD/dumpremotessh-aws.sh:/tmp/dumpremote.sh Ahora si creamos en mysql otra db y en amazon otro bucket, cambiamos los parametros del job y nos crea lo mismo sin cambiar el script. Podemos tambien hacerlo manualmente y en vez de llamar al script, lo copiamos dentro y hace lo mismo (opci\u00f3n m\u00e1s fea).","title":"DUMP AUTOMATIZADO"},{"location":"jenkins/#ansible","text":"Automatizaci\u00f3n de tareas hecho en python. Creamos un nuevo dockerfile: # sistema basado en jenkins FROM jenkins/jenkins # instalamos pip como root USER root RUN curl \"https://bootstrap.pypa.io/get-pip.py\" -o \"get-pip.py\" && python get-pip.py RUN pip install -U ansible USER jenkins Modificamos el docker-compose: jenkins: container_name: jenkins image: jenkins-ansible build: context: jenkins-ansible ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home networks: - net Hacemos docker-compose build y up -d Creamos un fichero hosts con lenguaje ansible para crear nuestro primer fichero de inventario. # ARCHIVO DE INVENTARIO ANSIBLE # todas las variables se definen asi [all:vars] # todas las maquinas se conectaran por ssh ansible_connection = ssh [test] # aque maquina me voy a conectar con el nombre test1 y con que usuario y donde esta la llave privada para conectarme test1 ansible_host=remote_host ansible_user=remote_user ansible_private_key_file=/var/jenkins_home/ansible/remotessh-key Despues lo copiamos dentro de [isx46410800@miguel jenkins]$ cp hosts jenkins_home/ansible/ para que est\u00e9 dentro del container jenkins-ansible ya que aqui est\u00e1 el volumen de la xixa del container que se guarda. Comprobamos conexion de nuestro inventario ansible-jenkins con la m\u00e1quina ssh remote_host: jenkins@7cafd0984215:~/ansible$ ansible -m ping -i hosts test1 -m de modulo -i fichero y maquina test1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" }","title":"ANSIBLE"},{"location":"jenkins/#playbooks","text":"Los Playbooks describen configuraciones, despliegue, y orquestaci\u00f3n en Ansible. \u200b El formato del Playbook es YAML. \u200b Cada Playbook asocia un grupo de hosts a un conjunto de roles. Cada rol est\u00e1 representado por llamadas a lo que Ansible define como Tareas. Creamos primer fichero playbook: cat play.yml - hosts: test1 tasks: - shell: echo \"Hola Mundo desde Ansible y Jenkins\" > /tmp/hola-ansible.txt Para comprobar el funcionamiento: jenkins@7cafd0984215:~/ansible$ ansible-playbook -i hosts play.yml lo que hace es desde jenkins conectar el playbook a la maquina creada en ansible test1(que es remote_host de ssh container) por ssh. Instalamos el modulo ansible en jenkins y creamos un job con build de ansible playbook. Ponemos la ruta del playbook y la ruta del file hosts para la conexion. asi nos ahorramos poner toda la ruta de arriba, lo hacemos automatizado. Modificamos el fichero play.yml para pasar el texto por parametro: A\u00f1adimos los parametros y la variable extra para que en el script coja la variavle MSG con el parametro texto de arriba( seria como a\u00f1adir la opcion -e \"MSG=hola\" en hardcode): - hosts: test1 tasks: - debug: var: MSG","title":"Playbooks"},{"location":"jenkins/#tags","text":"Ponemos tags en nuestro script: - hosts: test1 tasks: - debug: var: MSG - debug: msg: \"Yo no me voy a ejecutar :(\" tags: no-exec - debug: msg: \"Yo s\u00ed me voy a ejecutar :)\" tags: si-exec solo se ejecutan las tareas que ponen en RUN de tags en jenkins, el resto no: PLUGIN: ANSICOLOR para que salga en colo en jenkins el resultado del job activando la opci\u00f3n color en configuracion del job.","title":"TAGS"},{"location":"jenkins/#db-mysql","text":"Creamos en el container db una bbdd de people con registros en la tabla registro. De un file con 50 nombres, hacemos un script para meterlos todos en la bbdd: #!/bin/bash #iniciamos contador count=0 #mientras sea menos de 50 personas del archivo, coger los campos while [ $count -lt 50 ] do count=$((count+1)) nombre=$(nl people.txt | grep -w $count | tr -s '[:blank:]' ',' | cut -d',' -f3) apellido=$(nl people.txt | grep -w $count | tr -s '[:blank:]' ',' | cut -d',' -f4) edat=$(shuf -i 20-25 -n1) mysql -u root -p1234 people -e \"insert into registro values($id, '$nombre', '$apellido', $edat)\" echo \"$count, $nombre, $apellido importado\" sleep 5 done copiamos el script en el container db y lo ejecutamos para que se llene la bbdd creada.","title":"DB MYSQL"},{"location":"jenkins/#nginx-server","text":"Creamos un container con nginx server y php a partir del container con ssh: # a partir de la imagen de ssh generada ya FROM remote_host # a\u00f1adimos el repo del web server nginx para centos COPY ./conf/nginx.repo /etc/yum.repos.d/nginx.repo # instalamos los paquetes necesarios y de php RUN \\ yum -y install nginx-1.12.2 openssl --enablerepo=nginx && \\ yum -y install https://repo.ius.io/ius-release-el7.rpm \\ https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm && \\ yum -y install \\ php71u-fpm \\ php71u-cli \\ php71u-mysqlnd \\ php71u-soap \\ php71u-xml \\ php71u-zip \\ php71u-json \\ php71u-mcrypt \\ php71u-mbstring \\ php71u-zip \\ php71u-gd \\ --enablerepo=ius-archive && yum clean all # abrimos los puertos por donde escuchar EXPOSE 80 443 # nos quedamos con los volumenes VOLUME /var/www/html /var/log/nginx /var/log/php-fpm /var/lib/php-fpm # comando para dar permisos al usuario creado d ssh RUN setfacl -R -m u:remote_user:rwx /var/www/html # copiamos el fichero de configuracion COPY ./conf/nginx.conf /etc/nginx/conf.d/default.conf # copiamos el fichero de empezar COPY ./bin/start.sh /start.sh # damos permisos de ejecucucion RUN chmod +x /start.sh # arranca el container con el script CMD /start.sh Modificamos el docker-compose para a\u00f1adir el nuevo container nginx-php con ssh: web: container_name: web image: ansible-web build: context: jenkins-ansible/web ports: - \"80:80\" networks: - net creamos un servicio web con el nombre container y la imagen ansible-web que se crea a trav\u00e9s del dockerfile con la ruta en context. Hacemos un docker-compose build y up. NOTA: desactivo con systemctl stop httpd porque escucha por el puerto 80 del web que queremos crear. Entramos al container web y a\u00f1adimos el indice de index.php: [root@7d0d237e1686 /]# cat /var/www/html/index.php <?php phpinfo(); ?> Hacemos esto solo de prueba para nuestro navegador Creamos una tabla que muestra la informaci\u00f3n via web: [isx46410800@miguel jenkins-ansible]$ docker cp table.j2 web:/var/www/html/index.php Para integrar el webserver en nuestro inventario de Ansible modificamos el fichero host de /jenkins_home/ansible/hosts y a\u00f1adimos el nuevo alias y el nombre servicio: web1 ansible_host=web ansible_user=remote_user ansible_private_key_file=/var/jenkins_home/ansible/remotessh-key Comprobamos yendo al container jenkins que es donde est\u00e1 instalado Ansible y lo comprobamos como la otra vez: jenkins@7cafd0984215:~/ansible$ pwd /var/jenkins_home/ansible **jenkins@7cafd0984215:~/ansible$ ansible -i hosts -m ping web1 web1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } **jenkins@7cafd0984215:~/ansible$ ansible -i hosts -m ping all test1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } web1 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } Ahora vamos hacer lo anterior pero de manera automatizada en Jenkins. Para ello creamos un playbook nuevo: - hosts: web1 tasks: - name: Transfiere el template hacia web1 template: src: table.j2 dest: /var/www/html/index.php Cambiamos unos datos del fichero table.j2 donde contenia los datos a mostrar en el index.php para poder pasar las cosas por parametros en Jenkins: $sql = \"SELECT id, nombre, apellido, edat FROM registro where edat <= 25 and edat >=20\"; ----> CAMBIOS $sql = \"SELECT id, nombre, apellido, edat FROM registro {% IF EDAD is defined %} where edat = {{ EDAD }} {% endif %}\";---- queremos decir que si el parametro que pasamos EDAD est\u00e1 defenido haga la consulta donde la edad sea igual al parametro. Damos permisos para solucionar un fallo de poner escribir dentro del container web en la carpeta de html y despues dentro del container jenkins, probamos siempre lo del playbook: [root@7d0d237e1686 /]# chown remote_user:remote_user -R /var/www/html/ jenkins@7cafd0984215:~/ansible$ ansible-playbook -i hosts people.yml jenkins@7cafd0984215:~/ansible$ ansible-playbook -i hosts people.yml -e \"EDAD=22\" con y sin parametros, y el cambio lo vemos en el index.php del container web. Vamos a jenkins y automatizamos la tarea, poniendo una variable de opcion, el path del playbook y del fichero de hosts para conectar con la maquina y despues una extra variable que sera la variable que pasamos como parametro.","title":"NGINX SERVER"},{"location":"jenkins/#security-jenkins","text":"Por defecto no est\u00e1 activado, pero si queremos que cualquier persona se pueda loguear al jenkins via navegador vamos a Manage Jenkins- Conf global Security y clicamos en la opcion de desactivar seguridad. Se puede activar la opci\u00f3n Allow users to sign up para permitir a usuarios crearse una cuenta para entrar a Jenkins igual que la otra opci\u00f3n de que tengan permisos especiales los usuarios registrados. Activamos lo de registrarse, nos ddesconectamos y creamos dos cuentas: Instalamos un potente plugin de seguidad que sirve para gestionar los roles y dar permisos a los usuarios: Role-based Authorization Strategy Entramos de nuevo a la conf de seguridad con el uuario admin y le damos a este role de usuarios. Veremos que nos aparece una nueva pesta\u00f1a de menu para que pueda gestionar los roles:","title":"SECURITY JENKINS"},{"location":"jenkins/#manage-users","text":"Vamos a manage jenkins-manage users aqui podremos crear/borrar/modificar usuarios sin tener que hacerlos creando cuentas:","title":"MANAGE USERS"},{"location":"jenkins/#manage-roles","text":"Vamos a manage jenkins-manage and assign roles y manage roles para gestionar los roles de un usuario: Creamos un nuevo role en role to add como por ejemplo que solo sea de lectura el role del usuario, solo podr\u00e1 ver jobs sin ejecutar ni nada mas: Ahora asignamos este role creado de solo-lectura a uno de los uusuarios. Vamos a manage jenkins-manage and assign roles y assign role. Veremos al loguearlos despues que solo puede ver, solo lectura. Si modificamos el manage role y le ponemos que pueda read los jobs, al loguearse veremos que pueda ver los jobs almenos. Ahora creamos un role de poder ejecutar y ver los jobs y se lo asignamos: Ahora lo que queremos hacer es que un usuario en vez de ver todos los jobs, solo veas los que le digamos y pueda hacer build solo a esos. Para ello le quitamos el read the jobs y creamos un item role y le a\u00f1adimos un patron para ver solo jobs con ese patron.","title":"MANAGE ROLES"},{"location":"jenkins/#trips-and-ticks","text":"","title":"TRIPS AND TICKS"},{"location":"jenkins/#variables-de-entorno","text":"Lista de variables de entorno propias de Jenkins: echo \"BUILD_NUMBER: $BUILD_NUMBER\" echo \"BUILD_ID: $BUILD_ID\" echo \"BUILD_URL: $BUILD_URL\" echo \"JOB_NAME: $JOB_NAME\" echo \"JAVA_HOME: $JAVA_HOME\" echo \"JENKINS_URL: $JENKINS_URL\" lista variables Resultado de un simple job: Console Output Started by user admin Running as SYSTEM Building in workspace /var/jenkins_home/workspace/7-ENV [7-ENV] $ /bin/sh -xe /tmp/jenkins7847738549255029537.sh + echo BUILD_NUMBER: 1 BUILD_NUMBER: 1 + echo BUILD_ID: 1 BUILD_ID: 1 + echo BUILD_URL: http://localhost:9090/job/7-ENV/1/ BUILD_URL: http://localhost:9090/job/7-ENV/1/ + echo JOB_NAME: 7-ENV JOB_NAME: 7-ENV + echo JAVA_HOME: /usr/local/openjdk-8 JAVA_HOME: /usr/local/openjdk-8 + echo JENKINS_URL: http://localhost:9090/ JENKINS_URL: http://localhost:9090/ Finished: SUCCESS Podemos crear propias en manage jenkins- conf sistem y clicamos en la opcion de variables de entorno: echo \"PLATAFORMA: $PLATAFORMA\" echo \"PAIS: $PAIS\" + echo PLATAFORMA: UDEMY PLATAFORMA: UDEMY + echo PAIS: ESPA\u00d1A PAIS: ESPA\u00d1A","title":"Variables de entorno"},{"location":"jenkins/#cambio-url","text":"Podemos crear propias en manage jenkins- conf sistem y clicamos en la opcion de Jenkins Location: Cambiamos la url por la de dns (/etc/hosts): 192.168.1.44 host2 127.0.0.1 loopback.jenkins http://loopback.jenkins:9090/","title":"Cambio URL"},{"location":"jenkins/#cron","text":"Podemos ver una chuleta de crontab A la hora de construir un job hay que dar en la opci\u00f3n de Build triggers - execute periodically 5 * * * * cada 5 minutos Podemos poner una H en un * y quiere decir que coger\u00e1 cuando pueda de ese momento para que haya menos carga de jobs por si hay otras tareas tambi\u00e9n y no se sobrecargue.","title":"CRON"},{"location":"jenkins/#gatillar-jobs","text":"Quiere decir que lancemos un job sin necesidad sin entrar a jenkins y construir el job, sino desde un script desde la terminal. Vamos a Manage and Assign Roles - Manage Roles y creamos uno que se llame trigger-jobs. Creamos un usuario jenkins y le asignamos este rol. Va relacionado con la opci\u00f3n Crumb Issuer de seguridad global,ya viene por defecto. Instalamos un plugin para evitar error: Buscando en Internet he visto que el error se produce porque a partir de cierta versi\u00f3n de Jenkins (2.176.x) es necesario que ambas peticiones (para obtener el crumb y para lanzar el job) est\u00e9n dentro de la misma \"sesi\u00f3n web\" (ver https://jenkins.io/doc/upgrade-guide/2.176/#upgrading-to-jenkins-lts-2-176-3). Siguiendo la recomendaci\u00f3n en esa misma p\u00e1gina, instal\u00e9 el plugin \"Strict Crumb Issuer\" y lo configur\u00e9 para que no fuera necesario estar en la misma sesi\u00f3n web: [isx46410800@miguel jenkins]$ cat crumb.sh # generamos el crum, el usuario que queremos, -s de silencioso el output y la url de jenkins crumb=$(curl -u \"jenkins:1234\" -s 'http://127.0.0.1:9090/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)') # autenticamos el crumb a traves de variable pasada de crumb curl -u \"jenkins:1234\" -H \"$crumb\" -X POST http://127.0.0.1:9090/job/7-ENV/build?delay=0sec Ahora con parametros: [isx46410800@miguel jenkins]$ cat crumb.sh # generamos el crum, el usuario que queremos, -s de silencioso el output y la url de jenkins crumb=$(curl -u \"jenkins:1234\" -s 'http://127.0.0.1:9090/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)') #con parametros curl -u \"jenkins:1234\" -H \"$crumb\" -X POST http://127.0.0.1:9090/job/6-db-playbook-ansible-nginx-php/buildWithParameters?EDAD=23 [isx46410800@miguel jenkins]$ bash crumb.sh nos sale el index-php solo con los de 22","title":"GATILLAR JOBS"},{"location":"jenkins/#mail","text":"","title":"MAIL"},{"location":"jenkins/#configurar-envio-de-notificaciones","text":"Plugin a instalar Email Extension Plugin Vamos a manage jenkins-conf sistem - E-mail Notification Vamos a Amazon - SES - Stmp settings y copiamos la direccion del mail email-smtp.eu-west-2.amazonaws.com Despues le damos a crear credenciales stmp de amazon y ponemos un usuario jenkins-user : [isx46410800@miguel jenkins]$ cat credentials.csv IAM User Name,Smtp Username,Smtp Password \"jenkins-user\",AKIA5RIFOUI3LWLFOOG7,BFW538mmwDzTr4eaMMAzSVlQA57NeH1/Hqvnn3ABJsZ6 Creamos un email de admin en amazon: Probamos el email: Test e-mail recipient \ufffc Test configuration: miguel14amoros@gmail.com Email was successfully sent","title":"Configurar envio de notificaciones"},{"location":"jenkins/#gmail-como-server-de-correo","text":"Ponemos nuestro gmail como direccion de correo y luego rellenamos la parte de correo:","title":"Gmail como server de correo"},{"location":"jenkins/#email-de-error","text":"Cogemos un build e indicamos en la opcion post-build nuestro correo para si falla, enviarnos email. Escribimos algo mal y recibimos el email. Lo ponemos correcto y recibimos email de que todo va bien. Si sigue yendo bien, no recibimos email.","title":"Email de error"},{"location":"jenkins/#maven","text":"","title":"MAVEN"},{"location":"jenkins/#instalacion_1","text":"Instalamos el plugin Maven Integration Ejemplo de git maven: maven sample app","title":"Instalacion"},{"location":"jenkins/#configuracion-de-un-job","text":"Configuracion del job: Los workspace son las mesas de trabajo donde se deja lo clonado de git y ahi tenemos toda la xixa para trabajar en jenkins. Configuracion e instalamos maven: A\u00f1adimos el paso de construir tarea de maven: lo que hace todo el proceso es descargar el codigo fuente de git, instalar la version de maven indicada y despues ejecuta el comando de -B -DskipTests clean package de maven que jenkins coja el codigo fuente y lo construya(package) un .jar de la app y se ejecuta en un workspaces donde jenkins crea un pom.xml que necesita maven. Despues a\u00f1adimos que despues de todo esto haga un test: A\u00f1adimos otra opci\u00f3n de desplegar el jar: + java -jar /var/jenkins_home/workspace/8-MavenJob/target/my-app-1.0-SNAPSHOT.jar","title":"Configuracion de un job"},{"location":"jenkins/#registrar-los-resultados","text":"A\u00f1adimos acci\u00f3n para ejecutar despues(post build) con la opcion de publicar los resultados de tests Junit(Publish JUnit test result report)--> target/surefire-reports Vemos que nos sale una grafica y una nueva pesta\u00f1a de test results:","title":"Registrar los resultados"},{"location":"jenkins/#archivar-los-jar","text":"A\u00f1adimos otra acci\u00f3n post build de archivar los *.jar y vemos que nos aparece una nueva pesta\u00f1a para descargar el archivo jar: Podemos a\u00f1adir la alerta de email si falla:","title":"Archivar los jar"},{"location":"jenkins/#git-server","text":"Creamos en el docker-compose un git-server siguiendo estas instruciones Cambiamos el puerto local del servicio web para que no se colpasen: web: container_name: web image: ansible-web build: context: jenkins-ansible/web ports: - \"8888:80\" networks: - net git: container_name: git-server hostname: gitlab.example.com ports: - \"443:443\" - \"80:80\" volumes: - \"/srv/gitlab/config:/etc/gitlab\" - \"/srv/gitlab/logs:/var/log/gitlab\" - \"/srv/gitlab/data:/var/opt/gitlab\" image: gitlab/gitlab-ce networks: - net Ponemos la url en /etc/hosts para asignar la ip al servicio mejor: 127.0.0.1 gitlab.example.com Entramos, nos registramos con root y 12345678 y creamos un grupo llamado jenkinsci . Despues creamos un proyecto, lo llamamos maven . Despues vamos a usuarios y creamos un usuario nuevo miguel con acceso regular. Luego editamos el usuario y le ponemos una contrase\u00f1a 12345678 . Luego vamos al proyecto creado de jenkinsci/maven y vamos a manage settings y a\u00f1adimos como usuario developer al user creado. NOTA: lo pondremos en modo mantainer, un nivel superior, para poder hacer el primer push al crear la rama master con git pusg -u origin master. Despues clonamos el repo de maven con el simple app maven y clonamos el nuevo repo vacio y copiamos los archivos de uno a otro, hacemos un push y ya tenemos todo el contenido.","title":"GIT SERVER"},{"location":"jenkins/#cambio-url-mavengitjenkins","text":"Vemos la url de mi repo git en: [isx46410800@miguel maven]$ cat .git/config [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \"origin\"] url = http://gitlab.example.com/jenkinsci/maven.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \"master\"] remote = origin merge = refs/heads/master En jenkins vamos a credenciales y le damos al de la llave naranja y creamos las credenciales del git de dentro del docker: Una vez hecho esto, vamos a configurar el job que teniamos de maven y cambiamos el SCM por la url de nuestro git creado. Deberiamos poner la url de nuestro git http://gitlab.example.com/jenkinsci/maven.git pero como nuestro servicio especificado en docker-compose lo tenemos como git, ponemos http://git/jenkinsci/maven.git . Ponemos las credenciales de nuestro git y construimos el build viendo que lo descarga de nuestro gir y funciona. Vamos al container de git-server dentro donde se esconde el contenido del repo maven: root@gitlab:/var/opt/gitlab/git-data/repositories/@hashed/6b/86/6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b.git Creamos dentro el directorio mkdir custom_hooks y el file post-receive #!/bin/bash # Get branch name from ref head if ! [ -t 0 ]; then read -a ref fi IFS='/' read -ra REF <<< \"${ref[2]}\" branch=\"${REF[2]}\" # preguntamos por el nombre del branch(master) # si es master hacemos el gatillar con crumb if [ $branch == \"master\" ]; then crumb=$(curl -u \"jenkins:1234\" -s 'http://jenkins.local:9090/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)') curl -u \"jenkins:1234\" -H \"$crumb\" -X POST http://jenkins.local:9090/job/8-MavenJob/build?delay=0sec if [ $? -eq 0 ] ; then echo \"*** Ok\" else echo \"*** Error\" fi fi Con esto lo que queremos hacer es que cuando hagamos un push al repo git, como hay cambios, se haga automatico un job en el job de maven. Despues le damos chmod +x post-receive y chown git:git custom_hooks Hacemos un push y se deber\u00eda hacer automatico el build de maven job.","title":"CAMBIO URL MAVEN/GIT/JENKINS"},{"location":"jenkins/#job-dsl","text":"Instalamos el plugin Job DSL nos permite crear jobs codigo SEED JOB es el job padre que har\u00e1 ejecutar a los jobs hijos. Construimos un job y vamos a la opci\u00f3n build - process job DSLs Documentaci\u00f3n de job dsl","title":"JOB DSL"},{"location":"jenkins/#seed-job","text":"Ejemplo estructura: job('job_dsl_example') { }","title":"SEED JOB"},{"location":"jenkins/#descripcion","text":"Indicamos la descripcion del job hijo: job('job_dsl_example') { description('This is my awesome Job') } Con la descripcion te crea un job hijo que te dice la descripcion indicada","title":"DESCRIPCION"},{"location":"jenkins/#parametros","text":"Para poner parametros en el job: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } } Te crea el job fijo con una descripcion y tres variables parametrizadas.","title":"PAR\u00c1METROS"},{"location":"jenkins/#scm","text":"La administracion del codigo fuente: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } } Con SCM definimos la url y la branch del codigo fuente git en este caso.","title":"SCM"},{"location":"jenkins/#triggers","text":"Cron de tareas: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } } Definimos un trigger en este caso con un cron.","title":"TRIGGERS"},{"location":"jenkins/#steps","text":"Son los pasos que va hacer nuestro job, lo que se va ir ejecutando. job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { shell(\"echo 'Hello World'\") } } Paso de hacer un hello world","title":"STEPS"},{"location":"jenkins/#mailer","text":"Sirve para indicar el aviso de notificaciones por correo: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { shell(\"echo 'Hello World'\") shell(\"echo 'Hello World2'\") } publishers { mailer('me@example.com', true, true) } } Indicamos el aviso de notificaciones.","title":"MAILER"},{"location":"jenkins/#job-de-ansible-en-dsl","text":"En este ejemplo vamos a hacer el job n\u00famero de 6 de ansible con gnix php jenkins en JOBDSL: esto es lo que teniamos en el job6 de ansible. EJEMPLO JOBDSL, LO M\u00c1S UTILIZADO: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { wrappers { colorizeOutput(colorMap = 'xterm') } ansiblePlaybook('/etc/ansible/plays/i2b-cl/some_playbook.yml') { inventoryPath('/etc/ansible/plays/i2b-cl/hosts') tags('cool') forks(1) colorizedOutput(true) additionalParameters('--vault-password-file $HOME/pass-vault/i2b-cl.txt') extraVars { extraVar(\"whoami\", '${param1}', false) extraVar(\"my_pass\", 'some_pass', true) } } } publishers { mailer('me@example.com', true, true) } } AYUDA ANSIBLE DSL Creamos nuestro archivo jobdsl de ansible.js: job('ansible-dsl') { description('Este es un job de ansible con dsl') parameters { choiceParam('EDAD', ['20', '21', '22', '23', '24', '25']) } steps { wrappers { colorizeOutput(colorMap = 'xterm') } ansiblePlaybook('/var/jenkins_home/ansible/people.yml') { inventoryPath('/var/jenkins_home/ansible/hosts') colorizedOutput(true) extraVars { extraVar(\"EDAD\", '${EDAD}', false) } } } } Nos da un error que ya nos daba en su momento y lo que tenemos que hacer es entrar al contenedor web y cambiar los permisos: chown remote_user:remote_user -R /var/www/html/","title":"JOB DE ANSIBLE EN DSL"},{"location":"jenkins/#job-de-maven-en-dsl","text":"Seguimos el job8 de maven pero ahora en DSL: job('maven_dsl') { description('Maven dsl project') scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master', {node -> node / 'extensions' << '' }) } steps { maven { mavenInstallation('jenkins-maven') goals('-B -DskipTests clean package') } maven { mavenInstallation('jenkins-maven') goals('test') } shell(''' echo \"**************************\" echo \"Desplegando el jar\" echo \"**************************\" java -jar /var/jenkins_home/workspace/8-MavenJob/target/my-app-1.0-SNAPSHOT.jar ''') } publishers { archiveArtifacts('target/*.jar') archiveJunit('target/surefire-reports/*.xml') mailer('miguel14amoros@gmail.com', true, true) } }","title":"JOB DE MAVEN EN DSL"},{"location":"jenkins/#dsl-en-git","text":"Vamos a nuestro git-server http://gitlab.example.com:443 Creamos un nuevo proyecto dsl y lo clonamos y creamos un fichero copiando todo lo hecho en jobdsl padre: job('job_dsl_example') { description('This is my awesome Job') parameters { stringParam('Planet', defaultValue = 'world', description = 'This is the world') booleanParam('FLAG', true) choiceParam('OPTION', ['option 1 (default)', 'option 2', 'option 3']) } scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master') } triggers { cron('H 5 * * 7') } steps { shell(\"echo 'Hello World'\") shell(\"echo 'Hello World2'\") } publishers { mailer('me@example.com', true, true) } } job('ansible-dsl') { description('Este es un job de ansible con dsl') parameters { choiceParam('EDAD', ['20', '21', '22', '23', '24', '25']) } steps { wrappers { colorizeOutput(colorMap = 'xterm') } ansiblePlaybook('/var/jenkins_home/ansible/people.yml') { inventoryPath('/var/jenkins_home/ansible/hosts') colorizedOutput(true) extraVars { extraVar(\"EDAD\", '${EDAD}', false) } } } } job('maven_dsl') { description('Maven dsl project') scm { git('https://github.com/jenkins-docs/simple-java-maven-app', 'master', {node -> node / 'extensions' << '' }) } steps { maven { mavenInstallation('jenkins-maven') goals('-B -DskipTests clean package') } maven { mavenInstallation('jenkins-maven') goals('test') } shell(''' echo \"**************************\" echo \"Desplegando el jar\" echo \"**************************\" java -jar /var/jenkins_home/workspace/8-MavenJob/target/my-app-1.0-SNAPSHOT.jar ''') } publishers { archiveArtifacts('target/*.jar') archiveJunit('target/surefire-reports/*.xml') mailer('miguel14amoros@gmail.com', true, true) } }","title":"DSL en GIT"},{"location":"jenkins/#pipelines","text":"Flujo de trabajo por el que tiene que pasar nuestro c\u00f3digo para llegar a producci\u00f3n. Jenkins es, fundamentalmente, un motor de automatizaci\u00f3n que soporta un n\u00famero de patrones de automatizaci\u00f3n. Pipeline a\u00f1ade un poderoso conjunto de herramientas de automatizaci\u00f3n a Jenkins, soportando casos de uso que van desde la simple integraci\u00f3n continua hasta las tuber\u00edas completas de CD. Al modelar una serie de tareas relacionadas, los usuarios pueden aprovechar las muchas caracter\u00edsticas de Pipeline: C\u00f3digo: Pipeline se implementa en c\u00f3digo y normalmente se comprueba en el control de la fuente, dando a los equipos la capacidad de editar, revisar e iterar en su tuber\u00eda de entrega. Duradero: Los oleoductos pueden sobrevivir tanto a los reinicios planificados como a los no planificados del maestro Jenkins. Pausable: Los oleoductos pueden opcionalmente detenerse y esperar la entrada o aprobaci\u00f3n humana antes de continuar el recorrido del oleoducto. Vers\u00e1til: Los oleoductos soportan complejos requisitos de CD del mundo real, incluyendo la capacidad de bifurcarse/unirse, hacer bucles y realizar trabajos en paralelo. Extensible: El plugin Pipeline soporta extensiones personalizadas para su nota al pie de p\u00e1gina DSL:dsl:[] y m\u00faltiples opciones para la integraci\u00f3n con otros plugins. Mientras que Jenkins siempre ha permitido formas rudimentarias de encadenar Trabajos de Estilo Libre para realizar tareas secuenciales, [4] Pipeline hace de este concepto un ciudadano de primera clase en Jenkins. Construido sobre el valor central de Jenkins de la extensibilidad, Pipeline es tambi\u00e9n extensible tanto por los usuarios con las Bibliotecas Compartidas de Pipeline como por los desarrolladores de plugins. [5] El siguiente diagrama de flujo es un ejemplo de un escenario de CD f\u00e1cilmente modelado en la tuber\u00eda de Jenkins: Plugin Pipeline","title":"PIPELINES"},{"location":"jenkins/#jenkinsfile","text":"Estructura: pipeline { agent any stages { stage('Build') { steps { echo 'Building..' } } stage('Test') { steps { echo 'Testing..' } } stage('Deploy') { steps { echo 'Deploying....' } } } } AGENT: es quien ejecuta el pipeline. ANY quiere decir que cualquiera que est\u00e9 libre lo ejecute, sino, hay que especificar el agente.","title":"JENKINSFILE"},{"location":"jenkins/#multiple-steps","text":"pipeline { agent any stages { stage('Build') { steps { sh 'echo \"Este es mi primer pipeline\"' sh ''' echo \"Por cierto, puedo ejecutar m\u00e1s acciones aqu\u00ed\" ls -lah ''' } } } }","title":"MULTIPLE-STEPS"},{"location":"jenkins/#post-actions","text":"pipeline { agent any stages { stage('Test') { steps { sh 'echo \"Fail!\"; exit 1' } } } post { always { echo 'Siempre me voy a ejecutar :D' } success { echo 'Solo me ejecutar\u00e9 si el build no falla' } failure { echo 'Solo me ejecutar\u00e9 si el build falla' } unstable { echo 'Solo me ejecutar\u00e9 si me marco como inestable' } changed { echo 'El pipeline estaba fallando pero ahora est\u00e1 correcto o visceversa' } } }","title":"POST-ACTIONS"},{"location":"jenkins/#retry","text":"pipeline { agent any stages { stage('Timeout') { steps { retry(3) { sh 'No voy a funcionar :c' } } } } }","title":"RETRY"},{"location":"jenkins/#timeout","text":"pipeline { agent any stages { stage('Deploy') { steps { retry(3) { sh 'echo hola' } timeout(time: 3, unit: 'SECONDS') { sh 'sleep 5' } } } } } ######### pipeline { agent any stages { stage('Deploy') { steps { timeout(time: 2, unit: 'SECONDS') { retry(5) { sh 'sleep 3' } } } } } }","title":"TIMEOUT"},{"location":"jenkins/#variables-env","text":"pipeline { agent any environment { NOMBRE = 'ricardo' APELLIDO = 'gonzalez' } stages { stage('Build') { steps { sh 'echo $NOMBRE $APELLIDO' } } } }","title":"VARIABLES ENV"},{"location":"jenkins/#credenciales_1","text":"pipeline { agent any environment { secretito = credentials('TEST') } stages { stage('Example stage 1') { steps { sh 'echo $secretito' } } } }","title":"CREDENCIALES"},{"location":"jenkins/#cicd","text":"","title":"CI/CD"},{"location":"jenkins/#build","text":"Instalamos Docker dentro de un container Jenkins con el dockerfile de la carpeta pipelines y modificamos el Jenkins del docker-compose para poner el de la imagen creada por el dockerfile: version: '3' services: jenkins: container_name: jenkins image: jenkins/docker build: context: pipelines ports: - \"9090:8080\" volumes: - $PWD/jenkins_home:/var/jenkins_home - /var/run/docker.sock:/var/run/docker.sock networks: - net Cambiamos permisos para tener docker dentro con usuario jenkins: [isx46410800@miguel jenkins]$ docker exec -it -u root jenkins /bin/bash chown jenkins /var/run/docker.sock Copiamos la carpeta de maven dentro de la carpeta pipelines: [isx46410800@miguel jenkins]$ cp -r maven/ pipelines/java-app Iniciamos un container: docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn -B -Dskiptests clean package lo que hacemos es crear un contenedor con los volumes donde va el contenido de maven, volcamos el contenido de javaapp a app, -w para indicar el directorio activo, la version de maven, el comando hacer para generar un jar y --rm para que se elimine. Tendremos el jar construido en nuestro java-app/target/*.jar Creamos script automatizado: #!/bin/bash echo \"*************\" echo \"Construyendo jar de mi app java\" echo \"*************\" # Con esto construiriamos el container pero no deja la orden directa: #docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn -B -Dskiptests clean package # Para luego pasarle como argumento la orden docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine \"$@\" Ejecutamos: ./jenkins/build/mvn.sh mvn -B -DskipTests clean package Creamos un dockerfile con solo java y el jar creado en /jenkins/build/. Lo ejecutamos: [isx46410800@miguel build]$ docker build -f Dockerfile-java -t test . Comprobamos lo creado: [isx46410800@miguel build]$ docker run --rm -it test sh / # ls /app app.jar / # Creamos un docker-compose para automatizar esta creacion de la imagen: version: '3' services: app: image: \"app:$BUILD_TAG\" build: context: . dockerfile: Dockerfile-java Comprobamos: [isx46410800@miguel build]$ export BUILD_TAG=12 [isx46410800@miguel build]$ docker-compose -f docker-compose-build.yml build Crear un script para automatizar la creaci\u00f3n del docker-compose de la imagen: #!/bin/bash # Copia el jar cp -f java-app/target/*.jar jenkins/build/ echo \"######################\" echo \"*** Building image ***\" echo \"######################\" cd jenkins/build/ && docker-compose -f docker-compose-build.yml build --no-cache Lo comprobamos: [isx46410800@miguel pipelines]$ bash jenkins/build/build.sh ###################### *** Building image *** ###################### Building app Step 1/4 : FROM openjdk:8-jre-alpine ---> f7a292bbb70c Step 2/4 : RUN mkdir /app ---> Running in 3997da6947f6 Removing intermediate container 3997da6947f6 ---> f5f751fbe6ab Step 3/4 : COPY *.jar /app/app.jar ---> 9dc51ae21e48 Step 4/4 : CMD java -jar /app/app.jar ---> Running in dd03ae766c0e Removing intermediate container dd03ae766c0e ---> 48409229a4e8 Successfully built 48409229a4e8 Successfully tagged app:13 Lo agregamos al Jenkinsfile: pipeline { agent any stages { stage('Build') { steps { sh ''' ./jenkins/build/mvn.sh mvn -B -DskipTests clean package ./jenkins/build/build.sh ''' } } stage('Test') { steps { sh 'echo test' } } stage('Push') { steps { sh 'echo push' } } stage('Deploy') { steps { sh 'echo deploy' } } } }","title":"BUILD"},{"location":"jenkins/#test","text":"Para hacer el test de maven de la aplicaci\u00f3n se utiliza el mvn test : [isx46410800@miguel build]$ docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn test Vemos los test en java-app/target/surefire-reports: [isx46410800@miguel pipelines]$ ll java-app/target/surefire-reports/ total 12 -rw-r--r--. 1 root root 270 Sep 30 02:45 com.mycompany.app.AppTest.txt -rw-r--r--. 1 root root 4764 Sep 30 02:45 TEST-com.mycompany.app.AppTest.xml Ahora queremos automatizar los tests con un script: [isx46410800@miguel pipelines]$ mkdir jenkins/test [isx46410800@miguel pipelines]$ vi jenkins/test/test.sh #!/bin/bash echo \"################\" echo \"*** Testing ***\" echo \"################\" docker run --rm -v /root/.m2:/root/.m2 -v /home/ricardo/jenkins/jenkins_home/workspace/pipeline-docker-maven/java-app:/app -w /app maven:3-alpine \"$@\" [isx46410800@miguel pipelines]$ chmod +x jenkins/test/test.sh Comprobamos: [isx46410800@miguel pipelines]$ bash jenkins/test/test.sh mvn test ################ *** Testing *** ################ Agregamos el test al Jenkinsfile: stage('Test') { steps { sh './jenkins/test/test.sh mvn test' } }","title":"TEST"},{"location":"jenkins/#push-a-maquina-remota-aws","text":"Nos creamos una maquina virtual o maquina en amazon: [isx46410800@miguel .ssh]$ ssh -i mykeypair.pem fedora@18.133.221.84 Tenemos que tener unas llaves ssh creadas en la maquina remota para poder conectarnos sin contrase\u00f1a: [fedora@ip-172-31-28-138 ~]$ ssh-keygen -f ssh-aws-jenkins Creamos un DOCKER REGISTRY : [fedora@ip-172-31-28-138 .ssh]$ docker run -d -p 5000:5000 --name registry registry:2 Ayuda Vemos que est\u00e1: [fedora@ip-172-31-28-138 .ssh]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2ebffab5d6d6 registry:2 \"/entrypoint.sh /etc\u2026\" 50 seconds ago Up 49 seconds 0.0.0.0:5000->5000/tcp registry En contenido est\u00e1 en /var/lib/registry Creamos un directorio para meter las cosas en este volumen de registros: [fedora@ip-172-31-28-138 ~]$ mkdir tmp_registry [fedora@ip-172-31-28-138 ~]$ docker run -d -p 5000:5000 --name registry -v $PWD/tmp_registry:/var/lib/registry registry:2 Estamos en el AWS en nuestra maquina remota, por lo tanto estamos en local, localhost y queremos ver como bajamos un container y lo subimos a nuestro docker de registros creado anteriormente: [fedora@ip-172-31-28-138 ~]$ docker pull hello-world [fedora@ip-172-31-28-138 ~]$ docker tag hello-world localhost:5000/hello-world [fedora@ip-172-31-28-138 ~]$ docker push localhost:5000/hello-world [fedora@ip-172-31-28-138 ~]$ ll tmp_registry/ total 4 drwxr-xr-x. 3 root root 4096 Oct 1 18:38 docker [fedora@ip-172-31-28-138 ~]$ ll tmp_registry/docker/registry/v2/repositories/hello-world/ total 12 drwxr-xr-x. 3 root root 4096 Oct 1 18:38 _layers drwxr-xr-x. 4 root root 4096 Oct 1 18:38 _manifests drwxr-xr-x. 2 root root 4096 Oct 1 18:38 _uploads Como pusimos que el contenido que vaya al contenedor de registros se guarde en nuestra carpeta creada de tmp_registry, vemos ahi la xixa nueva. Ahora queremos que desde la maquina de casa se pueda subir cosas a este contenedor de registros de AWS: [isx46410800@miguel pipelines]$ sudo vim /lib/systemd/system/docker.service # A\u00f1adimos lo siguiente en la linea de EXECSTART de SERVICE(ip/puerto de aws) --insecure-registry 18.133.221.84:5000 # a\u00f1adimos el puerto 5000 en el security group de la maquina para poder verse amazon y mi maquina por ese puerto # comprobamos la conexion desde mi maquina a AWS con telnet [isx46410800@miguel pipelines]$ telnet 18.133.221.84 5000 [isx46410800@miguel pipelines]$ sudo systemctl daemon-reload [isx46410800@miguel pipelines]$ sudo systemctl restart docker Probamos ahora subirlo desde casa al docker registry de AWS: [isx46410800@miguel pipelines]$ docker pull hello-world [isx46410800@miguel pipelines]$ docker tag hello-world:latest 18.133.221.84:5000/hello-world-casa [isx46410800@miguel pipelines]$ docker push 18.133.221.84:5000/hello-world-casa [fedora@ip-172-31-28-138 ~]$ ll tmp_registry/docker/registry/v2/repositories/ total 8 drwxr-xr-x. 5 root root 4096 Oct 1 18:38 hello-world drwxr-xr-x. 5 root root 4096 Oct 1 18:56 hello-world-casa","title":"PUSH A MAQUINA REMOTA AWS"},{"location":"jenkins/#certificado-ssl-registry-con-autenticacion","text":"Creamos unos directorios tmp-jenkins/certs Creamos el fichero nginx.conf : server { listen 80; # reemplaza segun tus registros DNS server_name ec2-18-133-221-84.eu-west-2.compute.amazonaws.com; location ^~ /.well-known/acme-challenge/ { default_type \"text/plain\"; root /mnt; } } Arrancamos el contenedor: [fedora@ip-172-31-28-138 certs]$ docker run --rm -v $PWD/nginx.conf:/etc/nginx/conf.d/default.conf -v $PWD/letsencrypt:/etc/letsencrypt -p 80:80 -it nginx:alpine sh Instalamos certbot dentro del container que sirve para crear certificados SSL gratuidos durante 3 meses: / # nginx / # apk add --update certbot # certbot certonly --email miguel14amoros@gmail.com --agree-tos --non-interactive --webroot -w \"/mnt\" - d 18.133.221.84 PUSH de imagen con scrip a nuestro registry de amazon o dockerhub. Creamos un directorio en pipelines/jenkins/push: #!/bin/bash echo \"########################\" echo \"*** Preparing to push ***\" echo \"########################\" REGISTRY=\"isx46410800\" // \"18.133.211.84:5000\" IMAGE=\"app\" echo \"*** Logging in ***\" docker login echo \"*** Tagging image ***\" docker tag $IMAGE:$BUILD_TAG $REGISTRY/$IMAGE:$BUILD_TAG echo \"*** Pushing image ***\" docker push $REGISTRY/$IMAGE:$BUILD_TAG Tenemos ya bajada una imagen llamada APP y un export BUILD_TAG=13 Probamos primero y lo agregamos al Jenkinsfile: [isx46410800@miguel pipelines]$ bash jenkins/push/push.sh pipeline { agent any stages { stage('Build') { steps { sh ''' ./jenkins/build/mvn.sh mvn -B -DskipTests clean package ./jenkins/build/build.sh ''' } } stage('Test') { steps { sh './jenkins/test/test.sh mvn test' } } stage('Push') { steps { sh './jenkins/push/push.sh' } } stage('Deploy') { steps { sh 'echo deploy' } } } }","title":"CERTIFICADO SSL REGISTRY CON AUTENTICACION"},{"location":"jenkins/#deploy","text":"En deploy/deploy.sh #!/bin/bash # Transferimos variables echo app > /tmp/.auth echo $BUILD_TAG >> /tmp/.auth # Copiamos el fichero a AWS scp -i ~/.ssh/mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth Lo copiamos a nuestra AWS: scp -i mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth Creamos en AWS un docker-compose: version: '3' services: app: image: \"$REGISTRY/$IMAGE:$TAG\" container_name: app Exportamos las variables: [fedora@ip-172-31-28-138 jenkins]$ export REGISTRY=\"isx46410800\" [fedora@ip-172-31-28-138 jenkins]$ export IMAGE=$(sed -n '1p' /tmp/.auth) [fedora@ip-172-31-28-138 jenkins]$ export TAG=$(sed -n '2p' /tmp/.auth) Comprobamos que descarga la imagen: [fedora@ip-172-31-28-138 jenkins]$ docker-compose up -d Creamos otro fichero publish para pasar las cosas a la remota: [isx46410800@miguel jenkins]$ cat deploy/publish.sh #!/bin/bash export REGISTRY=\"isx46410800\" export IMAGE=$(sed -n '1p' /tmp/.auth) export TAG=$(sed -n '2p' /tmp/.auth) docker login cd ~/jenkins && docker-compose up -d A\u00f1adimos en deploy/deploy.sh: # Transferimos variables echo \"app\" > /tmp/.auth echo $BUILD_TAG >> /tmp/.auth # Copiamos el fichero a AWS scp -i ~/.ssh/mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth scp -i ~/.ssh/mykeypair.pem ./jenkins/deploy/publish.sh fedora@18.133.221.84:/tmp/publish.sh [isx46410800@miguel pipelines]$ bash jenkins/deploy/deploy.sh En AWS ejecutamos el /tmp/publish.sh y se arranca el docker-compose creado en ~/jenkins. Ahora hacemos que se ejecute directamente todo esto desde el deploy.sh en la maquina remota: #!/bin/bash # Transferimos variables echo \"app\" > /tmp/.auth echo $BUILD_TAG >> /tmp/.auth # Copiamos el fichero a AWS scp -i ~/.ssh/mykeypair.pem /tmp/.auth fedora@18.133.221.84:/tmp/.auth scp -i ~/.ssh/mykeypair.pem ./jenkins/deploy/publish.sh fedora@18.133.221.84:/tmp/publish.sh ssh -i ~/.ssh/mykeypair.pem fedora@18.133.221.84 /tmp/publish.sh A\u00f1adimos al Jenkinsfile la parte del deploy: stage('Deploy') { steps { sh './jenkins/deploy/deploy.sh' } }","title":"DEPLOY"},{"location":"jenkins/#cicd_1","text":"Creamos un proyecto de pipeline-maven en nuestro git-server y seguimos los pasos que nos indica el repositorio vacio para poder meter todo el contenido de pipelines en nuestro git. [isx46410800@miguel pipelines]$ git init Initialized empty Git repository in /home/isx46410800/Documents/jenkins/pipelines/.git/ [isx46410800@miguel pipelines]$ git remote add origin http://gitlab.example.com/jenkinsci/pipeline-maven.git [isx46410800@miguel pipelines]$ rm -rf java-app/.git/ [isx46410800@miguel pipelines]$ git add Jenkinsfile java-app/ jenkins/ [isx46410800@miguel pipelines]$ git commit -m \"contenido jenkins ci/cd pipeline\"; git push -u origin master Cambiamos la ruta del deploy.sh por /opt y lo copiamos al container de jenkins para que use la llave ssh: [isx46410800@miguel pipelines]$ docker cp jenkins/deploy/deploy.sh jenkins:/opt/. jenkins@ee5ab67daa7d:/$ chmod +x /opt/deploy.sh Creamos un proyecto de tipo pipeline pipeline-docker-maven Configuramos el pipeline con SCM de git: Modificamos de los ficheros test.sh y deploy.sh la ruta absoluta: test.sh #!/bin/bash echo \"################\" echo \"*** Testing ***\" echo \"################\" PROJECT=\"/home/isx46410800/Documents/jenkins/jenkins_home/workspace/pipeline-docker-maven\" docker run --rm -v /root/.m2:/root/.m2 -v $PROJECT/java-app:/app -w /app maven:3-alpine \"$@\" +++++++++++++++++++++ mvn.sh #!/bin/bash echo \"*************\" echo \"Construyendo jar de mi app java\" echo \"*************\" # Con esto construiriamos el container pero no deja la orden directa: #docker run --rm -v /root/.m2:/root/.m2 -v $PWD/java-app:/app -w /app maven:3-alpine mvn -B -Dskiptests clean package # Para luego pasarle como argumento la orden PROJECT=\"/home/isx46410800/Documents/jenkins/jenkins_home/workspace/pipeline-docker-maven\" docker run --rm -v /root/.m2:/root/.m2 -v $PROJECT/java-app:/app -w /app maven:3-alpine \"$@\" Despues entramos al container jenkins para hacer la conexion ssh manual para que no nos pida lo de autenticar conexion en los cripts: ssh -i /opt/mykeypair.pem fedora@18.133.221.84 Hemos copiado mi llave ssh de amazon a opt dentro de jenkins y la ruta de la llave del deploy.sh tambien. [isx46410800@miguel .ssh]$ docker cp mykeypair.pem jenkins:/opt/. A\u00f1adimos unos post-actions al Jenkisfile para nos de siempre un test de resultados y tambien por si va bien el build de maven guarde el jar: stage('Build') { steps { sh ''' ./jenkins/build/mvn.sh mvn -B -DskipTests clean package ./jenkins/build/build.sh ''' } post { success { archiveArtifacts artifacts 'java-app/target/*.jar', fingerprint: true } } } stage('Test') { steps { sh './jenkins/test/test.sh mvn test' } post { always { junit 'java-app/target/surefire-reports/*.xml' } } } Resultados finales: bajamos el codigo fuente de la app maven, la compilamos, subimos la imagen a dockerhub y mandamos los archivos a AWS para hacer el deploy alli.","title":"CI/CD"},{"location":"kubernetes/","text":"KUBERNETES K8S Es una herramienta extensible y de c\u00f3digo abierto para gestionar cargas de trabajo y servicios en contenedores, que facilita tanto la configuraci\u00f3n declarativa como la automatizaci\u00f3n. Tiene un ecosistema grande y de r\u00e1pido crecimiento. Los servicios, el soporte y las herramientas est\u00e1n ampliamente disponibles. Funciones: Service discovery: mira cuantos nodos hay, los escanea para saber de ellos. Rollouts/Rollbacks: para desplegar versiones nuevas o volver a la misma. Optimizaci\u00f3n de recursos en nodos: mira donde colocar el contenedor al host con menos carga. Self-healing: crea automaticamente un contenedor cuando uno muere. Configuraci\u00f3n de secretos Escalamiento horizontal ARQUITECTURA MASTER/NODE : Kubernetes se divide en master, es el cerebro, es la parte que se encarga de todo el procesamiento, es donde estan todas las herramientas, es el centro de operaciones. Los nodos son las m\u00e1quinas, host, m\u00e1quinas virutal. El master es como la aduana y los nodes son los barcos que se llevan los contenedores de la duana. API SERVER : Aplication Program Interface, significa que yo me puedo comunicar con un servicio a trav\u00e9s de la API. Puedo hacerlo con la herramienta kubectl o directamente por fichero de programaci\u00f3n. Ambos son en JSON, por lo que acaba procesando todo en c\u00f3digo JSON. KUBE-SCHEDULE : es el que se encarga de colocar las cosas donde deben ir. Cuando comunico algo a la API, este le pasa las especificaciones al Schedule y \u00e9ste busca a ver que nodo va mejor para poner todo, si hay muchos, mirar los 15 primeros aprox y lo pone donde mejor vea. Si no encuentra sitio, se espera hasta que quede uno libre correctamente para poder meter el contenedor. KUBE-CONTROLLER : dentro tiene el node controler (se encarga de ver nodos, si se cae uno, levanta otra m\u00e1quina), el replication (encargado de mantener todas las r\u00e9plicas especificadas), el end point controller (se encarga de la red y pods) y tenemos el service account y tokens controller (para la autenticaci\u00f3n). ETCD : es la base de datos de kubernetes donde est\u00e1n todas las configuraciones, cambios, estados nuevos, anteriores, etc. Si ponemos algo en una versi\u00f3n nueva y queremos volver atr\u00e1s, en el etcd est\u00e1 guardado el estado y configuraci\u00f3n anterior. KUBELET : se encuentra en cada nodo y tienen dos funciones, en enviar y recibir informaci\u00f3n al master y por otro lado, habla con el run controller(normalmente docker),que tiene que estar instalado en cada nodo, para decirle las especificaciones que debe desplegar/montar en el POD del nodo. KUBE-PROXY : se encuentra en cada nodo y se encarga de todo lo relacionado con la red del nodo y que se puedan comunicar entre contenedores/pods. CONTAINER-RUNTIME : el software de contenedores que tiene instalado el nodo: docker,etc. INSTALACI\u00d3N MINIKUBE/KUBECTL MINIKUBE : crea o simula un cluster peque\u00f1o que nos permite hacerlo en local. Documentaci\u00f3n Kubernetes Ejecutamos esta orden y sino sale vac\u00edo , vamos bien: grep -E --color 'vmx|svm' /proc/cpuinfo Instalamos kubectl , la intermediario para hablar con kubernetes: curl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\" chmod +x ./kubectl sudo mv ./kubectl /usr/bin/kubectl kubectl version --client Para usar minikube se necesita un Hypervisor (o monitor de m\u00e1quina virtual (virtual machine monitor)1\u200b es una plataforma que permite aplicar diversas t\u00e9cnicas de control de virtualizaci\u00f3n para utilizar, al mismo tiempo, diferentes sistemas operativos en una misma computadora): KVM VirtualBox Docker Descargamos minikube : curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 && chmod +x minikube sudo mv minikube /usr/bin/ minikube status [isx46410800@miguel curso_kubernetes]$ minikube status \ud83e\udd37 There is no local cluster named \"minikube\" \ud83d\udc49 To fix this, run: \"minikube start\" [isx46410800@miguel curso_kubernetes]$ minikube start \ud83d\ude04 minikube v1.13.1 on Fedora 27 \u2728 Automatically selected the docker driver \ud83d\udc4d Starting control plane node minikube in cluster minikube \ud83d\ude9c Pulling base image ... \ud83d\udcbe Downloading Kubernetes v1.19.2 preload ... > preloaded-images-k8s-v6-v1.19.2-docker-overlay2-amd64.tar.lz4: 486.36 MiB \ud83d\udd25 Creating docker container (CPUs=2, Memory=2200MB) ... \ud83e\uddef Docker is nearly out of disk space, which may cause deployments to fail! (93% of capacity) \ud83d\udca1 Suggestion: Try at least one of the following to free up space on the device: 1. Run \"docker system prune\" to remove unused docker data 2. Increase the amount of memory allocated to Docker for Desktop via Docker icon > Preferences > Resources > Disk Image Size 3. Run \"minikube ssh -- docker system prune\" if using the docker container runtime \ud83c\udf7f Related issue: https://github.com/kubernetes/minikube/issues/9024 \ud83d\udc33 Preparing Kubernetes v1.19.2 on Docker 19.03.8 ... \ud83d\udd0e Verifying Kubernetes components... \ud83c\udf1f Enabled addons: default-storageclass, storage-provisioner \ud83c\udfc4 Done! kubectl is now configured to use \"minikube\" by default Comprobamos de nuevo que s\u00ed funciona minikube status : [isx46410800@miguel curso_kubernetes]$ minikube status minikube type: Control Plane host: Running kubelet: Running apiserver: Running kubeconfig: Configured COMANDOS B\u00c1SICOS MINIKUBE : minikube status minikube stop/start/delete Repositorio curso Kubernetes PODS VS CONTENEDORES Los contenedores se ejecutan de manera aislada en un namespace: IPC (Inter Process Communication) Cgroup Network Mount PID User UTS (Unix Timesharing System) Los PODS sirven para compartir namespaces entre contenedores. Con docker permite que varios contenedores se puedan comunicar entre ellos por procesos, redes, files,etc. Kubernetes levanta un servicio y hace que el resto de contenedores compartan ese ID por ejemplo de red y se puedan comunicar y compartir namespaces como: De red(verse en la misma red) IPC(verse los procesos) UTS Cuando hablamos de PODs entonces nos referimos a que solo tiene una unica IP para todo lo que haya dentro comunicado. Solo es una capa que agrupa estos contenedores.","title":"Kubernetes"},{"location":"kubernetes/#kubernetes","text":"K8S Es una herramienta extensible y de c\u00f3digo abierto para gestionar cargas de trabajo y servicios en contenedores, que facilita tanto la configuraci\u00f3n declarativa como la automatizaci\u00f3n. Tiene un ecosistema grande y de r\u00e1pido crecimiento. Los servicios, el soporte y las herramientas est\u00e1n ampliamente disponibles. Funciones: Service discovery: mira cuantos nodos hay, los escanea para saber de ellos. Rollouts/Rollbacks: para desplegar versiones nuevas o volver a la misma. Optimizaci\u00f3n de recursos en nodos: mira donde colocar el contenedor al host con menos carga. Self-healing: crea automaticamente un contenedor cuando uno muere. Configuraci\u00f3n de secretos Escalamiento horizontal","title":"KUBERNETES"},{"location":"kubernetes/#arquitectura","text":"MASTER/NODE : Kubernetes se divide en master, es el cerebro, es la parte que se encarga de todo el procesamiento, es donde estan todas las herramientas, es el centro de operaciones. Los nodos son las m\u00e1quinas, host, m\u00e1quinas virutal. El master es como la aduana y los nodes son los barcos que se llevan los contenedores de la duana. API SERVER : Aplication Program Interface, significa que yo me puedo comunicar con un servicio a trav\u00e9s de la API. Puedo hacerlo con la herramienta kubectl o directamente por fichero de programaci\u00f3n. Ambos son en JSON, por lo que acaba procesando todo en c\u00f3digo JSON. KUBE-SCHEDULE : es el que se encarga de colocar las cosas donde deben ir. Cuando comunico algo a la API, este le pasa las especificaciones al Schedule y \u00e9ste busca a ver que nodo va mejor para poner todo, si hay muchos, mirar los 15 primeros aprox y lo pone donde mejor vea. Si no encuentra sitio, se espera hasta que quede uno libre correctamente para poder meter el contenedor. KUBE-CONTROLLER : dentro tiene el node controler (se encarga de ver nodos, si se cae uno, levanta otra m\u00e1quina), el replication (encargado de mantener todas las r\u00e9plicas especificadas), el end point controller (se encarga de la red y pods) y tenemos el service account y tokens controller (para la autenticaci\u00f3n). ETCD : es la base de datos de kubernetes donde est\u00e1n todas las configuraciones, cambios, estados nuevos, anteriores, etc. Si ponemos algo en una versi\u00f3n nueva y queremos volver atr\u00e1s, en el etcd est\u00e1 guardado el estado y configuraci\u00f3n anterior. KUBELET : se encuentra en cada nodo y tienen dos funciones, en enviar y recibir informaci\u00f3n al master y por otro lado, habla con el run controller(normalmente docker),que tiene que estar instalado en cada nodo, para decirle las especificaciones que debe desplegar/montar en el POD del nodo. KUBE-PROXY : se encuentra en cada nodo y se encarga de todo lo relacionado con la red del nodo y que se puedan comunicar entre contenedores/pods. CONTAINER-RUNTIME : el software de contenedores que tiene instalado el nodo: docker,etc.","title":"ARQUITECTURA"},{"location":"kubernetes/#instalacion-minikubekubectl","text":"MINIKUBE : crea o simula un cluster peque\u00f1o que nos permite hacerlo en local. Documentaci\u00f3n Kubernetes Ejecutamos esta orden y sino sale vac\u00edo , vamos bien: grep -E --color 'vmx|svm' /proc/cpuinfo Instalamos kubectl , la intermediario para hablar con kubernetes: curl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\" chmod +x ./kubectl sudo mv ./kubectl /usr/bin/kubectl kubectl version --client Para usar minikube se necesita un Hypervisor (o monitor de m\u00e1quina virtual (virtual machine monitor)1\u200b es una plataforma que permite aplicar diversas t\u00e9cnicas de control de virtualizaci\u00f3n para utilizar, al mismo tiempo, diferentes sistemas operativos en una misma computadora): KVM VirtualBox Docker Descargamos minikube : curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 && chmod +x minikube sudo mv minikube /usr/bin/ minikube status [isx46410800@miguel curso_kubernetes]$ minikube status \ud83e\udd37 There is no local cluster named \"minikube\" \ud83d\udc49 To fix this, run: \"minikube start\" [isx46410800@miguel curso_kubernetes]$ minikube start \ud83d\ude04 minikube v1.13.1 on Fedora 27 \u2728 Automatically selected the docker driver \ud83d\udc4d Starting control plane node minikube in cluster minikube \ud83d\ude9c Pulling base image ... \ud83d\udcbe Downloading Kubernetes v1.19.2 preload ... > preloaded-images-k8s-v6-v1.19.2-docker-overlay2-amd64.tar.lz4: 486.36 MiB \ud83d\udd25 Creating docker container (CPUs=2, Memory=2200MB) ... \ud83e\uddef Docker is nearly out of disk space, which may cause deployments to fail! (93% of capacity) \ud83d\udca1 Suggestion: Try at least one of the following to free up space on the device: 1. Run \"docker system prune\" to remove unused docker data 2. Increase the amount of memory allocated to Docker for Desktop via Docker icon > Preferences > Resources > Disk Image Size 3. Run \"minikube ssh -- docker system prune\" if using the docker container runtime \ud83c\udf7f Related issue: https://github.com/kubernetes/minikube/issues/9024 \ud83d\udc33 Preparing Kubernetes v1.19.2 on Docker 19.03.8 ... \ud83d\udd0e Verifying Kubernetes components... \ud83c\udf1f Enabled addons: default-storageclass, storage-provisioner \ud83c\udfc4 Done! kubectl is now configured to use \"minikube\" by default Comprobamos de nuevo que s\u00ed funciona minikube status : [isx46410800@miguel curso_kubernetes]$ minikube status minikube type: Control Plane host: Running kubelet: Running apiserver: Running kubeconfig: Configured COMANDOS B\u00c1SICOS MINIKUBE : minikube status minikube stop/start/delete Repositorio curso Kubernetes","title":"INSTALACI\u00d3N MINIKUBE/KUBECTL"},{"location":"kubernetes/#pods-vs-contenedores","text":"Los contenedores se ejecutan de manera aislada en un namespace: IPC (Inter Process Communication) Cgroup Network Mount PID User UTS (Unix Timesharing System) Los PODS sirven para compartir namespaces entre contenedores. Con docker permite que varios contenedores se puedan comunicar entre ellos por procesos, redes, files,etc. Kubernetes levanta un servicio y hace que el resto de contenedores compartan ese ID por ejemplo de red y se puedan comunicar y compartir namespaces como: De red(verse en la misma red) IPC(verse los procesos) UTS Cuando hablamos de PODs entonces nos referimos a que solo tiene una unica IP para todo lo que haya dentro comunicado. Solo es una capa que agrupa estos contenedores.","title":"PODS VS CONTENEDORES"},{"location":"linux/","text":"Comandos LINUX Hacer un listado: ls -la Manual de un comando(1-ordenes, 5-ficheros, 8-admin): man comando Ayuda de un comando: comando --help Crear/ver particiones: fdisk fdisck /dev/sda0 Editor: vim file.txt Ver un archivo: cat file.txt Montar algo: mount mount -t type device dir #mount -t ext4 /dev/sda5 /mnt mount /dir Montar todo lo que tenemos para montar: mount -a Ver tipo de cosas montadas o si est\u00e1 montado algo: mount -t ext4 Cambiar directorio: cd dir cd .. cd dir/file.txt cd /var/tmp Ver path de donde estoy: pwd Crear directorio: mkdir dir mkdir -p /dir1/dir2/dir2/ Borrar directorio(vac\u00edo): rmdir dir Borrar dir/ficheros: rm -rf dir/file Buscar una cadena, palabra..: grep [opciones] [el qu\u00e9] [donde] #grep -i web install.txt Fecha/hora: date Calendario: cal cal 3 2020 Informaci\u00f3n de nuestro usuario: who Indica el usuario: whoami Informaci\u00f3n de la sesi\u00f3n: w Cual es el S.O.: uname -a Tiempo de la sesi\u00f3n: uptime Cual es nuestro host: hostname Info de los usuarios del sistema: finger Numero identificaci\u00f3n del usuario en el sistema: id Ejecutable y man de un comando: whereis comando Lo que hace el ejecutable de un comando: which comando Buscar un fichero o algo de esa palabra en el sistema: locate palabra Primeras o ultimas 10 lineas de un fichero o busqueda: head -n10 /etc/passwd tail -n10 /etc/group Ver procesos en tiempo real: top htop Tipo de fichero: file Contar lineas de un archivo: nl file.txt Dar un numero aleatorio de un rango de numeros: shuf -i 10-20 -n 1 Texto que imprime o carga el kernel: dmesg Procesos: ps ps -u isx46410800 ps -ax ps -p n\u00baproces #indica cual es el proceso pidof nameproceso #pids de este proceso kill proceso kill -n\u00ba proceso killall proceso kill -l #9 mata #15 termina #19 para jobs kill %job ordre & #hacerlo en backgroung fg %job #hacerlo en foreground nohup orden & #desliga un proceso de la terminal disown %job # lo mismo Contar palabras, lineas... wc wc -l wc -c Ver estructura de \u00e1rbol de directorios: tree Copiar ficheros: cp [cosas..] [a donde] cp -r [dir/(cosas)] [a donde] Cambiar nombre de fichero o directorio: mv nombre nuevonombre Meter cosas en ficheros: echo \"hola\" > file.txt cat > file.txt ls -la > file.txt Pathname Expansion: * puede ser nada o muchas cosas ls *.txt ? cada ? es un char ls ???.* [25] coge 2 o 5 ls fit[25].txt [1-4] coge un char del 1 al 4 ls fit[-4].txt [7am7-8][0-9] coge un char del primero y otro del segundo ls fit[7am7-8][0-9].txt # fita8.txt [^abc] que no sea ni a ni b ni c ls fit[^abc].txt Info t\u00e9cnica de un file: stat file.txt Ver inodos: ls -i Crear hard link(no entre dirs ni entre file system diferentes, tama\u00f1o mismo): ln [de que cosa] [hacia donde cosa nueva] # ln file.txt /tmp/filenou.txt (mismo inodo apuntan, misma xixa) Crear simbolic link(equivale a un acceso directo, tama\u00f1o es el nombre): ln -s [de que cosa] [simbolic link creas nuevo] # ln -s file.txt file2.txt Renombre de muchos archivos: rename [donde dice tal cosa] [poner tal cosa] [a estos ficheros] # rename foo foo0 foo* Comparar ficheros: cmp/diff/diff3 file1 file2 Separar ficheros: split -n3/-b10k file prefijo Fichero ejecutable: chmod +x file Comprimir/descomprimir ficheros: gzip file -> file.gz gunzip file.gz bzip2 file -> file.bzp2 bunzip2 file.bzp2 Apagar o cerrar sesi\u00f3n: exit/poweroff/reboot/logout Instalar un paquete: dnf install paquete -y Buscar un paquete: dnf search paquete Donde esta el paquete: dnf provides paquete Lista contenido de un paquete: rpm -ql paquete | grep bin #busca los ejecutables Lista de paquetes instalados: rpm -qa Acciones con paquetes: dnf upgrade/update/reinstall/info paquete Repositorios: dnf repolist --all Permisos(r-leer,mirar,copiar/w-leer,modificar/x-ejecutable): chmod 640 file/dir chmod +rx file/dir Cambiar el propietario de un file/dir(root): chown user.group file/dir Cambiar el grupo de un file/dir: chgrp grupo file Agregar usuario: useradd usuario useradd usuario -g gprincipal -G gsecundario Contrase\u00f1a usuario: passwd usuario Crear grupo: groupadd grupo Borrar usuario y todo suyo: userdel -r usuario Redireccionamientos: 0 - stdin 1 - stdout 2 - stderr 2> salida de errores < entrada > salida 2>&1 donde esta la salida de errores rederiger a la stdout Traducir: tr -s '[a-z]' '[A-Z]' tr -s '[:blanck:]' ' ' Ver espacio ocupado en disco: du / du -sh /tmp Ver variables predefinidas del sistema: set Crear/eliminar variables, mayus SISTEMA, minus USUARIO: nom=valor nom=\"el valor\" usuario=$(id) unset nom Crear subbash: bash Arbol de procesos: pstree Exportar variable a otros niveles ENVIROMENT: export variable Crear alias: alias listar='ls -la' alias quiensoy='id;whoami' unalias listar Command substitution: $(orden) # file $(ls) Brace expansion: mkdir dir{1..20} echo hisx{1,2}-{01-20} Aritmetic expansion: echo $((2*8)) Cron o tareas programadas: at 9:12 --> >cal, date.. #crear tarea programada atq # lista de tareas atrm # borra tareas cron (file /etc/crontab) (min-horas-dia-mes-diasemana(0-7)-ordre) 15 14 1 * * script.sh crontab -l #lista crontab -e #crea o edita crontab -r #borra Ordenar: sort sort -r sort -t: -k3 /etc/passwd #campo 3 sort -t: -k3rg,3 /etc/passwd #descente y de numeric sort -u #unico Lista hardware: lshw Hora del hardware clock: hwclock Ordens grub: grub2-install /dev/sda grub2-mkconfig -o /boot/grub2/grub.cfg Ordenes en debian: apt-get install paquete dpkg -i paquete Compresi\u00f3n de archivos: tar -cvf nombreTar archivosAcomprimir -c crea -v verbose -x descomprimir -f nombre archivo -p permisos para dir tar -zcvf nombreGZIP ficheros tar -jcvf nombreBZIP2 ficheros tar -Jcvf nombreXZ ficheros Backup: tar --listed-incremental fichero.snar -czpf fichero-incremental.tar.gz directorio/. SSH: systemctl start sshd ssh hostname/ip #conectarte ssh user@server -P puerto ssh -p 22 i03/0.0.0.0 #conectarte ssh-keygen #crea llaves ssh -P puerto [fichero] [ip:a donde/.] #copiar fichero scp user@server:file user@server:/dirdestino scp origen destino ssh-copy-id user@ip #copia mi publica a ese ip con ese usuario FTP: ftp ip/host get file put filecopy filedesti wget schema://host-uri-ip/ruta-files #wget ftp://user10@localhost/file.txt Routing: ifconfig ip a ip r nslookup host/web netstat -putano ping -c3 web/ip nmap ip/localhost/host #ver puertos abiertos telnet gost/ip puerto #GET / HTTP/1.0 Netcat conectar: nc -l puerto #conectarte ponte el tuyo a escuchar nc hostname puerto #conectarse al puerto tuyo Activar servicios: systemctl start/stop/enable/disable servicio Cargar de nuevo los demonios: systemctl daemon-reload Culpa de lo que tarda cada cosa al encenderse: systemd-analyse blame Ver errores del sistema: journalctl / journalctl -u servicio Cargar las cosas montables: exportfs -rv SAMBA: meter lo compartido en smb.conf //server/recurso smbtree -L #lista smbtree -D #ver el dominio smbtree -S #ver el servicio smbclient //j17/manuals (-U marta) smbget smb://localhost/manuals/man1/ls mount -t -v cifs //localhost/manuals /mnt -o guest smbpasswd -a miguel #a\u00f1ade user samba pdbeddit -L #lista de cuentas samba MAIL: mail -v -s asunto aquien sendmail -bv user mailq Conectarte a AMAZON AWS: ssh -i ~/ssh/key.pem fedora@IPamazon Servicios mas comunes: /sbin/httpd /sbin/sshd","title":"Linux"},{"location":"linux/#comandos-linux","text":"Hacer un listado: ls -la Manual de un comando(1-ordenes, 5-ficheros, 8-admin): man comando Ayuda de un comando: comando --help Crear/ver particiones: fdisk fdisck /dev/sda0 Editor: vim file.txt Ver un archivo: cat file.txt Montar algo: mount mount -t type device dir #mount -t ext4 /dev/sda5 /mnt mount /dir Montar todo lo que tenemos para montar: mount -a Ver tipo de cosas montadas o si est\u00e1 montado algo: mount -t ext4 Cambiar directorio: cd dir cd .. cd dir/file.txt cd /var/tmp Ver path de donde estoy: pwd Crear directorio: mkdir dir mkdir -p /dir1/dir2/dir2/ Borrar directorio(vac\u00edo): rmdir dir Borrar dir/ficheros: rm -rf dir/file Buscar una cadena, palabra..: grep [opciones] [el qu\u00e9] [donde] #grep -i web install.txt Fecha/hora: date Calendario: cal cal 3 2020 Informaci\u00f3n de nuestro usuario: who Indica el usuario: whoami Informaci\u00f3n de la sesi\u00f3n: w Cual es el S.O.: uname -a Tiempo de la sesi\u00f3n: uptime Cual es nuestro host: hostname Info de los usuarios del sistema: finger Numero identificaci\u00f3n del usuario en el sistema: id Ejecutable y man de un comando: whereis comando Lo que hace el ejecutable de un comando: which comando Buscar un fichero o algo de esa palabra en el sistema: locate palabra Primeras o ultimas 10 lineas de un fichero o busqueda: head -n10 /etc/passwd tail -n10 /etc/group Ver procesos en tiempo real: top htop Tipo de fichero: file Contar lineas de un archivo: nl file.txt Dar un numero aleatorio de un rango de numeros: shuf -i 10-20 -n 1 Texto que imprime o carga el kernel: dmesg Procesos: ps ps -u isx46410800 ps -ax ps -p n\u00baproces #indica cual es el proceso pidof nameproceso #pids de este proceso kill proceso kill -n\u00ba proceso killall proceso kill -l #9 mata #15 termina #19 para jobs kill %job ordre & #hacerlo en backgroung fg %job #hacerlo en foreground nohup orden & #desliga un proceso de la terminal disown %job # lo mismo Contar palabras, lineas... wc wc -l wc -c Ver estructura de \u00e1rbol de directorios: tree Copiar ficheros: cp [cosas..] [a donde] cp -r [dir/(cosas)] [a donde] Cambiar nombre de fichero o directorio: mv nombre nuevonombre Meter cosas en ficheros: echo \"hola\" > file.txt cat > file.txt ls -la > file.txt Pathname Expansion: * puede ser nada o muchas cosas ls *.txt ? cada ? es un char ls ???.* [25] coge 2 o 5 ls fit[25].txt [1-4] coge un char del 1 al 4 ls fit[-4].txt [7am7-8][0-9] coge un char del primero y otro del segundo ls fit[7am7-8][0-9].txt # fita8.txt [^abc] que no sea ni a ni b ni c ls fit[^abc].txt Info t\u00e9cnica de un file: stat file.txt Ver inodos: ls -i Crear hard link(no entre dirs ni entre file system diferentes, tama\u00f1o mismo): ln [de que cosa] [hacia donde cosa nueva] # ln file.txt /tmp/filenou.txt (mismo inodo apuntan, misma xixa) Crear simbolic link(equivale a un acceso directo, tama\u00f1o es el nombre): ln -s [de que cosa] [simbolic link creas nuevo] # ln -s file.txt file2.txt Renombre de muchos archivos: rename [donde dice tal cosa] [poner tal cosa] [a estos ficheros] # rename foo foo0 foo* Comparar ficheros: cmp/diff/diff3 file1 file2 Separar ficheros: split -n3/-b10k file prefijo Fichero ejecutable: chmod +x file Comprimir/descomprimir ficheros: gzip file -> file.gz gunzip file.gz bzip2 file -> file.bzp2 bunzip2 file.bzp2 Apagar o cerrar sesi\u00f3n: exit/poweroff/reboot/logout Instalar un paquete: dnf install paquete -y Buscar un paquete: dnf search paquete Donde esta el paquete: dnf provides paquete Lista contenido de un paquete: rpm -ql paquete | grep bin #busca los ejecutables Lista de paquetes instalados: rpm -qa Acciones con paquetes: dnf upgrade/update/reinstall/info paquete Repositorios: dnf repolist --all Permisos(r-leer,mirar,copiar/w-leer,modificar/x-ejecutable): chmod 640 file/dir chmod +rx file/dir Cambiar el propietario de un file/dir(root): chown user.group file/dir Cambiar el grupo de un file/dir: chgrp grupo file Agregar usuario: useradd usuario useradd usuario -g gprincipal -G gsecundario Contrase\u00f1a usuario: passwd usuario Crear grupo: groupadd grupo Borrar usuario y todo suyo: userdel -r usuario Redireccionamientos: 0 - stdin 1 - stdout 2 - stderr 2> salida de errores < entrada > salida 2>&1 donde esta la salida de errores rederiger a la stdout Traducir: tr -s '[a-z]' '[A-Z]' tr -s '[:blanck:]' ' ' Ver espacio ocupado en disco: du / du -sh /tmp Ver variables predefinidas del sistema: set Crear/eliminar variables, mayus SISTEMA, minus USUARIO: nom=valor nom=\"el valor\" usuario=$(id) unset nom Crear subbash: bash Arbol de procesos: pstree Exportar variable a otros niveles ENVIROMENT: export variable Crear alias: alias listar='ls -la' alias quiensoy='id;whoami' unalias listar Command substitution: $(orden) # file $(ls) Brace expansion: mkdir dir{1..20} echo hisx{1,2}-{01-20} Aritmetic expansion: echo $((2*8)) Cron o tareas programadas: at 9:12 --> >cal, date.. #crear tarea programada atq # lista de tareas atrm # borra tareas cron (file /etc/crontab) (min-horas-dia-mes-diasemana(0-7)-ordre) 15 14 1 * * script.sh crontab -l #lista crontab -e #crea o edita crontab -r #borra Ordenar: sort sort -r sort -t: -k3 /etc/passwd #campo 3 sort -t: -k3rg,3 /etc/passwd #descente y de numeric sort -u #unico Lista hardware: lshw Hora del hardware clock: hwclock Ordens grub: grub2-install /dev/sda grub2-mkconfig -o /boot/grub2/grub.cfg Ordenes en debian: apt-get install paquete dpkg -i paquete Compresi\u00f3n de archivos: tar -cvf nombreTar archivosAcomprimir -c crea -v verbose -x descomprimir -f nombre archivo -p permisos para dir tar -zcvf nombreGZIP ficheros tar -jcvf nombreBZIP2 ficheros tar -Jcvf nombreXZ ficheros Backup: tar --listed-incremental fichero.snar -czpf fichero-incremental.tar.gz directorio/. SSH: systemctl start sshd ssh hostname/ip #conectarte ssh user@server -P puerto ssh -p 22 i03/0.0.0.0 #conectarte ssh-keygen #crea llaves ssh -P puerto [fichero] [ip:a donde/.] #copiar fichero scp user@server:file user@server:/dirdestino scp origen destino ssh-copy-id user@ip #copia mi publica a ese ip con ese usuario FTP: ftp ip/host get file put filecopy filedesti wget schema://host-uri-ip/ruta-files #wget ftp://user10@localhost/file.txt Routing: ifconfig ip a ip r nslookup host/web netstat -putano ping -c3 web/ip nmap ip/localhost/host #ver puertos abiertos telnet gost/ip puerto #GET / HTTP/1.0 Netcat conectar: nc -l puerto #conectarte ponte el tuyo a escuchar nc hostname puerto #conectarse al puerto tuyo Activar servicios: systemctl start/stop/enable/disable servicio Cargar de nuevo los demonios: systemctl daemon-reload Culpa de lo que tarda cada cosa al encenderse: systemd-analyse blame Ver errores del sistema: journalctl / journalctl -u servicio Cargar las cosas montables: exportfs -rv SAMBA: meter lo compartido en smb.conf //server/recurso smbtree -L #lista smbtree -D #ver el dominio smbtree -S #ver el servicio smbclient //j17/manuals (-U marta) smbget smb://localhost/manuals/man1/ls mount -t -v cifs //localhost/manuals /mnt -o guest smbpasswd -a miguel #a\u00f1ade user samba pdbeddit -L #lista de cuentas samba MAIL: mail -v -s asunto aquien sendmail -bv user mailq Conectarte a AMAZON AWS: ssh -i ~/ssh/key.pem fedora@IPamazon Servicios mas comunes: /sbin/httpd /sbin/sshd","title":"Comandos LINUX"},{"location":"markdown/","text":"Comandos lenguaje MARKDOWN T\u00edtulos: #,##... Underlines: ------/==== Negrita: **/__ Cursiva: */_ Tachado ~~ Lista normal: */- Lista numerada: 1. / 2. ... L\u00edneas para encabezado despu\u00e9s de t\u00edtulo: ===/--- Notas: > C\u00f3digo de bloque: `` Bloque de texto: ```tipo_lenguaje L\u00edneas de separaci\u00f3n: ***/---/___ Link: titulo[]()web Link autom\u00e1tico: <> Imagen: titulo![]()ruta imagen Tablas: | letra | letra / --- linea","title":"Markdown"},{"location":"markdown/#comandos-lenguaje-markdown","text":"T\u00edtulos: #,##... Underlines: ------/==== Negrita: **/__ Cursiva: */_ Tachado ~~ Lista normal: */- Lista numerada: 1. / 2. ... L\u00edneas para encabezado despu\u00e9s de t\u00edtulo: ===/--- Notas: > C\u00f3digo de bloque: `` Bloque de texto: ```tipo_lenguaje L\u00edneas de separaci\u00f3n: ***/---/___ Link: titulo[]()web Link autom\u00e1tico: <> Imagen: titulo![]()ruta imagen Tablas: | letra | letra / --- linea","title":"Comandos lenguaje MARKDOWN"},{"location":"python/","text":"Programaci\u00f3n PYTHON Shebang # !/usr/bin/python3 # -*-coding: utf-8-*- Server Python python -m SimpleHTTPDServer 80 Mostrar algo print(\"Uso windows\") Mostrar algo con formato print(\"Hello World, my name is {}\" .format(name)) print(f'My Python version is {version}') Importar librerias import platform from xxxx import xx Variables x=100 y=True z=\"Miguel\" Condicional x = 25 y = 15 if x > y: print(\"x is greater than y: where x is {} and y {}\" .format(x,y)) elif x == y: print(\"x and y are the same: where x is {} and y {}\" .format(x,y)) else: print(\"x is lesser than y: where x is {} and y {}\" .format(x,y)) tengoHambre = True y = \"Necesito comer\" if tengoHambre else \"solo necesito beber\" a = True b = False # comparamos a y b if a and b: print('Expresiones son TRUE') else: print(\"Expresiones son False\") Bucle for (iterar elementos) food = [\"breakfast\", \"lunch\", \"snack\", \"dinner\"] for i in food: print(i) Bucle while food = [\"breakfast\", \"lunch\", \"snack\", \"dinner\"] while m < 4: print(food[m]) m +=1 Funciones def message(): print(\"Mi version de python es la {}\" .format(platform.python_version())) message() def operation(n=25): print(n) return n*2 Test main if __name__ == \"__main__\": runMe() name(\"Miguel\") name(2) print(x) Objetos class Time: h = \"horas\" m = \"minutos\" s = \"segundos\" def hours(self): print(self.h) def minuts(self): print(self.m) def seconds(self): print(self.s) def main2(): how_time = Time() how_time.hours() how_time.minuts() how_time.seconds() main2() Mayusculas, minusculas, letra capital mayus = \"hello world\".upper() minus = \"hello world\".lower() capi = \"hello world\".capitalize() Ver tipo de dato print(type(w)) #float Listas x = [1,2,3,4] print(x[2]) x[2] = 10 for i in x: print(i) # LISTA ACCIONES -- TUPLAS SON INMUTABLES Y NO SE PUEDE def main(): lista = ['perro', 'gato', 'cerdo', 'caballo'] lista2 = ['perro', 'gato', 'cerdo', 'caballo'] print(lista[1]) # gato print(lista[1:3]) # gato, cerdo print(lista[0:5:2]) # perro, cerdo print(lista.index('gato')) # 1, busca la posicion de esa palabra lista.append('koala') # a\u00f1ade koala lista.insert(0, 'vaca') # a\u00f1ade vaca en posicion 0 lista.remove(\"vaca\") # borra de la lista vaca lista.pop() # borra el ultimo elemento de la lista lista.pop(1) # borra esa posicion de la lista del lista[1] # borra de la lista ese elemento del lista[0:1] # borra ese slicing print(len(lista)) # cuenta en numero de elementos de la lista lista.extend(lista2) # junta dos listas print_lista(lista) # funcion de iterar la lista # funcion para iterar la lista pasada por argumento def print_lista(lista): for i in lista: print(i, end=' ', flush=True) print() Tuplas t = (1,2,3,4,5) # cosas con tuplas ## t[2] = 10 NO SE PUEDE ASIGNAR PARA CAMBIAR print(t[2]) for e in t: print(e) Diccionarios dic = { 'x' : 5, 'y' : 'miguel', 'z' : False } # cosas con diccionarios print(dic['y']) dic['y'] = 'miguelito' for id, valor in dic.items(): print(f\"id: {id} valor: {valor}\") for e in dic.values(): print(e) for e in dic: print(f'el id es {e}') print(f'el valor es {dic[e]}') gente = {'1': \"miguel\", '2': \"cristina\", '3': \"isabel\"} gente['4'] = 'maria' for k in gente: print(k) for k,v in gente.items(): print(f'key: {k} valor: {v}') for k in gente.keys(): print(f'key: {k}') for v in gente.values(): print(f'valor: {v}') Rangos r = range(5) # no se puede asignar sino es con una lista ra = list(range(5)) ra[2] = 20 rang = range(5,10,2) # del 5 al 10 de dos en dos # cosas con rangos for e in ra: print(e) for e in rang: print(e) List Comprension # de una lista lista = range(11) tupla = ((0,1),(1,2),(2,3)) # creas una lista,tupla iterando lista y operaciones lista2 = [ x * 2 for x in lista] tupla2 = [ (y*2, x*2) for x,y in tupla] # resultados print(lista2) print(tupla2) Len len(*args/lista) Objetos # definimos una clase class mobile: #definimos unas variables con contenido old_phone = \"keypad\" new_phone = \"touch screen\" # definimos funciones que printes esas variables def old_mobile(self): print(self.old_phone) def new_mobile(self): print(self.new_phone) # creamos funcion,variable con objeto y sus dos partes de funciones def main(): x = mobile() x.old_mobile() x.new_mobile() class Animal: def __init__(self, type, name, sound): self._type = type self._name = name self._sound = sound def type(self): return self._type def name(self): return self._name def sound(self): return self._sound def print_animal(x): if not isinstance(x, Animal): raise TypeError(\"error, requiere un animal\") print(f'El {x.type()} se llama {x.name()} y dice {x.sound()}') # le pasamos a la funcion de hacer algo, los argumentos al objeto def main(): print_animal(Animal(\"Kitten\", \"Fluffly\", \"Meow\")) print_animal(Animal(\"Duck\", \"Donald\", \"Quak\")) Ficheros Leer def main(): file = open('lines.txt', 'r') # file = open('lines.txt', 'r') # read only # file = open('lines.txt', 'w') # write only (empties files) # file = open('lines.txt', 'a') # a\u00f1adir data in files # file = open('lines.txt', 'r+') # optional + read or write for line in file: print(line.rstrip()) #rstrip elimina espacios o lo que se ponga en () Escribir def main(): fileInput = open('lines.txt', 'rt') # r read t text fileOutput = open('linesOutput.txt', 'wt') # w write t text for line in fileInput: print(line.rstrip(), file=fileOutput) # cada linea sin blancos la envia al nuevo file print('.', end='', flush=True) # aqui solo printa esto por cada linea leida fileOutput.close() # cierra el doc nuevo print('\\nDone.') # printa que se ha realizado todo Copiar def main(): fileInput = open('cat.jpg', 'rb') # r read b binario fileOutput = open('cat_copy.jpg', 'wb') # w write b binario # mientras todo se pueda while True: # leemos datos y lo metemos en un buffer buffer = fileInput.read(102400) # mientras haya buffer por leer if buffer: # copiamos del buffer en el file nuevo fileOutput.write(buffer) print('.', end='', flush=True) # aqui solo printa esto por cada linea leida else: break fileOutput.close() # cierra el doc nuevo print('\\nDone.') # printa que se ha realizado todo M\u00f3dulos import os, datetime, sys def main(): # modulo de system v = sys.version_info print('Mi version es {}.{}.{}' .format(*v)) # modulo de operating system x = os.name w = os.getcwdb() print(v) print(w) # modulo de datetime date = datetime.datetime.now() # fecha y hora de ahora print(date) print(date.year) print(date.month) print(date.day)","title":"Python"},{"location":"python/#programacion-python","text":"","title":"Programaci\u00f3n PYTHON"},{"location":"python/#shebang","text":"# !/usr/bin/python3 # -*-coding: utf-8-*-","title":"Shebang"},{"location":"python/#server-python","text":"python -m SimpleHTTPDServer 80","title":"Server Python"},{"location":"python/#mostrar-algo","text":"print(\"Uso windows\")","title":"Mostrar algo"},{"location":"python/#mostrar-algo-con-formato","text":"print(\"Hello World, my name is {}\" .format(name)) print(f'My Python version is {version}')","title":"Mostrar algo con formato"},{"location":"python/#importar-librerias","text":"import platform from xxxx import xx","title":"Importar librerias"},{"location":"python/#variables","text":"x=100 y=True z=\"Miguel\"","title":"Variables"},{"location":"python/#condicional","text":"x = 25 y = 15 if x > y: print(\"x is greater than y: where x is {} and y {}\" .format(x,y)) elif x == y: print(\"x and y are the same: where x is {} and y {}\" .format(x,y)) else: print(\"x is lesser than y: where x is {} and y {}\" .format(x,y)) tengoHambre = True y = \"Necesito comer\" if tengoHambre else \"solo necesito beber\" a = True b = False # comparamos a y b if a and b: print('Expresiones son TRUE') else: print(\"Expresiones son False\")","title":"Condicional"},{"location":"python/#bucle-for-iterar-elementos","text":"food = [\"breakfast\", \"lunch\", \"snack\", \"dinner\"] for i in food: print(i)","title":"Bucle for (iterar elementos)"},{"location":"python/#bucle-while","text":"food = [\"breakfast\", \"lunch\", \"snack\", \"dinner\"] while m < 4: print(food[m]) m +=1","title":"Bucle while"},{"location":"python/#funciones","text":"def message(): print(\"Mi version de python es la {}\" .format(platform.python_version())) message() def operation(n=25): print(n) return n*2","title":"Funciones"},{"location":"python/#test-main","text":"if __name__ == \"__main__\": runMe() name(\"Miguel\") name(2) print(x)","title":"Test main"},{"location":"python/#objetos","text":"class Time: h = \"horas\" m = \"minutos\" s = \"segundos\" def hours(self): print(self.h) def minuts(self): print(self.m) def seconds(self): print(self.s) def main2(): how_time = Time() how_time.hours() how_time.minuts() how_time.seconds() main2()","title":"Objetos"},{"location":"python/#mayusculas-minusculas-letra-capital","text":"mayus = \"hello world\".upper() minus = \"hello world\".lower() capi = \"hello world\".capitalize()","title":"Mayusculas, minusculas, letra capital"},{"location":"python/#ver-tipo-de-dato","text":"print(type(w)) #float","title":"Ver tipo de dato"},{"location":"python/#listas","text":"x = [1,2,3,4] print(x[2]) x[2] = 10 for i in x: print(i) # LISTA ACCIONES -- TUPLAS SON INMUTABLES Y NO SE PUEDE def main(): lista = ['perro', 'gato', 'cerdo', 'caballo'] lista2 = ['perro', 'gato', 'cerdo', 'caballo'] print(lista[1]) # gato print(lista[1:3]) # gato, cerdo print(lista[0:5:2]) # perro, cerdo print(lista.index('gato')) # 1, busca la posicion de esa palabra lista.append('koala') # a\u00f1ade koala lista.insert(0, 'vaca') # a\u00f1ade vaca en posicion 0 lista.remove(\"vaca\") # borra de la lista vaca lista.pop() # borra el ultimo elemento de la lista lista.pop(1) # borra esa posicion de la lista del lista[1] # borra de la lista ese elemento del lista[0:1] # borra ese slicing print(len(lista)) # cuenta en numero de elementos de la lista lista.extend(lista2) # junta dos listas print_lista(lista) # funcion de iterar la lista # funcion para iterar la lista pasada por argumento def print_lista(lista): for i in lista: print(i, end=' ', flush=True) print()","title":"Listas"},{"location":"python/#tuplas","text":"t = (1,2,3,4,5) # cosas con tuplas ## t[2] = 10 NO SE PUEDE ASIGNAR PARA CAMBIAR print(t[2]) for e in t: print(e)","title":"Tuplas"},{"location":"python/#diccionarios","text":"dic = { 'x' : 5, 'y' : 'miguel', 'z' : False } # cosas con diccionarios print(dic['y']) dic['y'] = 'miguelito' for id, valor in dic.items(): print(f\"id: {id} valor: {valor}\") for e in dic.values(): print(e) for e in dic: print(f'el id es {e}') print(f'el valor es {dic[e]}') gente = {'1': \"miguel\", '2': \"cristina\", '3': \"isabel\"} gente['4'] = 'maria' for k in gente: print(k) for k,v in gente.items(): print(f'key: {k} valor: {v}') for k in gente.keys(): print(f'key: {k}') for v in gente.values(): print(f'valor: {v}')","title":"Diccionarios"},{"location":"python/#rangos","text":"r = range(5) # no se puede asignar sino es con una lista ra = list(range(5)) ra[2] = 20 rang = range(5,10,2) # del 5 al 10 de dos en dos # cosas con rangos for e in ra: print(e) for e in rang: print(e)","title":"Rangos"},{"location":"python/#list-comprension","text":"# de una lista lista = range(11) tupla = ((0,1),(1,2),(2,3)) # creas una lista,tupla iterando lista y operaciones lista2 = [ x * 2 for x in lista] tupla2 = [ (y*2, x*2) for x,y in tupla] # resultados print(lista2) print(tupla2)","title":"List Comprension"},{"location":"python/#len","text":"len(*args/lista)","title":"Len"},{"location":"python/#objetos_1","text":"# definimos una clase class mobile: #definimos unas variables con contenido old_phone = \"keypad\" new_phone = \"touch screen\" # definimos funciones que printes esas variables def old_mobile(self): print(self.old_phone) def new_mobile(self): print(self.new_phone) # creamos funcion,variable con objeto y sus dos partes de funciones def main(): x = mobile() x.old_mobile() x.new_mobile() class Animal: def __init__(self, type, name, sound): self._type = type self._name = name self._sound = sound def type(self): return self._type def name(self): return self._name def sound(self): return self._sound def print_animal(x): if not isinstance(x, Animal): raise TypeError(\"error, requiere un animal\") print(f'El {x.type()} se llama {x.name()} y dice {x.sound()}') # le pasamos a la funcion de hacer algo, los argumentos al objeto def main(): print_animal(Animal(\"Kitten\", \"Fluffly\", \"Meow\")) print_animal(Animal(\"Duck\", \"Donald\", \"Quak\"))","title":"Objetos"},{"location":"python/#ficheros","text":"Leer def main(): file = open('lines.txt', 'r') # file = open('lines.txt', 'r') # read only # file = open('lines.txt', 'w') # write only (empties files) # file = open('lines.txt', 'a') # a\u00f1adir data in files # file = open('lines.txt', 'r+') # optional + read or write for line in file: print(line.rstrip()) #rstrip elimina espacios o lo que se ponga en () Escribir def main(): fileInput = open('lines.txt', 'rt') # r read t text fileOutput = open('linesOutput.txt', 'wt') # w write t text for line in fileInput: print(line.rstrip(), file=fileOutput) # cada linea sin blancos la envia al nuevo file print('.', end='', flush=True) # aqui solo printa esto por cada linea leida fileOutput.close() # cierra el doc nuevo print('\\nDone.') # printa que se ha realizado todo Copiar def main(): fileInput = open('cat.jpg', 'rb') # r read b binario fileOutput = open('cat_copy.jpg', 'wb') # w write b binario # mientras todo se pueda while True: # leemos datos y lo metemos en un buffer buffer = fileInput.read(102400) # mientras haya buffer por leer if buffer: # copiamos del buffer en el file nuevo fileOutput.write(buffer) print('.', end='', flush=True) # aqui solo printa esto por cada linea leida else: break fileOutput.close() # cierra el doc nuevo print('\\nDone.') # printa que se ha realizado todo","title":"Ficheros"},{"location":"python/#modulos","text":"import os, datetime, sys def main(): # modulo de system v = sys.version_info print('Mi version es {}.{}.{}' .format(*v)) # modulo de operating system x = os.name w = os.getcwdb() print(v) print(w) # modulo de datetime date = datetime.datetime.now() # fecha y hora de ahora print(date) print(date.year) print(date.month) print(date.day)","title":"M\u00f3dulos"}]}